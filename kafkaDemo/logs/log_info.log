2020-08-14 11:25:17.344 [main] INFO  com.kafka.demo.test.KafkaProducerSerTest - Starting KafkaProducerSerTest on LAPTOP-NFQDMTR9 with PID 13976 (started by sq in E:\otherProjects\kafkaDemo)
2020-08-14 11:25:17.348 [main] INFO  com.kafka.demo.test.KafkaProducerSerTest - No active profile set, falling back to default profiles: default
2020-08-14 11:25:19.938 [main] INFO  com.kafka.demo.clients.KafkaProducerSevice - 初始化:producer
2020-08-14 11:25:20.112 [main] INFO  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [192.168.100.213:6667, 192.168.100.214:6667, 192.168.100.215:6667]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 500
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2020-08-14 11:25:20.658 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.5.0
2020-08-14 11:25:20.660 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 66563e712b0b9f84
2020-08-14 11:25:20.660 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1597375520656
2020-08-14 11:25:21.881 [main] INFO  o.s.scheduling.concurrent.ThreadPoolTaskExecutor - Initializing ExecutorService 'applicationTaskExecutor'
2020-08-14 11:25:21.901 [kafka-producer-network-thread | producer-1] INFO  org.apache.kafka.clients.Metadata - [Producer clientId=producer-1] Cluster ID: JcD5Rmr-Rmu4LUPRR7vWMw
2020-08-14 11:25:23.249 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [192.168.100.213:6667, 192.168.100.214:6667, 192.168.100.215:6667]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = topic.group2
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 100
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-08-14 11:25:23.394 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.5.0
2020-08-14 11:25:23.395 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 66563e712b0b9f84
2020-08-14 11:25:23.395 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1597375523394
2020-08-14 11:25:23.396 [main] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group2-1, groupId=topic.group2] Subscribed to topic(s): topic.test
2020-08-14 11:25:23.399 [main] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Initializing ExecutorService
2020-08-14 11:25:23.405 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [192.168.100.213:6667, 192.168.100.214:6667, 192.168.100.215:6667]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = topic.group2
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 100
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-08-14 11:25:23.416 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.5.0
2020-08-14 11:25:23.416 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 66563e712b0b9f84
2020-08-14 11:25:23.417 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1597375523416
2020-08-14 11:25:23.417 [main] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group2-2, groupId=topic.group2] Subscribed to topic(s): topic.test
2020-08-14 11:25:23.417 [main] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Initializing ExecutorService
2020-08-14 11:25:23.419 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [192.168.100.213:6667, 192.168.100.214:6667, 192.168.100.215:6667]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = topic.group2
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 100
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-08-14 11:25:23.431 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.5.0
2020-08-14 11:25:23.432 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 66563e712b0b9f84
2020-08-14 11:25:23.432 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-topic.group2-2, groupId=topic.group2] Cluster ID: JcD5Rmr-Rmu4LUPRR7vWMw
2020-08-14 11:25:23.432 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1597375523431
2020-08-14 11:25:23.432 [main] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group2-3, groupId=topic.group2] Subscribed to topic(s): topic.test
2020-08-14 11:25:23.433 [main] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Initializing ExecutorService
2020-08-14 11:25:23.434 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-2, groupId=topic.group2] Discovered group coordinator ops-basic03.lingda.com:6667 (id: 2147483645 rack: null)
2020-08-14 11:25:23.434 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [192.168.100.213:6667, 192.168.100.214:6667, 192.168.100.215:6667]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = topic.group2
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 100
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-08-14 11:25:23.438 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-2, groupId=topic.group2] (Re-)joining group
2020-08-14 11:25:23.446 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-topic.group2-3, groupId=topic.group2] Cluster ID: JcD5Rmr-Rmu4LUPRR7vWMw
2020-08-14 11:25:23.446 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-3, groupId=topic.group2] Discovered group coordinator ops-basic03.lingda.com:6667 (id: 2147483645 rack: null)
2020-08-14 11:25:23.448 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-3, groupId=topic.group2] (Re-)joining group
2020-08-14 11:25:23.450 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.5.0
2020-08-14 11:25:23.450 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 66563e712b0b9f84
2020-08-14 11:25:23.451 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1597375523450
2020-08-14 11:25:23.451 [main] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group2-4, groupId=topic.group2] Subscribed to topic(s): topic.test
2020-08-14 11:25:23.451 [main] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Initializing ExecutorService
2020-08-14 11:25:23.454 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [192.168.100.213:6667, 192.168.100.214:6667, 192.168.100.215:6667]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = topic.group2
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 100
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-08-14 11:25:23.463 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group2-2, groupId=topic.group2] Finished assignment for group at generation 1: {consumer-topic.group2-2-82ee6dc2-e748-4067-9a48-8c5afdfee31e=Assignment(partitions=[topic.test-0, topic.test-1, topic.test-2])}
2020-08-14 11:25:23.468 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-topic.group2-4, groupId=topic.group2] Cluster ID: JcD5Rmr-Rmu4LUPRR7vWMw
2020-08-14 11:25:23.468 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-2, groupId=topic.group2] Join group failed with org.apache.kafka.common.errors.RebalanceInProgressException: The group is rebalancing, so a rejoin is needed.
2020-08-14 11:25:23.469 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-4, groupId=topic.group2] Discovered group coordinator ops-basic03.lingda.com:6667 (id: 2147483645 rack: null)
2020-08-14 11:25:23.470 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-2, groupId=topic.group2] (Re-)joining group
2020-08-14 11:25:23.471 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-4, groupId=topic.group2] (Re-)joining group
2020-08-14 11:25:23.472 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group2-2, groupId=topic.group2] Finished assignment for group at generation 2: {consumer-topic.group2-2-82ee6dc2-e748-4067-9a48-8c5afdfee31e=Assignment(partitions=[topic.test-0, topic.test-1]), consumer-topic.group2-3-75c50203-082f-4570-b272-2bdbf890c8d6=Assignment(partitions=[topic.test-2])}
2020-08-14 11:25:23.474 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.5.0
2020-08-14 11:25:23.474 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 66563e712b0b9f84
2020-08-14 11:25:23.474 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1597375523474
2020-08-14 11:25:23.476 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-3, groupId=topic.group2] Join group failed with org.apache.kafka.common.errors.RebalanceInProgressException: The group is rebalancing, so a rejoin is needed.
2020-08-14 11:25:23.477 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-3, groupId=topic.group2] (Re-)joining group
2020-08-14 11:25:23.477 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-2, groupId=topic.group2] Join group failed with org.apache.kafka.common.errors.RebalanceInProgressException: The group is rebalancing, so a rejoin is needed.
2020-08-14 11:25:23.477 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-2, groupId=topic.group2] (Re-)joining group
2020-08-14 11:25:23.477 [main] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group2-5, groupId=topic.group2] Subscribed to topic(s): topic.test
2020-08-14 11:25:23.478 [main] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Initializing ExecutorService
2020-08-14 11:25:23.479 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group2-2, groupId=topic.group2] Finished assignment for group at generation 3: {consumer-topic.group2-4-2996e1c5-4452-47ed-b1c2-83ac611e5c32=Assignment(partitions=[topic.test-2]), consumer-topic.group2-2-82ee6dc2-e748-4067-9a48-8c5afdfee31e=Assignment(partitions=[topic.test-0]), consumer-topic.group2-3-75c50203-082f-4570-b272-2bdbf890c8d6=Assignment(partitions=[topic.test-1])}
2020-08-14 11:25:23.481 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [192.168.100.213:6667, 192.168.100.214:6667, 192.168.100.215:6667]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = topic.group1
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 100
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-08-14 11:25:23.482 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-3, groupId=topic.group2] Successfully joined group with generation 3
2020-08-14 11:25:23.482 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-4, groupId=topic.group2] Successfully joined group with generation 3
2020-08-14 11:25:23.482 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-2, groupId=topic.group2] Successfully joined group with generation 3
2020-08-14 11:25:23.491 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group2-3, groupId=topic.group2] Adding newly assigned partitions: topic.test-1
2020-08-14 11:25:23.493 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group2-2, groupId=topic.group2] Adding newly assigned partitions: topic.test-0
2020-08-14 11:25:23.493 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group2-4, groupId=topic.group2] Adding newly assigned partitions: topic.test-2
2020-08-14 11:25:23.495 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.5.0
2020-08-14 11:25:23.496 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 66563e712b0b9f84
2020-08-14 11:25:23.496 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1597375523495
2020-08-14 11:25:23.496 [main] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group1-6, groupId=topic.group1] Subscribed to topic(s): topic.test
2020-08-14 11:25:23.497 [main] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Initializing ExecutorService
2020-08-14 11:25:23.500 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [192.168.100.213:6667, 192.168.100.214:6667, 192.168.100.215:6667]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = topic.group1
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 100
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-08-14 11:25:23.505 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group2-3, groupId=topic.group2] Found no committed offset for partition topic.test-1
2020-08-14 11:25:23.505 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group2-2, groupId=topic.group2] Found no committed offset for partition topic.test-0
2020-08-14 11:25:23.509 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group2-4, groupId=topic.group2] Found no committed offset for partition topic.test-2
2020-08-14 11:25:23.515 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.5.0
2020-08-14 11:25:23.515 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 66563e712b0b9f84
2020-08-14 11:25:23.516 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1597375523515
2020-08-14 11:25:23.516 [main] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group1-7, groupId=topic.group1] Subscribed to topic(s): topic.test
2020-08-14 11:25:23.517 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-topic.group1-6, groupId=topic.group1] Cluster ID: JcD5Rmr-Rmu4LUPRR7vWMw
2020-08-14 11:25:23.517 [main] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Initializing ExecutorService
2020-08-14 11:25:23.518 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-6, groupId=topic.group1] Discovered group coordinator ops-basic02.lingda.com:6667 (id: 2147483646 rack: null)
2020-08-14 11:25:23.520 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-6, groupId=topic.group1] (Re-)joining group
2020-08-14 11:25:23.524 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  o.a.k.clients.consumer.internals.SubscriptionState - [Consumer clientId=consumer-topic.group2-3, groupId=topic.group2] Resetting offset for partition topic.test-1 to offset 0.
2020-08-14 11:25:23.524 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.a.k.clients.consumer.internals.SubscriptionState - [Consumer clientId=consumer-topic.group2-4, groupId=topic.group2] Resetting offset for partition topic.test-2 to offset 1.
2020-08-14 11:25:23.524 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [192.168.100.213:6667, 192.168.100.214:6667, 192.168.100.215:6667]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = topic.group1
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 100
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-08-14 11:25:23.526 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - topic.group2: partitions assigned: [topic.test-2]
2020-08-14 11:25:23.526 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - topic.group2: partitions assigned: [topic.test-1]
2020-08-14 11:25:23.531 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group1-6, groupId=topic.group1] Finished assignment for group at generation 1: {consumer-topic.group1-6-06256d66-945d-43c6-adbf-96e26cfaee96=Assignment(partitions=[topic.test-0, topic.test-1, topic.test-2])}
2020-08-14 11:25:23.537 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.5.0
2020-08-14 11:25:23.537 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 66563e712b0b9f84
2020-08-14 11:25:23.538 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1597375523537
2020-08-14 11:25:23.538 [main] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group1-8, groupId=topic.group1] Subscribed to topic(s): topic.test
2020-08-14 11:25:23.538 [main] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Initializing ExecutorService
2020-08-14 11:25:23.548 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-6, groupId=topic.group1] Successfully joined group with generation 1
2020-08-14 11:25:23.550 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [192.168.100.213:6667, 192.168.100.214:6667, 192.168.100.215:6667]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = topic.group1
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 100
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-08-14 11:25:23.559 [org.springframework.kafka.KafkaListenerEndpointContainer#1-2-C-1] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-topic.group1-8, groupId=topic.group1] Cluster ID: JcD5Rmr-Rmu4LUPRR7vWMw
2020-08-14 11:25:23.560 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group1-6, groupId=topic.group1] Adding newly assigned partitions: topic.test-0, topic.test-1, topic.test-2
2020-08-14 11:25:23.560 [org.springframework.kafka.KafkaListenerEndpointContainer#1-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-8, groupId=topic.group1] Discovered group coordinator ops-basic02.lingda.com:6667 (id: 2147483646 rack: null)
2020-08-14 11:25:23.561 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group1-6, groupId=topic.group1] Found no committed offset for partition topic.test-0
2020-08-14 11:25:23.562 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group1-6, groupId=topic.group1] Found no committed offset for partition topic.test-1
2020-08-14 11:25:23.562 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group1-6, groupId=topic.group1] Found no committed offset for partition topic.test-2
2020-08-14 11:25:23.561 [org.springframework.kafka.KafkaListenerEndpointContainer#1-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-8, groupId=topic.group1] (Re-)joining group
2020-08-14 11:25:23.564 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.5.0
2020-08-14 11:25:23.564 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 66563e712b0b9f84
2020-08-14 11:25:23.565 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1597375523564
2020-08-14 11:25:23.566 [main] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group1-9, groupId=topic.group1] Subscribed to topic(s): topic.test
2020-08-14 11:25:23.567 [main] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Initializing ExecutorService
2020-08-14 11:25:23.571 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [192.168.100.213:6667, 192.168.100.214:6667, 192.168.100.215:6667]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = topic.group1
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 100
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-08-14 11:25:23.572 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.a.k.clients.consumer.internals.SubscriptionState - [Consumer clientId=consumer-topic.group1-6, groupId=topic.group1] Resetting offset for partition topic.test-1 to offset 0.
2020-08-14 11:25:23.573 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.a.k.clients.consumer.internals.SubscriptionState - [Consumer clientId=consumer-topic.group1-6, groupId=topic.group1] Resetting offset for partition topic.test-2 to offset 1.
2020-08-14 11:25:23.578 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.5.0
2020-08-14 11:25:23.579 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 66563e712b0b9f84
2020-08-14 11:25:23.579 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1597375523578
2020-08-14 11:25:23.579 [main] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group1-10, groupId=topic.group1] Subscribed to topic(s): topic.test
2020-08-14 11:25:23.579 [main] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Initializing ExecutorService
2020-08-14 11:25:23.591 [org.springframework.kafka.KafkaListenerEndpointContainer#1-3-C-1] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-topic.group1-9, groupId=topic.group1] Cluster ID: JcD5Rmr-Rmu4LUPRR7vWMw
2020-08-14 11:25:23.592 [org.springframework.kafka.KafkaListenerEndpointContainer#1-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-9, groupId=topic.group1] Discovered group coordinator ops-basic02.lingda.com:6667 (id: 2147483646 rack: null)
2020-08-14 11:25:23.594 [org.springframework.kafka.KafkaListenerEndpointContainer#1-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-9, groupId=topic.group1] (Re-)joining group
2020-08-14 11:25:23.599 [main] INFO  com.kafka.demo.test.KafkaProducerSerTest - Started KafkaProducerSerTest in 7.198 seconds (JVM running for 9.568)
2020-08-14 11:25:23.605 [pool-2-thread-1] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [192.168.100.213:6667, 192.168.100.214:6667, 192.168.100.215:6667]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = new
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 100
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-08-14 11:25:23.613 [pool-2-thread-1] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.5.0
2020-08-14 11:25:23.613 [pool-2-thread-1] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 66563e712b0b9f84
2020-08-14 11:25:23.613 [pool-2-thread-1] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1597375523613
2020-08-14 11:25:23.615 [pool-2-thread-1] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-new-11, groupId=new] Subscribed to topic(s): test_kafka_service
2020-08-14 11:25:23.621 [pool-2-thread-1] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-new-11, groupId=new] Cluster ID: JcD5Rmr-Rmu4LUPRR7vWMw
2020-08-14 11:25:23.622 [pool-2-thread-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-new-11, groupId=new] Discovered group coordinator ops-basic03.lingda.com:6667 (id: 2147483645 rack: null)
2020-08-14 11:25:23.623 [pool-2-thread-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-new-11, groupId=new] (Re-)joining group
2020-08-14 11:25:23.629 [pool-2-thread-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-new-11, groupId=new] Finished assignment for group at generation 1: {consumer-new-11-0e039cd4-8168-40af-8c3e-e672a9623cd4=Assignment(partitions=[test_kafka_service-0, test_kafka_service-1, test_kafka_service-2])}
2020-08-14 11:25:23.631 [pool-2-thread-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-new-11, groupId=new] Successfully joined group with generation 1
2020-08-14 11:25:23.633 [pool-2-thread-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-new-11, groupId=new] Adding newly assigned partitions: test_kafka_service-0, test_kafka_service-2, test_kafka_service-1
2020-08-14 11:25:23.636 [pool-2-thread-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-new-11, groupId=new] Found no committed offset for partition test_kafka_service-0
2020-08-14 11:25:23.636 [pool-2-thread-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-new-11, groupId=new] Found no committed offset for partition test_kafka_service-2
2020-08-14 11:25:23.636 [pool-2-thread-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-new-11, groupId=new] Found no committed offset for partition test_kafka_service-1
2020-08-14 11:25:23.643 [pool-2-thread-1] INFO  o.a.k.clients.consumer.internals.SubscriptionState - [Consumer clientId=consumer-new-11, groupId=new] Resetting offset for partition test_kafka_service-2 to offset 0.
2020-08-14 11:25:23.647 [pool-2-thread-1] INFO  o.a.k.clients.consumer.internals.SubscriptionState - [Consumer clientId=consumer-new-11, groupId=new] Resetting offset for partition test_kafka_service-0 to offset 0.
2020-08-14 11:25:26.854 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-6, groupId=topic.group1] Attempt to heartbeat failed since group is rebalancing
2020-08-14 11:25:29.931 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-6, groupId=topic.group1] Attempt to heartbeat failed since group is rebalancing
2020-08-14 11:25:33.140 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-6, groupId=topic.group1] Attempt to heartbeat failed since group is rebalancing
2020-08-14 11:25:36.220 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-6, groupId=topic.group1] Attempt to heartbeat failed since group is rebalancing
2020-08-14 11:25:39.307 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-6, groupId=topic.group1] Attempt to heartbeat failed since group is rebalancing
2020-08-14 11:25:42.381 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-6, groupId=topic.group1] Attempt to heartbeat failed since group is rebalancing
2020-08-14 11:25:44.477 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-1, groupId=topic.group2] Discovered group coordinator ops-basic03.lingda.com:6667 (id: 2147483645 rack: null)
2020-08-14 11:25:44.478 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-1, groupId=topic.group2] (Re-)joining group
2020-08-14 11:25:44.514 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-5, groupId=topic.group2] Discovered group coordinator ops-basic03.lingda.com:6667 (id: 2147483645 rack: null)
2020-08-14 11:25:44.516 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-5, groupId=topic.group2] (Re-)joining group
2020-08-14 11:25:44.538 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-4, groupId=topic.group2] Attempt to heartbeat failed since group is rebalancing
2020-08-14 11:25:44.540 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group2-4, groupId=topic.group2] Revoke previously assigned partitions topic.test-2
2020-08-14 11:25:44.541 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - topic.group2: partitions revoked: [topic.test-2]
2020-08-14 11:25:44.541 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-4, groupId=topic.group2] (Re-)joining group
2020-08-14 11:25:44.541 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-3, groupId=topic.group2] Attempt to heartbeat failed since group is rebalancing
2020-08-14 11:25:44.541 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group2-3, groupId=topic.group2] Revoke previously assigned partitions topic.test-1
2020-08-14 11:25:44.541 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - topic.group2: partitions revoked: [topic.test-1]
2020-08-14 11:25:44.542 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-3, groupId=topic.group2] (Re-)joining group
2020-08-14 11:25:44.566 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-topic.group2-1, groupId=topic.group2] Cluster ID: JcD5Rmr-Rmu4LUPRR7vWMw
2020-08-14 11:25:44.568 [org.springframework.kafka.KafkaListenerEndpointContainer#1-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-7, groupId=topic.group1] Discovered group coordinator ops-basic02.lingda.com:6667 (id: 2147483646 rack: null)
2020-08-14 11:25:44.569 [org.springframework.kafka.KafkaListenerEndpointContainer#1-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-7, groupId=topic.group1] (Re-)joining group
2020-08-14 11:25:44.610 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-topic.group2-5, groupId=topic.group2] Cluster ID: JcD5Rmr-Rmu4LUPRR7vWMw
2020-08-14 11:25:44.648 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-10, groupId=topic.group1] Discovered group coordinator ops-basic02.lingda.com:6667 (id: 2147483646 rack: null)
2020-08-14 11:25:44.649 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-10, groupId=topic.group1] (Re-)joining group
2020-08-14 11:25:44.662 [org.springframework.kafka.KafkaListenerEndpointContainer#1-1-C-1] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-topic.group1-7, groupId=topic.group1] Cluster ID: JcD5Rmr-Rmu4LUPRR7vWMw
2020-08-14 11:25:44.767 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-topic.group1-10, groupId=topic.group1] Cluster ID: JcD5Rmr-Rmu4LUPRR7vWMw
2020-08-14 11:25:45.320 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-2, groupId=topic.group2] Attempt to heartbeat failed since group is rebalancing
2020-08-14 11:25:45.383 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-6, groupId=topic.group1] Attempt to heartbeat failed since group is rebalancing
2020-08-14 11:25:48.383 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-2, groupId=topic.group2] Attempt to heartbeat failed since group is rebalancing
2020-08-14 11:25:48.666 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-6, groupId=topic.group1] Attempt to heartbeat failed since group is rebalancing
2020-08-14 11:25:51.561 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-2, groupId=topic.group2] Attempt to heartbeat failed since group is rebalancing
2020-08-14 11:25:51.618 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-6, groupId=topic.group1] Attempt to heartbeat failed since group is rebalancing
2020-08-14 11:25:54.650 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-2, groupId=topic.group2] Attempt to heartbeat failed since group is rebalancing
2020-08-14 11:25:54.796 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-6, groupId=topic.group1] Attempt to heartbeat failed since group is rebalancing
2020-08-14 11:25:57.761 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-6, groupId=topic.group1] Attempt to heartbeat failed since group is rebalancing
2020-08-14 11:25:57.841 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-2, groupId=topic.group2] Attempt to heartbeat failed since group is rebalancing
2020-08-14 11:26:00.912 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-2, groupId=topic.group2] Attempt to heartbeat failed since group is rebalancing
2020-08-14 11:26:01.053 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-6, groupId=topic.group1] Attempt to heartbeat failed since group is rebalancing
2020-08-14 11:26:04.004 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-6, groupId=topic.group1] Attempt to heartbeat failed since group is rebalancing
2020-08-14 11:26:04.084 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-2, groupId=topic.group2] Attempt to heartbeat failed since group is rebalancing
2020-08-14 11:26:07.100 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-2, groupId=topic.group2] Attempt to heartbeat failed since group is rebalancing
2020-08-14 11:26:07.100 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-6, groupId=topic.group1] Attempt to heartbeat failed since group is rebalancing
2020-08-14 11:26:10.164 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-2, groupId=topic.group2] Attempt to heartbeat failed since group is rebalancing
2020-08-14 11:26:10.165 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-6, groupId=topic.group1] Attempt to heartbeat failed since group is rebalancing
2020-08-14 11:26:13.226 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-2, groupId=topic.group2] Attempt to heartbeat failed since group is rebalancing
2020-08-14 11:26:13.227 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-6, groupId=topic.group1] Attempt to heartbeat failed since group is rebalancing
2020-08-14 11:26:16.415 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-2, groupId=topic.group2] Attempt to heartbeat failed since group is rebalancing
2020-08-14 11:26:16.416 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-6, groupId=topic.group1] Attempt to heartbeat failed since group is rebalancing
2020-08-14 11:26:19.472 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-6, groupId=topic.group1] Attempt to heartbeat failed since group is rebalancing
2020-08-14 11:26:19.581 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-2, groupId=topic.group2] Attempt to heartbeat failed since group is rebalancing
2020-08-14 11:26:22.785 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-6, groupId=topic.group1] Attempt to heartbeat failed since group is rebalancing
2020-08-14 11:26:22.877 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-2, groupId=topic.group2] Attempt to heartbeat failed since group is rebalancing
2020-08-14 11:26:23.530 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group2-2, groupId=topic.group2] Adding newly assigned partitions: 
2020-08-14 11:26:23.531 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - topic.group2: partitions assigned: []
2020-08-14 11:26:23.534 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group2-2, groupId=topic.group2] Revoke previously assigned partitions topic.test-0
2020-08-14 11:26:23.535 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - topic.group2: partitions revoked: [topic.test-0]
2020-08-14 11:26:23.535 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-2, groupId=topic.group2] (Re-)joining group
2020-08-14 11:26:23.568 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group2-2, groupId=topic.group2] Finished assignment for group at generation 4: {consumer-topic.group2-4-2996e1c5-4452-47ed-b1c2-83ac611e5c32=Assignment(partitions=[]), consumer-topic.group2-2-82ee6dc2-e748-4067-9a48-8c5afdfee31e=Assignment(partitions=[topic.test-1]), consumer-topic.group2-1-56a4f027-a287-4984-ab1c-cb08143fe564=Assignment(partitions=[topic.test-0]), consumer-topic.group2-3-75c50203-082f-4570-b272-2bdbf890c8d6=Assignment(partitions=[topic.test-2]), consumer-topic.group2-5-e03bb439-29fb-403d-9b73-3319711aff05=Assignment(partitions=[])}
2020-08-14 11:26:23.570 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-4, groupId=topic.group2] Successfully joined group with generation 4
2020-08-14 11:26:23.570 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-1, groupId=topic.group2] Successfully joined group with generation 4
2020-08-14 11:26:23.570 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-2, groupId=topic.group2] Successfully joined group with generation 4
2020-08-14 11:26:23.571 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group2-1, groupId=topic.group2] Adding newly assigned partitions: topic.test-0
2020-08-14 11:26:23.571 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group2-2, groupId=topic.group2] Adding newly assigned partitions: topic.test-1
2020-08-14 11:26:23.571 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group2-4, groupId=topic.group2] Adding newly assigned partitions: 
2020-08-14 11:26:23.570 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-5, groupId=topic.group2] Successfully joined group with generation 4
2020-08-14 11:26:23.571 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - topic.group2: partitions assigned: []
2020-08-14 11:26:23.571 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group2-5, groupId=topic.group2] Adding newly assigned partitions: 
2020-08-14 11:26:23.573 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-3, groupId=topic.group2] Successfully joined group with generation 4
2020-08-14 11:26:23.750 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group1-6, groupId=topic.group1] Adding newly assigned partitions: 
2020-08-14 11:26:23.750 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - topic.group1: partitions assigned: []
2020-08-14 11:26:23.750 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group1-6, groupId=topic.group1] Revoke previously assigned partitions topic.test-0, topic.test-1, topic.test-2
2020-08-14 11:26:23.580 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - topic.group2: partitions assigned: []
2020-08-14 11:26:23.752 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group2-3, groupId=topic.group2] Adding newly assigned partitions: topic.test-2
2020-08-14 11:26:23.753 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group2-3, groupId=topic.group2] Found no committed offset for partition topic.test-2
2020-08-14 11:26:23.580 [kafka-coordinator-heartbeat-thread | topic.group2] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group2-1, groupId=topic.group2] Found no committed offset for partition topic.test-0
2020-08-14 11:26:23.750 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - topic.group1: partitions revoked: [topic.test-0, topic.test-1, topic.test-2]
2020-08-14 11:26:23.757 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-6, groupId=topic.group1] (Re-)joining group
2020-08-14 11:26:23.772 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group1-6, groupId=topic.group1] Finished assignment for group at generation 2: {consumer-topic.group1-8-7a6de9da-43b8-4288-9246-c3f19bf6fff7=Assignment(partitions=[]), consumer-topic.group1-6-06256d66-945d-43c6-adbf-96e26cfaee96=Assignment(partitions=[topic.test-1]), consumer-topic.group1-9-1ee26c1c-7ae8-4401-975d-23d73d1f64f6=Assignment(partitions=[]), consumer-topic.group1-7-a813c7de-b38e-4d63-8050-94a8ba540741=Assignment(partitions=[topic.test-2]), consumer-topic.group1-10-fa2485db-9ad3-4ec2-aa2c-21386de5b369=Assignment(partitions=[topic.test-0])}
2020-08-14 11:26:23.580 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group2-2, groupId=topic.group2] Found no committed offset for partition topic.test-1
2020-08-14 11:26:23.778 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  o.a.k.clients.consumer.internals.SubscriptionState - [Consumer clientId=consumer-topic.group2-3, groupId=topic.group2] Resetting offset for partition topic.test-2 to offset 1.
2020-08-14 11:26:23.778 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - topic.group2: partitions assigned: [topic.test-2]
2020-08-14 11:26:23.783 [org.springframework.kafka.KafkaListenerEndpointContainer#1-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-8, groupId=topic.group1] Successfully joined group with generation 2
2020-08-14 11:26:23.783 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-6, groupId=topic.group1] Successfully joined group with generation 2
2020-08-14 11:26:23.783 [org.springframework.kafka.KafkaListenerEndpointContainer#1-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-7, groupId=topic.group1] Successfully joined group with generation 2
2020-08-14 11:26:23.783 [org.springframework.kafka.KafkaListenerEndpointContainer#1-2-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group1-8, groupId=topic.group1] Adding newly assigned partitions: 
2020-08-14 11:26:23.784 [org.springframework.kafka.KafkaListenerEndpointContainer#1-2-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - topic.group1: partitions assigned: []
2020-08-14 11:26:23.803 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group1-6, groupId=topic.group1] Adding newly assigned partitions: topic.test-1
2020-08-14 11:26:23.803 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-10, groupId=topic.group1] Successfully joined group with generation 2
2020-08-14 11:26:23.803 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group1-10, groupId=topic.group1] Adding newly assigned partitions: topic.test-0
2020-08-14 11:26:23.805 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group1-10, groupId=topic.group1] Found no committed offset for partition topic.test-0
2020-08-14 11:26:23.805 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group1-6, groupId=topic.group1] Found no committed offset for partition topic.test-1
2020-08-14 11:26:23.807 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.a.k.clients.consumer.internals.SubscriptionState - [Consumer clientId=consumer-topic.group1-6, groupId=topic.group1] Resetting offset for partition topic.test-1 to offset 0.
2020-08-14 11:26:23.807 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - topic.group1: partitions assigned: [topic.test-1]
2020-08-14 11:26:23.805 [org.springframework.kafka.KafkaListenerEndpointContainer#1-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-9, groupId=topic.group1] Successfully joined group with generation 2
2020-08-14 11:26:23.810 [org.springframework.kafka.KafkaListenerEndpointContainer#1-3-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group1-9, groupId=topic.group1] Adding newly assigned partitions: 
2020-08-14 11:26:23.811 [org.springframework.kafka.KafkaListenerEndpointContainer#1-3-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - topic.group1: partitions assigned: []
2020-08-14 11:26:23.811 [org.springframework.kafka.KafkaListenerEndpointContainer#1-1-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group1-7, groupId=topic.group1] Adding newly assigned partitions: topic.test-2
2020-08-14 11:26:23.818 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.a.k.clients.consumer.internals.SubscriptionState - [Consumer clientId=consumer-topic.group2-2, groupId=topic.group2] Resetting offset for partition topic.test-1 to offset 0.
2020-08-14 11:26:23.818 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - topic.group2: partitions assigned: [topic.test-1]
2020-08-14 11:26:23.818 [org.springframework.kafka.KafkaListenerEndpointContainer#1-1-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group1-7, groupId=topic.group1] Found no committed offset for partition topic.test-2
2020-08-14 11:26:23.823 [org.springframework.kafka.KafkaListenerEndpointContainer#1-1-C-1] INFO  o.a.k.clients.consumer.internals.SubscriptionState - [Consumer clientId=consumer-topic.group1-7, groupId=topic.group1] Resetting offset for partition topic.test-2 to offset 1.
2020-08-14 11:26:23.824 [org.springframework.kafka.KafkaListenerEndpointContainer#1-1-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - topic.group1: partitions assigned: [topic.test-2]
2020-08-14 11:26:30.785 [pool-2-thread-1] INFO  com.kafka.demo.clients.KafkaConsumerService - 消费到消息:{"data":"测试消息1","id":"1"}
2020-08-14 11:26:30.785 [pool-2-thread-1] INFO  com.kafka.demo.clients.KafkaConsumerService - 消费到消息:{"data":"测试消息2","id":"1"}
2020-08-14 11:26:30.785 [pool-2-thread-1] INFO  com.kafka.demo.clients.KafkaConsumerService - 消费到消息:{"data":"测试消息3","id":"1"}
2020-08-14 11:26:30.785 [pool-2-thread-1] INFO  com.kafka.demo.clients.KafkaConsumerService - 消费到消息:{"data":"测试消息4","id":"1"}
2020-08-14 11:26:30.785 [pool-2-thread-1] INFO  com.kafka.demo.clients.KafkaConsumerService - 消费到消息:{"data":"测试消息5","id":"1"}
2020-08-14 11:26:30.785 [pool-2-thread-1] INFO  com.kafka.demo.clients.KafkaConsumerService - 消费到消息:{"data":"测试消息6","id":"1"}
2020-08-14 11:26:30.785 [pool-2-thread-1] INFO  com.kafka.demo.clients.KafkaConsumerService - 消费到消息:{"data":"测试消息7","id":"1"}
2020-08-14 11:26:30.785 [pool-2-thread-1] INFO  com.kafka.demo.clients.KafkaConsumerService - 消费到消息:{"data":"测试消息8","id":"1"}
2020-08-14 11:26:30.785 [pool-2-thread-1] INFO  com.kafka.demo.clients.KafkaConsumerService - 消费到消息:{"data":"测试消息9","id":"1"}
2020-08-14 11:26:32.880 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group2-3, groupId=topic.group2] Revoke previously assigned partitions topic.test-2
2020-08-14 11:26:32.881 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-4, groupId=topic.group2] Member consumer-topic.group2-4-2996e1c5-4452-47ed-b1c2-83ac611e5c32 sending LeaveGroup request to coordinator ops-basic03.lingda.com:6667 (id: 2147483645 rack: null) due to the consumer unsubscribed from all topics
2020-08-14 11:26:32.880 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group2-2, groupId=topic.group2] Revoke previously assigned partitions topic.test-1
2020-08-14 11:26:32.881 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group1-6, groupId=topic.group1] Revoke previously assigned partitions topic.test-1
2020-08-14 11:26:32.880 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group2-1, groupId=topic.group2] Revoke previously assigned partitions topic.test-0
2020-08-14 11:26:32.881 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - topic.group2: partitions revoked: [topic.test-2]
2020-08-14 11:26:32.881 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - topic.group2: partitions revoked: [topic.test-0]
2020-08-14 11:26:32.881 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - topic.group2: partitions revoked: [topic.test-1]
2020-08-14 11:26:32.881 [org.springframework.kafka.KafkaListenerEndpointContainer#1-1-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group1-7, groupId=topic.group1] Revoke previously assigned partitions topic.test-2
2020-08-14 11:26:32.881 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-5, groupId=topic.group2] Member consumer-topic.group2-5-e03bb439-29fb-403d-9b73-3319711aff05 sending LeaveGroup request to coordinator ops-basic03.lingda.com:6667 (id: 2147483645 rack: null) due to the consumer unsubscribed from all topics
2020-08-14 11:26:32.881 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - topic.group1: partitions revoked: [topic.test-1]
2020-08-14 11:26:32.881 [org.springframework.kafka.KafkaListenerEndpointContainer#1-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-8, groupId=topic.group1] Member consumer-topic.group1-8-7a6de9da-43b8-4288-9246-c3f19bf6fff7 sending LeaveGroup request to coordinator ops-basic02.lingda.com:6667 (id: 2147483646 rack: null) due to the consumer unsubscribed from all topics
2020-08-14 11:26:32.881 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-6, groupId=topic.group1] Member consumer-topic.group1-6-06256d66-945d-43c6-adbf-96e26cfaee96 sending LeaveGroup request to coordinator ops-basic02.lingda.com:6667 (id: 2147483646 rack: null) due to the consumer unsubscribed from all topics
2020-08-14 11:26:32.881 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-3, groupId=topic.group2] Member consumer-topic.group2-3-75c50203-082f-4570-b272-2bdbf890c8d6 sending LeaveGroup request to coordinator ops-basic03.lingda.com:6667 (id: 2147483645 rack: null) due to the consumer unsubscribed from all topics
2020-08-14 11:26:32.881 [org.springframework.kafka.KafkaListenerEndpointContainer#1-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-9, groupId=topic.group1] Member consumer-topic.group1-9-1ee26c1c-7ae8-4401-975d-23d73d1f64f6 sending LeaveGroup request to coordinator ops-basic02.lingda.com:6667 (id: 2147483646 rack: null) due to the consumer unsubscribed from all topics
2020-08-14 11:26:32.881 [org.springframework.kafka.KafkaListenerEndpointContainer#1-2-C-1] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group1-8, groupId=topic.group1] Unsubscribed all topics or patterns and assigned partitions
2020-08-14 11:26:32.881 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group1-6, groupId=topic.group1] Unsubscribed all topics or patterns and assigned partitions
2020-08-14 11:26:32.881 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-1, groupId=topic.group2] Member consumer-topic.group2-1-56a4f027-a287-4984-ab1c-cb08143fe564 sending LeaveGroup request to coordinator ops-basic03.lingda.com:6667 (id: 2147483645 rack: null) due to the consumer unsubscribed from all topics
2020-08-14 11:26:32.881 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-2, groupId=topic.group2] Member consumer-topic.group2-2-82ee6dc2-e748-4067-9a48-8c5afdfee31e sending LeaveGroup request to coordinator ops-basic03.lingda.com:6667 (id: 2147483645 rack: null) due to the consumer unsubscribed from all topics
2020-08-14 11:26:32.881 [org.springframework.kafka.KafkaListenerEndpointContainer#1-1-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - topic.group1: partitions revoked: [topic.test-2]
2020-08-14 11:26:32.882 [org.springframework.kafka.KafkaListenerEndpointContainer#1-2-C-1] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Shutting down ExecutorService
2020-08-14 11:26:32.881 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group2-4, groupId=topic.group2] Unsubscribed all topics or patterns and assigned partitions
2020-08-14 11:26:32.881 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group2-5, groupId=topic.group2] Unsubscribed all topics or patterns and assigned partitions
2020-08-14 11:26:32.881 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group2-3, groupId=topic.group2] Unsubscribed all topics or patterns and assigned partitions
2020-08-14 11:26:32.882 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group2-1, groupId=topic.group2] Unsubscribed all topics or patterns and assigned partitions
2020-08-14 11:26:32.882 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group2-2, groupId=topic.group2] Unsubscribed all topics or patterns and assigned partitions
2020-08-14 11:26:32.881 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group1-10, groupId=topic.group1] Revoke previously assigned partitions topic.test-0
2020-08-14 11:26:32.881 [org.springframework.kafka.KafkaListenerEndpointContainer#1-3-C-1] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group1-9, groupId=topic.group1] Unsubscribed all topics or patterns and assigned partitions
2020-08-14 11:26:32.882 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Shutting down ExecutorService
2020-08-14 11:26:32.882 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - topic.group1: partitions revoked: [topic.test-0]
2020-08-14 11:26:32.882 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Shutting down ExecutorService
2020-08-14 11:26:32.882 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-10, groupId=topic.group1] Member consumer-topic.group1-10-fa2485db-9ad3-4ec2-aa2c-21386de5b369 sending LeaveGroup request to coordinator ops-basic02.lingda.com:6667 (id: 2147483646 rack: null) due to the consumer unsubscribed from all topics
2020-08-14 11:26:32.882 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Shutting down ExecutorService
2020-08-14 11:26:32.882 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Shutting down ExecutorService
2020-08-14 11:26:32.882 [org.springframework.kafka.KafkaListenerEndpointContainer#1-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-7, groupId=topic.group1] Member consumer-topic.group1-7-a813c7de-b38e-4d63-8050-94a8ba540741 sending LeaveGroup request to coordinator ops-basic02.lingda.com:6667 (id: 2147483646 rack: null) due to the consumer unsubscribed from all topics
2020-08-14 11:26:32.882 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Shutting down ExecutorService
2020-08-14 11:26:32.883 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group1-10, groupId=topic.group1] Unsubscribed all topics or patterns and assigned partitions
2020-08-14 11:26:32.882 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Shutting down ExecutorService
2020-08-14 11:26:32.882 [org.springframework.kafka.KafkaListenerEndpointContainer#1-3-C-1] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Shutting down ExecutorService
2020-08-14 11:26:32.883 [org.springframework.kafka.KafkaListenerEndpointContainer#1-1-C-1] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group1-7, groupId=topic.group1] Unsubscribed all topics or patterns and assigned partitions
2020-08-14 11:26:32.883 [org.springframework.kafka.KafkaListenerEndpointContainer#1-1-C-1] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Shutting down ExecutorService
2020-08-14 11:26:32.883 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Shutting down ExecutorService
2020-08-14 11:26:32.902 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - topic.group2: Consumer stopped
2020-08-14 11:26:32.902 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - topic.group2: Consumer stopped
2020-08-14 11:26:32.904 [org.springframework.kafka.KafkaListenerEndpointContainer#1-3-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - topic.group1: Consumer stopped
2020-08-14 11:26:32.907 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - topic.group2: Consumer stopped
2020-08-14 11:26:32.908 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - topic.group1: Consumer stopped
2020-08-14 11:26:32.908 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - topic.group2: Consumer stopped
2020-08-14 11:26:32.908 [org.springframework.kafka.KafkaListenerEndpointContainer#1-1-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - topic.group1: Consumer stopped
2020-08-14 11:26:32.909 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - topic.group2: Consumer stopped
2020-08-14 11:26:32.909 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - topic.group1: Consumer stopped
2020-08-14 11:26:32.909 [org.springframework.kafka.KafkaListenerEndpointContainer#1-2-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - topic.group1: Consumer stopped
2020-08-14 11:26:32.911 [SpringContextShutdownHook] INFO  o.s.scheduling.concurrent.ThreadPoolTaskExecutor - Shutting down ExecutorService 'applicationTaskExecutor'
2020-08-14 11:40:43.987 [main] INFO  com.kafka.demo.test.KafkaProducerSerTest - Starting KafkaProducerSerTest on LAPTOP-NFQDMTR9 with PID 16136 (started by sq in E:\otherProjects\kafkaDemo)
2020-08-14 11:40:43.989 [main] INFO  com.kafka.demo.test.KafkaProducerSerTest - No active profile set, falling back to default profiles: default
2020-08-14 11:40:45.108 [main] INFO  com.kafka.demo.clients.KafkaProducerSevice - 初始化:producer
2020-08-14 11:40:50.728 [main] INFO  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [192.168.100.213:6667, 192.168.100.214:6667, 192.168.100.215:6667]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 500
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2020-08-14 11:40:51.159 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.5.0
2020-08-14 11:40:51.160 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 66563e712b0b9f84
2020-08-14 11:40:51.161 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1597376451157
2020-08-14 11:40:51.642 [main] INFO  o.s.scheduling.concurrent.ThreadPoolTaskExecutor - Initializing ExecutorService 'applicationTaskExecutor'
2020-08-14 11:40:52.281 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [192.168.100.213:6667, 192.168.100.214:6667, 192.168.100.215:6667]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = topic.group1
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 100
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-08-14 11:40:52.326 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.5.0
2020-08-14 11:40:52.327 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 66563e712b0b9f84
2020-08-14 11:40:52.327 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1597376452326
2020-08-14 11:40:52.329 [main] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group1-1, groupId=topic.group1] Subscribed to topic(s): topic.test
2020-08-14 11:40:52.331 [main] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Initializing ExecutorService
2020-08-14 11:40:52.339 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [192.168.100.213:6667, 192.168.100.214:6667, 192.168.100.215:6667]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = topic.group1
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 100
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-08-14 11:40:52.351 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.5.0
2020-08-14 11:40:52.351 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 66563e712b0b9f84
2020-08-14 11:40:52.351 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1597376452350
2020-08-14 11:40:52.352 [main] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group1-2, groupId=topic.group1] Subscribed to topic(s): topic.test
2020-08-14 11:40:52.352 [main] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Initializing ExecutorService
2020-08-14 11:40:52.355 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [192.168.100.213:6667, 192.168.100.214:6667, 192.168.100.215:6667]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = topic.group1
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 100
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-08-14 11:40:52.371 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.5.0
2020-08-14 11:40:52.371 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 66563e712b0b9f84
2020-08-14 11:40:52.371 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1597376452371
2020-08-14 11:40:52.372 [main] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group1-3, groupId=topic.group1] Subscribed to topic(s): topic.test
2020-08-14 11:40:52.372 [main] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Initializing ExecutorService
2020-08-14 11:40:52.375 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [192.168.100.213:6667, 192.168.100.214:6667, 192.168.100.215:6667]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = topic.group1
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 100
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-08-14 11:40:52.384 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.5.0
2020-08-14 11:40:52.384 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 66563e712b0b9f84
2020-08-14 11:40:52.384 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1597376452384
2020-08-14 11:40:52.385 [main] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group1-4, groupId=topic.group1] Subscribed to topic(s): topic.test
2020-08-14 11:40:52.385 [main] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Initializing ExecutorService
2020-08-14 11:40:52.387 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [192.168.100.213:6667, 192.168.100.214:6667, 192.168.100.215:6667]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = topic.group1
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 100
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-08-14 11:40:52.395 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.5.0
2020-08-14 11:40:52.395 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 66563e712b0b9f84
2020-08-14 11:40:52.395 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1597376452395
2020-08-14 11:40:52.396 [main] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group1-5, groupId=topic.group1] Subscribed to topic(s): topic.test
2020-08-14 11:40:52.396 [main] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Initializing ExecutorService
2020-08-14 11:40:52.398 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [192.168.100.213:6667, 192.168.100.214:6667, 192.168.100.215:6667]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = topic.group2
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 100
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-08-14 11:40:52.410 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.5.0
2020-08-14 11:40:52.410 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 66563e712b0b9f84
2020-08-14 11:40:52.410 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1597376452410
2020-08-14 11:40:52.410 [main] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group2-6, groupId=topic.group2] Subscribed to topic(s): topic.test
2020-08-14 11:40:52.411 [main] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Initializing ExecutorService
2020-08-14 11:40:52.413 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [192.168.100.213:6667, 192.168.100.214:6667, 192.168.100.215:6667]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = topic.group2
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 100
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-08-14 11:40:52.419 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.5.0
2020-08-14 11:40:52.419 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 66563e712b0b9f84
2020-08-14 11:40:52.420 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1597376452419
2020-08-14 11:40:52.420 [main] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group2-7, groupId=topic.group2] Subscribed to topic(s): topic.test
2020-08-14 11:40:52.420 [main] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Initializing ExecutorService
2020-08-14 11:40:52.423 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [192.168.100.213:6667, 192.168.100.214:6667, 192.168.100.215:6667]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = topic.group2
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 100
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-08-14 11:40:52.429 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.5.0
2020-08-14 11:40:52.430 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 66563e712b0b9f84
2020-08-14 11:40:52.430 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1597376452429
2020-08-14 11:40:52.430 [main] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group2-8, groupId=topic.group2] Subscribed to topic(s): topic.test
2020-08-14 11:40:52.431 [main] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Initializing ExecutorService
2020-08-14 11:40:52.432 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [192.168.100.213:6667, 192.168.100.214:6667, 192.168.100.215:6667]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = topic.group2
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 100
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-08-14 11:40:52.440 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.5.0
2020-08-14 11:40:52.440 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 66563e712b0b9f84
2020-08-14 11:40:52.441 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1597376452440
2020-08-14 11:40:52.441 [main] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group2-9, groupId=topic.group2] Subscribed to topic(s): topic.test
2020-08-14 11:40:52.441 [main] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Initializing ExecutorService
2020-08-14 11:40:52.443 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [192.168.100.213:6667, 192.168.100.214:6667, 192.168.100.215:6667]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = topic.group2
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 100
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-08-14 11:40:52.449 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.5.0
2020-08-14 11:40:52.450 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 66563e712b0b9f84
2020-08-14 11:40:52.450 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1597376452449
2020-08-14 11:40:52.450 [main] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group2-10, groupId=topic.group2] Subscribed to topic(s): topic.test
2020-08-14 11:40:52.450 [main] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Initializing ExecutorService
2020-08-14 11:40:52.463 [main] INFO  com.kafka.demo.test.KafkaProducerSerTest - Started KafkaProducerSerTest in 9.237 seconds (JVM running for 10.557)
2020-08-14 11:40:52.468 [pool-2-thread-1] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [192.168.100.213:6667, 192.168.100.214:6667, 192.168.100.215:6667]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = new
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 100
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-08-14 11:40:52.478 [pool-2-thread-1] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.5.0
2020-08-14 11:40:52.478 [pool-2-thread-1] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 66563e712b0b9f84
2020-08-14 11:40:52.479 [pool-2-thread-1] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1597376452478
2020-08-14 11:40:52.480 [pool-2-thread-1] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-new-11, groupId=new] Subscribed to topic(s): test_kafka_service
2020-08-14 11:40:52.854 [org.springframework.kafka.KafkaListenerEndpointContainer#1-2-C-1] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-topic.group2-8, groupId=topic.group2] Cluster ID: JcD5Rmr-Rmu4LUPRR7vWMw
2020-08-14 11:40:52.854 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-topic.group2-6, groupId=topic.group2] Cluster ID: JcD5Rmr-Rmu4LUPRR7vWMw
2020-08-14 11:40:52.855 [pool-2-thread-1] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-new-11, groupId=new] Cluster ID: JcD5Rmr-Rmu4LUPRR7vWMw
2020-08-14 11:40:52.854 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-topic.group2-10, groupId=topic.group2] Cluster ID: JcD5Rmr-Rmu4LUPRR7vWMw
2020-08-14 11:40:52.854 [org.springframework.kafka.KafkaListenerEndpointContainer#1-3-C-1] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-topic.group2-9, groupId=topic.group2] Cluster ID: JcD5Rmr-Rmu4LUPRR7vWMw
2020-08-14 11:40:52.854 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-topic.group1-2, groupId=topic.group1] Cluster ID: JcD5Rmr-Rmu4LUPRR7vWMw
2020-08-14 11:40:52.855 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-topic.group1-1, groupId=topic.group1] Cluster ID: JcD5Rmr-Rmu4LUPRR7vWMw
2020-08-14 11:40:52.856 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-topic.group1-5, groupId=topic.group1] Cluster ID: JcD5Rmr-Rmu4LUPRR7vWMw
2020-08-14 11:40:52.857 [org.springframework.kafka.KafkaListenerEndpointContainer#1-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-8, groupId=topic.group2] Discovered group coordinator ops-basic03.lingda.com:6667 (id: 2147483645 rack: null)
2020-08-14 11:40:52.857 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-10, groupId=topic.group2] Discovered group coordinator ops-basic03.lingda.com:6667 (id: 2147483645 rack: null)
2020-08-14 11:40:52.857 [pool-2-thread-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-new-11, groupId=new] Discovered group coordinator ops-basic03.lingda.com:6667 (id: 2147483645 rack: null)
2020-08-14 11:40:52.857 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-2, groupId=topic.group1] Discovered group coordinator ops-basic02.lingda.com:6667 (id: 2147483646 rack: null)
2020-08-14 11:40:52.857 [org.springframework.kafka.KafkaListenerEndpointContainer#1-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-9, groupId=topic.group2] Discovered group coordinator ops-basic03.lingda.com:6667 (id: 2147483645 rack: null)
2020-08-14 11:40:52.857 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-5, groupId=topic.group1] Discovered group coordinator ops-basic02.lingda.com:6667 (id: 2147483646 rack: null)
2020-08-14 11:40:52.858 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-1, groupId=topic.group1] Discovered group coordinator ops-basic02.lingda.com:6667 (id: 2147483646 rack: null)
2020-08-14 11:40:52.861 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-10, groupId=topic.group2] (Re-)joining group
2020-08-14 11:40:52.861 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-2, groupId=topic.group1] (Re-)joining group
2020-08-14 11:40:52.861 [org.springframework.kafka.KafkaListenerEndpointContainer#1-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-9, groupId=topic.group2] (Re-)joining group
2020-08-14 11:40:52.862 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-5, groupId=topic.group1] (Re-)joining group
2020-08-14 11:40:52.862 [org.springframework.kafka.KafkaListenerEndpointContainer#1-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-8, groupId=topic.group2] (Re-)joining group
2020-08-14 11:40:52.863 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-1, groupId=topic.group1] (Re-)joining group
2020-08-14 11:40:52.861 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-6, groupId=topic.group2] Discovered group coordinator ops-basic03.lingda.com:6667 (id: 2147483645 rack: null)
2020-08-14 11:40:52.862 [pool-2-thread-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-new-11, groupId=new] (Re-)joining group
2020-08-14 11:40:52.866 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-6, groupId=topic.group2] (Re-)joining group
2020-08-14 11:40:52.885 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group1-1, groupId=topic.group1] Finished assignment for group at generation 1: {consumer-topic.group1-1-ef589b1c-f3ef-479e-94a0-db15e57f3448=Assignment(partitions=[topic.test-0]), consumer-topic.group1-2-02a18042-073c-4d08-aa9a-7ef37bb89129=Assignment(partitions=[topic.test-1]), consumer-topic.group1-5-5d68b642-f230-4de9-88af-323b0dcaeab2=Assignment(partitions=[topic.test-2])}
2020-08-14 11:40:52.887 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group2-6, groupId=topic.group2] Finished assignment for group at generation 1: {consumer-topic.group2-6-dba37054-81c2-4883-843c-1d0264a042f4=Assignment(partitions=[topic.test-0, topic.test-1, topic.test-2])}
2020-08-14 11:40:52.887 [pool-2-thread-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-new-11, groupId=new] Finished assignment for group at generation 3: {consumer-new-11-cc6e1175-be7d-4ad4-b843-52167943d8b6=Assignment(partitions=[test_kafka_service-0, test_kafka_service-1, test_kafka_service-2])}
2020-08-14 11:40:52.889 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-6, groupId=topic.group2] Join group failed with org.apache.kafka.common.errors.RebalanceInProgressException: The group is rebalancing, so a rejoin is needed.
2020-08-14 11:40:52.889 [pool-2-thread-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-new-11, groupId=new] Successfully joined group with generation 3
2020-08-14 11:40:52.889 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-6, groupId=topic.group2] (Re-)joining group
2020-08-14 11:40:52.891 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group2-6, groupId=topic.group2] Finished assignment for group at generation 2: {consumer-topic.group2-9-91de815f-87ce-4624-8e29-909270bd1c0a=Assignment(partitions=[]), consumer-topic.group2-6-dba37054-81c2-4883-843c-1d0264a042f4=Assignment(partitions=[topic.test-1]), consumer-topic.group2-10-3c888485-f46c-4aca-9973-519106ba9911=Assignment(partitions=[topic.test-0]), consumer-topic.group2-8-49da83f6-2e9b-45f3-b6a5-644e8212fa1f=Assignment(partitions=[topic.test-2])}
2020-08-14 11:40:52.894 [org.springframework.kafka.KafkaListenerEndpointContainer#1-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-8, groupId=topic.group2] Successfully joined group with generation 2
2020-08-14 11:40:52.894 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-10, groupId=topic.group2] Successfully joined group with generation 2
2020-08-14 11:40:52.894 [org.springframework.kafka.KafkaListenerEndpointContainer#1-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-9, groupId=topic.group2] Successfully joined group with generation 2
2020-08-14 11:40:52.894 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-6, groupId=topic.group2] Successfully joined group with generation 2
2020-08-14 11:40:52.896 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-2, groupId=topic.group1] Successfully joined group with generation 1
2020-08-14 11:40:52.896 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-1, groupId=topic.group1] Successfully joined group with generation 1
2020-08-14 11:40:52.896 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-5, groupId=topic.group1] Successfully joined group with generation 1
2020-08-14 11:40:52.897 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group1-1, groupId=topic.group1] Adding newly assigned partitions: topic.test-0
2020-08-14 11:40:52.897 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group1-5, groupId=topic.group1] Adding newly assigned partitions: topic.test-2
2020-08-14 11:40:52.897 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group1-2, groupId=topic.group1] Adding newly assigned partitions: topic.test-1
2020-08-14 11:40:52.897 [org.springframework.kafka.KafkaListenerEndpointContainer#1-2-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group2-8, groupId=topic.group2] Adding newly assigned partitions: topic.test-2
2020-08-14 11:40:52.897 [pool-2-thread-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-new-11, groupId=new] Adding newly assigned partitions: test_kafka_service-0, test_kafka_service-2, test_kafka_service-1
2020-08-14 11:40:52.897 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group2-10, groupId=topic.group2] Adding newly assigned partitions: topic.test-0
2020-08-14 11:40:52.902 [org.springframework.kafka.KafkaListenerEndpointContainer#1-3-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group2-9, groupId=topic.group2] Adding newly assigned partitions: 
2020-08-14 11:40:52.902 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group2-6, groupId=topic.group2] Adding newly assigned partitions: topic.test-1
2020-08-14 11:40:52.903 [org.springframework.kafka.KafkaListenerEndpointContainer#1-3-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - topic.group2: partitions assigned: []
2020-08-14 11:40:52.909 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group1-2, groupId=topic.group1] Found no committed offset for partition topic.test-1
2020-08-14 11:40:52.909 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group2-10, groupId=topic.group2] Found no committed offset for partition topic.test-0
2020-08-14 11:40:52.909 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group2-6, groupId=topic.group2] Found no committed offset for partition topic.test-1
2020-08-14 11:40:52.909 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group1-1, groupId=topic.group1] Found no committed offset for partition topic.test-0
2020-08-14 11:40:52.909 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group1-5, groupId=topic.group1] Found no committed offset for partition topic.test-2
2020-08-14 11:40:52.909 [org.springframework.kafka.KafkaListenerEndpointContainer#1-2-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group2-8, groupId=topic.group2] Found no committed offset for partition topic.test-2
2020-08-14 11:40:52.909 [pool-2-thread-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-new-11, groupId=new] Found no committed offset for partition test_kafka_service-1
2020-08-14 11:40:52.912 [pool-2-thread-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-new-11, groupId=new] Setting offset for partition test_kafka_service-2 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[ops-basic02.lingda.com:6667 (id: 1 rack: null)], epoch=absent}}
2020-08-14 11:40:52.913 [pool-2-thread-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-new-11, groupId=new] Setting offset for partition test_kafka_service-0 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[ops-basic03.lingda.com:6667 (id: 2 rack: null)], epoch=absent}}
2020-08-14 11:40:52.923 [org.springframework.kafka.KafkaListenerEndpointContainer#1-2-C-1] INFO  o.a.k.clients.consumer.internals.SubscriptionState - [Consumer clientId=consumer-topic.group2-8, groupId=topic.group2] Resetting offset for partition topic.test-2 to offset 1.
2020-08-14 11:40:52.923 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.a.k.clients.consumer.internals.SubscriptionState - [Consumer clientId=consumer-topic.group1-2, groupId=topic.group1] Resetting offset for partition topic.test-1 to offset 0.
2020-08-14 11:40:52.923 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.a.k.clients.consumer.internals.SubscriptionState - [Consumer clientId=consumer-topic.group2-6, groupId=topic.group2] Resetting offset for partition topic.test-1 to offset 0.
2020-08-14 11:40:52.923 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  o.a.k.clients.consumer.internals.SubscriptionState - [Consumer clientId=consumer-topic.group1-5, groupId=topic.group1] Resetting offset for partition topic.test-2 to offset 1.
2020-08-14 11:40:52.924 [org.springframework.kafka.KafkaListenerEndpointContainer#1-2-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - topic.group2: partitions assigned: [topic.test-2]
2020-08-14 11:40:52.924 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - topic.group2: partitions assigned: [topic.test-1]
2020-08-14 11:40:52.924 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - topic.group1: partitions assigned: [topic.test-2]
2020-08-14 11:40:52.924 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - topic.group1: partitions assigned: [topic.test-1]
2020-08-14 11:41:12.328 [kafka-producer-network-thread | producer-1] INFO  org.apache.kafka.clients.Metadata - [Producer clientId=producer-1] Cluster ID: JcD5Rmr-Rmu4LUPRR7vWMw
2020-08-14 11:41:13.671 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-3, groupId=topic.group1] Discovered group coordinator ops-basic02.lingda.com:6667 (id: 2147483646 rack: null)
2020-08-14 11:41:13.672 [org.springframework.kafka.KafkaListenerEndpointContainer#1-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-7, groupId=topic.group2] Discovered group coordinator ops-basic03.lingda.com:6667 (id: 2147483645 rack: null)
2020-08-14 11:41:13.674 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-3, groupId=topic.group1] (Re-)joining group
2020-08-14 11:41:13.674 [org.springframework.kafka.KafkaListenerEndpointContainer#1-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-7, groupId=topic.group2] (Re-)joining group
2020-08-14 11:41:13.764 [org.springframework.kafka.KafkaListenerEndpointContainer#1-1-C-1] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-topic.group2-7, groupId=topic.group2] Cluster ID: JcD5Rmr-Rmu4LUPRR7vWMw
2020-08-14 11:41:13.764 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-topic.group1-3, groupId=topic.group1] Cluster ID: JcD5Rmr-Rmu4LUPRR7vWMw
2020-08-14 11:41:14.142 [org.springframework.kafka.KafkaListenerEndpointContainer#1-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-9, groupId=topic.group2] Attempt to heartbeat failed since group is rebalancing
2020-08-14 11:41:14.143 [org.springframework.kafka.KafkaListenerEndpointContainer#1-3-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group2-9, groupId=topic.group2] Revoke previously assigned partitions 
2020-08-14 11:41:14.144 [org.springframework.kafka.KafkaListenerEndpointContainer#1-3-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - topic.group2: partitions revoked: []
2020-08-14 11:41:14.144 [org.springframework.kafka.KafkaListenerEndpointContainer#1-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-9, groupId=topic.group2] (Re-)joining group
2020-08-14 11:41:14.157 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-5, groupId=topic.group1] Attempt to heartbeat failed since group is rebalancing
2020-08-14 11:41:14.157 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-6, groupId=topic.group2] Attempt to heartbeat failed since group is rebalancing
2020-08-14 11:41:14.157 [org.springframework.kafka.KafkaListenerEndpointContainer#1-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-8, groupId=topic.group2] Attempt to heartbeat failed since group is rebalancing
2020-08-14 11:41:14.157 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group1-5, groupId=topic.group1] Revoke previously assigned partitions topic.test-2
2020-08-14 11:41:14.157 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group2-6, groupId=topic.group2] Revoke previously assigned partitions topic.test-1
2020-08-14 11:41:14.157 [org.springframework.kafka.KafkaListenerEndpointContainer#1-2-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group2-8, groupId=topic.group2] Revoke previously assigned partitions topic.test-2
2020-08-14 11:41:14.158 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - topic.group1: partitions revoked: [topic.test-2]
2020-08-14 11:41:14.158 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - topic.group2: partitions revoked: [topic.test-1]
2020-08-14 11:41:14.158 [org.springframework.kafka.KafkaListenerEndpointContainer#1-2-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - topic.group2: partitions revoked: [topic.test-2]
2020-08-14 11:41:14.158 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-5, groupId=topic.group1] (Re-)joining group
2020-08-14 11:41:14.158 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-6, groupId=topic.group2] (Re-)joining group
2020-08-14 11:41:14.158 [org.springframework.kafka.KafkaListenerEndpointContainer#1-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-8, groupId=topic.group2] (Re-)joining group
2020-08-14 11:41:14.159 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-2, groupId=topic.group1] Attempt to heartbeat failed since group is rebalancing
2020-08-14 11:41:14.160 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group1-2, groupId=topic.group1] Revoke previously assigned partitions topic.test-1
2020-08-14 11:41:14.160 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - topic.group1: partitions revoked: [topic.test-1]
2020-08-14 11:41:14.160 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-2, groupId=topic.group1] (Re-)joining group
2020-08-14 11:41:15.046 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-10, groupId=topic.group2] Attempt to heartbeat failed since group is rebalancing
2020-08-14 11:41:15.142 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-1, groupId=topic.group1] Attempt to heartbeat failed since group is rebalancing
2020-08-14 11:41:15.406 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group1-1, groupId=topic.group1] Revoke previously assigned partitions topic.test-0
2020-08-14 11:41:15.406 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-2, groupId=topic.group1] Member consumer-topic.group1-2-02a18042-073c-4d08-aa9a-7ef37bb89129 sending LeaveGroup request to coordinator ops-basic02.lingda.com:6667 (id: 2147483646 rack: null) due to the consumer unsubscribed from all topics
2020-08-14 11:41:15.406 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - topic.group1: partitions revoked: [topic.test-0]
2020-08-14 11:41:15.406 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-1, groupId=topic.group1] Member consumer-topic.group1-1-ef589b1c-f3ef-479e-94a0-db15e57f3448 sending LeaveGroup request to coordinator ops-basic02.lingda.com:6667 (id: 2147483646 rack: null) due to the consumer unsubscribed from all topics
2020-08-14 11:41:15.406 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group1-3, groupId=topic.group1] Unsubscribed all topics or patterns and assigned partitions
2020-08-14 11:41:15.407 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Shutting down ExecutorService
2020-08-14 11:41:15.407 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group1-1, groupId=topic.group1] Unsubscribed all topics or patterns and assigned partitions
2020-08-14 11:41:15.407 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group1-2, groupId=topic.group1] Unsubscribed all topics or patterns and assigned partitions
2020-08-14 11:41:15.407 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Shutting down ExecutorService
2020-08-14 11:41:15.407 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Shutting down ExecutorService
2020-08-14 11:41:15.408 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group1-4, groupId=topic.group1] Unsubscribed all topics or patterns and assigned partitions
2020-08-14 11:41:15.408 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Shutting down ExecutorService
2020-08-14 11:41:15.408 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-5, groupId=topic.group1] Member consumer-topic.group1-5-5d68b642-f230-4de9-88af-323b0dcaeab2 sending LeaveGroup request to coordinator ops-basic02.lingda.com:6667 (id: 2147483646 rack: null) due to the consumer unsubscribed from all topics
2020-08-14 11:41:15.408 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group1-5, groupId=topic.group1] Unsubscribed all topics or patterns and assigned partitions
2020-08-14 11:41:15.408 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-6, groupId=topic.group2] Member consumer-topic.group2-6-dba37054-81c2-4883-843c-1d0264a042f4 sending LeaveGroup request to coordinator ops-basic03.lingda.com:6667 (id: 2147483645 rack: null) due to the consumer unsubscribed from all topics
2020-08-14 11:41:15.408 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Shutting down ExecutorService
2020-08-14 11:41:15.408 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group2-6, groupId=topic.group2] Unsubscribed all topics or patterns and assigned partitions
2020-08-14 11:41:15.409 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Shutting down ExecutorService
2020-08-14 11:41:15.409 [org.springframework.kafka.KafkaListenerEndpointContainer#1-1-C-1] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group2-7, groupId=topic.group2] Unsubscribed all topics or patterns and assigned partitions
2020-08-14 11:41:15.409 [org.springframework.kafka.KafkaListenerEndpointContainer#1-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-9, groupId=topic.group2] Member consumer-topic.group2-9-91de815f-87ce-4624-8e29-909270bd1c0a sending LeaveGroup request to coordinator ops-basic03.lingda.com:6667 (id: 2147483645 rack: null) due to the consumer unsubscribed from all topics
2020-08-14 11:41:15.409 [org.springframework.kafka.KafkaListenerEndpointContainer#1-1-C-1] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Shutting down ExecutorService
2020-08-14 11:41:15.409 [org.springframework.kafka.KafkaListenerEndpointContainer#1-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-8, groupId=topic.group2] Member consumer-topic.group2-8-49da83f6-2e9b-45f3-b6a5-644e8212fa1f sending LeaveGroup request to coordinator ops-basic03.lingda.com:6667 (id: 2147483645 rack: null) due to the consumer unsubscribed from all topics
2020-08-14 11:41:15.409 [org.springframework.kafka.KafkaListenerEndpointContainer#1-3-C-1] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group2-9, groupId=topic.group2] Unsubscribed all topics or patterns and assigned partitions
2020-08-14 11:41:15.409 [org.springframework.kafka.KafkaListenerEndpointContainer#1-3-C-1] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Shutting down ExecutorService
2020-08-14 11:41:15.409 [org.springframework.kafka.KafkaListenerEndpointContainer#1-2-C-1] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group2-8, groupId=topic.group2] Unsubscribed all topics or patterns and assigned partitions
2020-08-14 11:41:15.409 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group2-10, groupId=topic.group2] Revoke previously assigned partitions topic.test-0
2020-08-14 11:41:15.410 [org.springframework.kafka.KafkaListenerEndpointContainer#1-2-C-1] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Shutting down ExecutorService
2020-08-14 11:41:15.410 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - topic.group2: partitions revoked: [topic.test-0]
2020-08-14 11:41:15.410 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-10, groupId=topic.group2] Member consumer-topic.group2-10-3c888485-f46c-4aca-9973-519106ba9911 sending LeaveGroup request to coordinator ops-basic03.lingda.com:6667 (id: 2147483645 rack: null) due to the consumer unsubscribed from all topics
2020-08-14 11:41:15.410 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group2-10, groupId=topic.group2] Unsubscribed all topics or patterns and assigned partitions
2020-08-14 11:41:15.411 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Shutting down ExecutorService
2020-08-14 11:41:15.412 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - topic.group1: Consumer stopped
2020-08-14 11:41:15.443 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - topic.group2: Consumer stopped
2020-08-14 11:41:15.446 [org.springframework.kafka.KafkaListenerEndpointContainer#1-2-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - topic.group2: Consumer stopped
2020-08-14 11:41:15.448 [org.springframework.kafka.KafkaListenerEndpointContainer#1-1-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - topic.group2: Consumer stopped
2020-08-14 11:41:15.450 [org.springframework.kafka.KafkaListenerEndpointContainer#1-3-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - topic.group2: Consumer stopped
2020-08-14 11:41:15.451 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - topic.group1: Consumer stopped
2020-08-14 11:41:15.452 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - topic.group2: Consumer stopped
2020-08-14 11:41:15.452 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - topic.group1: Consumer stopped
2020-08-14 11:41:15.453 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - topic.group1: Consumer stopped
2020-08-14 11:41:15.454 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - topic.group1: Consumer stopped
2020-08-14 11:41:15.455 [SpringContextShutdownHook] INFO  o.s.scheduling.concurrent.ThreadPoolTaskExecutor - Shutting down ExecutorService 'applicationTaskExecutor'
2020-08-14 11:42:49.315 [main] INFO  com.kafka.demo.test.KafkaProducerSerTest - Starting KafkaProducerSerTest on LAPTOP-NFQDMTR9 with PID 20108 (started by sq in E:\otherProjects\kafkaDemo)
2020-08-14 11:42:49.318 [main] INFO  com.kafka.demo.test.KafkaProducerSerTest - No active profile set, falling back to default profiles: default
2020-08-14 11:42:50.422 [main] INFO  com.kafka.demo.clients.KafkaProducerSevice - 初始化:producer
2020-08-14 11:42:50.455 [main] INFO  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [192.168.100.213:6667, 192.168.100.214:6667, 192.168.100.215:6667]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 500
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2020-08-14 11:42:51.012 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.5.0
2020-08-14 11:42:51.014 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 66563e712b0b9f84
2020-08-14 11:42:51.014 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1597376571009
2020-08-14 11:42:51.551 [main] INFO  o.s.scheduling.concurrent.ThreadPoolTaskExecutor - Initializing ExecutorService 'applicationTaskExecutor'
2020-08-14 11:42:52.196 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [192.168.100.213:6667, 192.168.100.214:6667, 192.168.100.215:6667]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = topic.group2
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 100
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-08-14 11:42:52.248 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.5.0
2020-08-14 11:42:52.248 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 66563e712b0b9f84
2020-08-14 11:42:52.248 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1597376572247
2020-08-14 11:42:52.251 [main] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group2-1, groupId=topic.group2] Subscribed to topic(s): topic.test
2020-08-14 11:42:52.254 [main] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Initializing ExecutorService
2020-08-14 11:42:52.262 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [192.168.100.213:6667, 192.168.100.214:6667, 192.168.100.215:6667]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = topic.group2
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 100
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-08-14 11:42:52.273 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.5.0
2020-08-14 11:42:52.273 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 66563e712b0b9f84
2020-08-14 11:42:52.273 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1597376572273
2020-08-14 11:42:52.274 [main] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group2-2, groupId=topic.group2] Subscribed to topic(s): topic.test
2020-08-14 11:42:52.274 [main] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Initializing ExecutorService
2020-08-14 11:42:52.275 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [192.168.100.213:6667, 192.168.100.214:6667, 192.168.100.215:6667]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = topic.group2
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 100
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-08-14 11:42:52.289 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.5.0
2020-08-14 11:42:52.289 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 66563e712b0b9f84
2020-08-14 11:42:52.289 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1597376572289
2020-08-14 11:42:52.290 [main] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group2-3, groupId=topic.group2] Subscribed to topic(s): topic.test
2020-08-14 11:42:52.290 [main] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Initializing ExecutorService
2020-08-14 11:42:52.292 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [192.168.100.213:6667, 192.168.100.214:6667, 192.168.100.215:6667]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = topic.group2
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 100
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-08-14 11:42:52.299 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.5.0
2020-08-14 11:42:52.299 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 66563e712b0b9f84
2020-08-14 11:42:52.299 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1597376572299
2020-08-14 11:42:52.300 [main] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group2-4, groupId=topic.group2] Subscribed to topic(s): topic.test
2020-08-14 11:42:52.300 [main] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Initializing ExecutorService
2020-08-14 11:42:52.302 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [192.168.100.213:6667, 192.168.100.214:6667, 192.168.100.215:6667]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = topic.group2
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 100
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-08-14 11:42:52.310 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.5.0
2020-08-14 11:42:52.310 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 66563e712b0b9f84
2020-08-14 11:42:52.310 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1597376572310
2020-08-14 11:42:52.311 [main] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group2-5, groupId=topic.group2] Subscribed to topic(s): topic.test
2020-08-14 11:42:52.311 [main] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Initializing ExecutorService
2020-08-14 11:42:52.313 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [192.168.100.213:6667, 192.168.100.214:6667, 192.168.100.215:6667]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = topic.group1
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 100
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-08-14 11:42:52.323 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.5.0
2020-08-14 11:42:52.323 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 66563e712b0b9f84
2020-08-14 11:42:52.324 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1597376572323
2020-08-14 11:42:52.324 [main] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group1-6, groupId=topic.group1] Subscribed to topic(s): topic.test
2020-08-14 11:42:52.325 [main] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Initializing ExecutorService
2020-08-14 11:42:52.327 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [192.168.100.213:6667, 192.168.100.214:6667, 192.168.100.215:6667]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = topic.group1
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 100
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-08-14 11:42:52.335 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.5.0
2020-08-14 11:42:52.335 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 66563e712b0b9f84
2020-08-14 11:42:52.335 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1597376572335
2020-08-14 11:42:52.335 [main] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group1-7, groupId=topic.group1] Subscribed to topic(s): topic.test
2020-08-14 11:42:52.336 [main] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Initializing ExecutorService
2020-08-14 11:42:52.338 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [192.168.100.213:6667, 192.168.100.214:6667, 192.168.100.215:6667]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = topic.group1
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 100
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-08-14 11:42:52.348 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.5.0
2020-08-14 11:42:52.348 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 66563e712b0b9f84
2020-08-14 11:42:52.349 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1597376572348
2020-08-14 11:42:52.349 [main] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group1-8, groupId=topic.group1] Subscribed to topic(s): topic.test
2020-08-14 11:42:52.349 [main] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Initializing ExecutorService
2020-08-14 11:42:52.352 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [192.168.100.213:6667, 192.168.100.214:6667, 192.168.100.215:6667]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = topic.group1
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 100
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-08-14 11:42:52.366 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.5.0
2020-08-14 11:42:52.367 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 66563e712b0b9f84
2020-08-14 11:42:52.367 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1597376572366
2020-08-14 11:42:52.367 [main] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group1-9, groupId=topic.group1] Subscribed to topic(s): topic.test
2020-08-14 11:42:52.368 [main] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Initializing ExecutorService
2020-08-14 11:42:52.370 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [192.168.100.213:6667, 192.168.100.214:6667, 192.168.100.215:6667]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = topic.group1
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 100
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-08-14 11:42:52.379 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.5.0
2020-08-14 11:42:52.380 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 66563e712b0b9f84
2020-08-14 11:42:52.380 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1597376572379
2020-08-14 11:42:52.380 [main] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group1-10, groupId=topic.group1] Subscribed to topic(s): topic.test
2020-08-14 11:42:52.380 [main] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Initializing ExecutorService
2020-08-14 11:42:52.394 [main] INFO  com.kafka.demo.test.KafkaProducerSerTest - Started KafkaProducerSerTest in 3.96 seconds (JVM running for 5.257)
2020-08-14 11:42:52.398 [pool-2-thread-1] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [192.168.100.213:6667, 192.168.100.214:6667, 192.168.100.215:6667]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = new
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 100
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-08-14 11:42:52.418 [pool-2-thread-1] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.5.0
2020-08-14 11:42:52.419 [pool-2-thread-1] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 66563e712b0b9f84
2020-08-14 11:42:52.419 [pool-2-thread-1] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1597376572418
2020-08-14 11:42:52.420 [pool-2-thread-1] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-new-11, groupId=new] Subscribed to topic(s): test_kafka_service
2020-08-14 11:42:52.804 [pool-2-thread-1] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-new-11, groupId=new] Cluster ID: JcD5Rmr-Rmu4LUPRR7vWMw
2020-08-14 11:42:52.805 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-topic.group2-3, groupId=topic.group2] Cluster ID: JcD5Rmr-Rmu4LUPRR7vWMw
2020-08-14 11:42:52.804 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-topic.group2-5, groupId=topic.group2] Cluster ID: JcD5Rmr-Rmu4LUPRR7vWMw
2020-08-14 11:42:52.806 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-topic.group1-10, groupId=topic.group1] Cluster ID: JcD5Rmr-Rmu4LUPRR7vWMw
2020-08-14 11:42:52.804 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-topic.group2-1, groupId=topic.group2] Cluster ID: JcD5Rmr-Rmu4LUPRR7vWMw
2020-08-14 11:42:52.808 [pool-2-thread-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-new-11, groupId=new] Discovered group coordinator ops-basic03.lingda.com:6667 (id: 2147483645 rack: null)
2020-08-14 11:42:52.809 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-10, groupId=topic.group1] Discovered group coordinator ops-basic02.lingda.com:6667 (id: 2147483646 rack: null)
2020-08-14 11:42:52.809 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-5, groupId=topic.group2] Discovered group coordinator ops-basic03.lingda.com:6667 (id: 2147483645 rack: null)
2020-08-14 11:42:52.810 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-3, groupId=topic.group2] Discovered group coordinator ops-basic03.lingda.com:6667 (id: 2147483645 rack: null)
2020-08-14 11:42:52.809 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-1, groupId=topic.group2] Discovered group coordinator ops-basic03.lingda.com:6667 (id: 2147483645 rack: null)
2020-08-14 11:42:52.813 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-5, groupId=topic.group2] (Re-)joining group
2020-08-14 11:42:52.814 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-topic.group1-6, groupId=topic.group1] Cluster ID: JcD5Rmr-Rmu4LUPRR7vWMw
2020-08-14 11:42:52.814 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-10, groupId=topic.group1] (Re-)joining group
2020-08-14 11:42:52.815 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-6, groupId=topic.group1] Discovered group coordinator ops-basic02.lingda.com:6667 (id: 2147483646 rack: null)
2020-08-14 11:42:52.815 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-topic.group2-4, groupId=topic.group2] Cluster ID: JcD5Rmr-Rmu4LUPRR7vWMw
2020-08-14 11:42:52.816 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-4, groupId=topic.group2] Discovered group coordinator ops-basic03.lingda.com:6667 (id: 2147483645 rack: null)
2020-08-14 11:42:52.816 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-6, groupId=topic.group1] (Re-)joining group
2020-08-14 11:42:52.817 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-4, groupId=topic.group2] (Re-)joining group
2020-08-14 11:42:52.817 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-1, groupId=topic.group2] (Re-)joining group
2020-08-14 11:42:52.817 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-3, groupId=topic.group2] (Re-)joining group
2020-08-14 11:42:52.818 [pool-2-thread-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-new-11, groupId=new] (Re-)joining group
2020-08-14 11:42:52.835 [pool-2-thread-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-new-11, groupId=new] Finished assignment for group at generation 5: {consumer-new-11-a14793f4-f7ec-4826-af5e-a937cabbb57f=Assignment(partitions=[test_kafka_service-0, test_kafka_service-1, test_kafka_service-2])}
2020-08-14 11:42:52.835 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group2-4, groupId=topic.group2] Finished assignment for group at generation 5: {consumer-topic.group2-4-21499007-96e3-45f9-a1f9-fab82fd1e8bf=Assignment(partitions=[topic.test-0, topic.test-1, topic.test-2])}
2020-08-14 11:42:52.835 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group1-10, groupId=topic.group1] Finished assignment for group at generation 4: {consumer-topic.group1-10-02fbd766-2d98-402f-a7ca-a6422b46edee=Assignment(partitions=[topic.test-0, topic.test-1, topic.test-2])}
2020-08-14 11:42:52.839 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-10, groupId=topic.group1] Join group failed with org.apache.kafka.common.errors.RebalanceInProgressException: The group is rebalancing, so a rejoin is needed.
2020-08-14 11:42:52.840 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-10, groupId=topic.group1] (Re-)joining group
2020-08-14 11:42:52.840 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-4, groupId=topic.group2] Join group failed with org.apache.kafka.common.errors.RebalanceInProgressException: The group is rebalancing, so a rejoin is needed.
2020-08-14 11:42:52.840 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-4, groupId=topic.group2] (Re-)joining group
2020-08-14 11:42:52.842 [pool-2-thread-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-new-11, groupId=new] Successfully joined group with generation 5
2020-08-14 11:42:52.842 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group1-10, groupId=topic.group1] Finished assignment for group at generation 5: {consumer-topic.group1-6-1578279e-a985-4a45-9340-32ed782e886b=Assignment(partitions=[topic.test-2]), consumer-topic.group1-10-02fbd766-2d98-402f-a7ca-a6422b46edee=Assignment(partitions=[topic.test-0, topic.test-1])}
2020-08-14 11:42:52.843 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group2-4, groupId=topic.group2] Finished assignment for group at generation 6: {consumer-topic.group2-1-7479dd3f-9626-4632-bf38-22cef6b787ef=Assignment(partitions=[topic.test-0]), consumer-topic.group2-3-18821aa4-ec12-4e67-873c-9e054568465a=Assignment(partitions=[topic.test-1]), consumer-topic.group2-4-21499007-96e3-45f9-a1f9-fab82fd1e8bf=Assignment(partitions=[topic.test-2]), consumer-topic.group2-5-45dcae35-0659-44c3-8b53-2eaf7353165c=Assignment(partitions=[])}
2020-08-14 11:42:52.846 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-1, groupId=topic.group2] Successfully joined group with generation 6
2020-08-14 11:42:52.847 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-4, groupId=topic.group2] Successfully joined group with generation 6
2020-08-14 11:42:52.847 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-5, groupId=topic.group2] Successfully joined group with generation 6
2020-08-14 11:42:52.847 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group2-5, groupId=topic.group2] Adding newly assigned partitions: 
2020-08-14 11:42:52.848 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - topic.group2: partitions assigned: []
2020-08-14 11:42:52.848 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-3, groupId=topic.group2] Successfully joined group with generation 6
2020-08-14 11:42:52.851 [pool-2-thread-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-new-11, groupId=new] Adding newly assigned partitions: test_kafka_service-0, test_kafka_service-2, test_kafka_service-1
2020-08-14 11:42:52.851 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group2-4, groupId=topic.group2] Adding newly assigned partitions: topic.test-2
2020-08-14 11:42:52.851 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group2-1, groupId=topic.group2] Adding newly assigned partitions: topic.test-0
2020-08-14 11:42:52.855 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group2-3, groupId=topic.group2] Adding newly assigned partitions: topic.test-1
2020-08-14 11:42:52.858 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-10, groupId=topic.group1] Successfully joined group with generation 5
2020-08-14 11:42:52.859 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group1-10, groupId=topic.group1] Adding newly assigned partitions: topic.test-0, topic.test-1
2020-08-14 11:42:52.859 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-6, groupId=topic.group1] Successfully joined group with generation 5
2020-08-14 11:42:52.859 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group1-6, groupId=topic.group1] Adding newly assigned partitions: topic.test-2
2020-08-14 11:42:52.860 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group2-3, groupId=topic.group2] Found no committed offset for partition topic.test-1
2020-08-14 11:42:52.861 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group2-4, groupId=topic.group2] Found no committed offset for partition topic.test-2
2020-08-14 11:42:52.861 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group2-1, groupId=topic.group2] Found no committed offset for partition topic.test-0
2020-08-14 11:42:52.862 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group1-6, groupId=topic.group1] Found no committed offset for partition topic.test-2
2020-08-14 11:42:52.879 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group1-10, groupId=topic.group1] Found no committed offset for partition topic.test-0
2020-08-14 11:42:52.879 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group1-10, groupId=topic.group1] Found no committed offset for partition topic.test-1
2020-08-14 11:42:52.897 [pool-2-thread-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-new-11, groupId=new] Found no committed offset for partition test_kafka_service-1
2020-08-14 11:42:52.906 [pool-2-thread-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-new-11, groupId=new] Setting offset for partition test_kafka_service-2 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[ops-basic02.lingda.com:6667 (id: 1 rack: null)], epoch=absent}}
2020-08-14 11:42:52.906 [pool-2-thread-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-new-11, groupId=new] Setting offset for partition test_kafka_service-0 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[ops-basic03.lingda.com:6667 (id: 2 rack: null)], epoch=absent}}
2020-08-14 11:42:52.907 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.a.k.clients.consumer.internals.SubscriptionState - [Consumer clientId=consumer-topic.group1-10, groupId=topic.group1] Resetting offset for partition topic.test-1 to offset 0.
2020-08-14 11:42:52.908 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.a.k.clients.consumer.internals.SubscriptionState - [Consumer clientId=consumer-topic.group1-6, groupId=topic.group1] Resetting offset for partition topic.test-2 to offset 1.
2020-08-14 11:42:52.909 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - topic.group1: partitions assigned: [topic.test-2]
2020-08-14 11:42:52.947 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  o.a.k.clients.consumer.internals.SubscriptionState - [Consumer clientId=consumer-topic.group2-3, groupId=topic.group2] Resetting offset for partition topic.test-1 to offset 0.
2020-08-14 11:42:52.947 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.a.k.clients.consumer.internals.SubscriptionState - [Consumer clientId=consumer-topic.group2-4, groupId=topic.group2] Resetting offset for partition topic.test-2 to offset 1.
2020-08-14 11:42:52.947 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - topic.group2: partitions assigned: [topic.test-2]
2020-08-14 11:42:52.947 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - topic.group2: partitions assigned: [topic.test-1]
2020-08-14 11:43:12.182 [kafka-producer-network-thread | producer-1] INFO  org.apache.kafka.clients.Metadata - [Producer clientId=producer-1] Cluster ID: JcD5Rmr-Rmu4LUPRR7vWMw
2020-08-14 11:43:12.729 [pool-2-thread-1] INFO  com.kafka.demo.clients.KafkaConsumerService - 消费到消息:{"data":"测试消息0","id":"1"},消息所在分区:0
2020-08-14 11:43:12.729 [pool-2-thread-1] INFO  com.kafka.demo.clients.KafkaConsumerService - 消费到消息:{"data":"测试消息1","id":"1"},消息所在分区:0
2020-08-14 11:43:12.729 [pool-2-thread-1] INFO  com.kafka.demo.clients.KafkaConsumerService - 消费到消息:{"data":"测试消息2","id":"1"},消息所在分区:0
2020-08-14 11:43:12.729 [pool-2-thread-1] INFO  com.kafka.demo.clients.KafkaConsumerService - 消费到消息:{"data":"测试消息3","id":"1"},消息所在分区:0
2020-08-14 11:43:12.729 [pool-2-thread-1] INFO  com.kafka.demo.clients.KafkaConsumerService - 消费到消息:{"data":"测试消息4","id":"1"},消息所在分区:0
2020-08-14 11:43:12.729 [pool-2-thread-1] INFO  com.kafka.demo.clients.KafkaConsumerService - 消费到消息:{"data":"测试消息5","id":"1"},消息所在分区:0
2020-08-14 11:43:12.729 [pool-2-thread-1] INFO  com.kafka.demo.clients.KafkaConsumerService - 消费到消息:{"data":"测试消息6","id":"1"},消息所在分区:0
2020-08-14 11:43:12.729 [pool-2-thread-1] INFO  com.kafka.demo.clients.KafkaConsumerService - 消费到消息:{"data":"测试消息7","id":"1"},消息所在分区:0
2020-08-14 11:43:12.729 [pool-2-thread-1] INFO  com.kafka.demo.clients.KafkaConsumerService - 消费到消息:{"data":"测试消息8","id":"1"},消息所在分区:0
2020-08-14 11:43:12.729 [pool-2-thread-1] INFO  com.kafka.demo.clients.KafkaConsumerService - 消费到消息:{"data":"测试消息9","id":"1"},消息所在分区:0
2020-08-14 11:43:13.645 [org.springframework.kafka.KafkaListenerEndpointContainer#1-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-9, groupId=topic.group1] Discovered group coordinator ops-basic02.lingda.com:6667 (id: 2147483646 rack: null)
2020-08-14 11:43:13.645 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-2, groupId=topic.group2] Discovered group coordinator ops-basic03.lingda.com:6667 (id: 2147483645 rack: null)
2020-08-14 11:43:13.645 [org.springframework.kafka.KafkaListenerEndpointContainer#1-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-8, groupId=topic.group1] Discovered group coordinator ops-basic02.lingda.com:6667 (id: 2147483646 rack: null)
2020-08-14 11:43:13.645 [org.springframework.kafka.KafkaListenerEndpointContainer#1-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-7, groupId=topic.group1] Discovered group coordinator ops-basic02.lingda.com:6667 (id: 2147483646 rack: null)
2020-08-14 11:43:13.646 [org.springframework.kafka.KafkaListenerEndpointContainer#1-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-8, groupId=topic.group1] (Re-)joining group
2020-08-14 11:43:13.647 [org.springframework.kafka.KafkaListenerEndpointContainer#1-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-7, groupId=topic.group1] (Re-)joining group
2020-08-14 11:43:13.646 [org.springframework.kafka.KafkaListenerEndpointContainer#1-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-9, groupId=topic.group1] (Re-)joining group
2020-08-14 11:43:13.646 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-2, groupId=topic.group2] (Re-)joining group
2020-08-14 11:43:13.738 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-topic.group2-2, groupId=topic.group2] Cluster ID: JcD5Rmr-Rmu4LUPRR7vWMw
2020-08-14 11:43:13.738 [org.springframework.kafka.KafkaListenerEndpointContainer#1-2-C-1] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-topic.group1-8, groupId=topic.group1] Cluster ID: JcD5Rmr-Rmu4LUPRR7vWMw
2020-08-14 11:43:13.739 [org.springframework.kafka.KafkaListenerEndpointContainer#1-1-C-1] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-topic.group1-7, groupId=topic.group1] Cluster ID: JcD5Rmr-Rmu4LUPRR7vWMw
2020-08-14 11:43:13.743 [org.springframework.kafka.KafkaListenerEndpointContainer#1-3-C-1] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-topic.group1-9, groupId=topic.group1] Cluster ID: JcD5Rmr-Rmu4LUPRR7vWMw
2020-08-14 11:43:13.899 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-5, groupId=topic.group2] Attempt to heartbeat failed since group is rebalancing
2020-08-14 11:43:13.899 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-4, groupId=topic.group2] Attempt to heartbeat failed since group is rebalancing
2020-08-14 11:43:13.901 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group2-4, groupId=topic.group2] Revoke previously assigned partitions topic.test-2
2020-08-14 11:43:13.901 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group2-5, groupId=topic.group2] Revoke previously assigned partitions 
2020-08-14 11:43:13.902 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - topic.group2: partitions revoked: []
2020-08-14 11:43:13.902 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - topic.group2: partitions revoked: [topic.test-2]
2020-08-14 11:43:13.902 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-5, groupId=topic.group2] (Re-)joining group
2020-08-14 11:43:13.903 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-4, groupId=topic.group2] (Re-)joining group
2020-08-14 11:43:13.913 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-6, groupId=topic.group1] Attempt to heartbeat failed since group is rebalancing
2020-08-14 11:43:13.914 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group1-6, groupId=topic.group1] Revoke previously assigned partitions topic.test-2
2020-08-14 11:43:13.915 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - topic.group1: partitions revoked: [topic.test-2]
2020-08-14 11:43:13.915 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-6, groupId=topic.group1] (Re-)joining group
2020-08-14 11:43:13.916 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-3, groupId=topic.group2] Attempt to heartbeat failed since group is rebalancing
2020-08-14 11:43:13.917 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group2-3, groupId=topic.group2] Revoke previously assigned partitions topic.test-1
2020-08-14 11:43:13.917 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - topic.group2: partitions revoked: [topic.test-1]
2020-08-14 11:43:13.918 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-3, groupId=topic.group2] (Re-)joining group
2020-08-14 11:43:14.290 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-1, groupId=topic.group2] Attempt to heartbeat failed since group is rebalancing
2020-08-14 11:43:14.627 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-10, groupId=topic.group1] Attempt to heartbeat failed since group is rebalancing
2020-08-14 11:43:15.375 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group2-1, groupId=topic.group2] Revoke previously assigned partitions topic.test-0
2020-08-14 11:43:15.375 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - topic.group2: partitions revoked: [topic.test-0]
2020-08-14 11:43:15.376 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-1, groupId=topic.group2] Member consumer-topic.group2-1-7479dd3f-9626-4632-bf38-22cef6b787ef sending LeaveGroup request to coordinator ops-basic03.lingda.com:6667 (id: 2147483645 rack: null) due to the consumer unsubscribed from all topics
2020-08-14 11:43:15.377 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group2-1, groupId=topic.group2] Unsubscribed all topics or patterns and assigned partitions
2020-08-14 11:43:15.377 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Shutting down ExecutorService
2020-08-14 11:43:15.379 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-3, groupId=topic.group2] Member consumer-topic.group2-3-18821aa4-ec12-4e67-873c-9e054568465a sending LeaveGroup request to coordinator ops-basic03.lingda.com:6667 (id: 2147483645 rack: null) due to the consumer unsubscribed from all topics
2020-08-14 11:43:15.379 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group2-3, groupId=topic.group2] Unsubscribed all topics or patterns and assigned partitions
2020-08-14 11:43:15.379 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Shutting down ExecutorService
2020-08-14 11:43:15.380 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-4, groupId=topic.group2] Member consumer-topic.group2-4-21499007-96e3-45f9-a1f9-fab82fd1e8bf sending LeaveGroup request to coordinator ops-basic03.lingda.com:6667 (id: 2147483645 rack: null) due to the consumer unsubscribed from all topics
2020-08-14 11:43:15.380 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-5, groupId=topic.group2] Member consumer-topic.group2-5-45dcae35-0659-44c3-8b53-2eaf7353165c sending LeaveGroup request to coordinator ops-basic03.lingda.com:6667 (id: 2147483645 rack: null) due to the consumer unsubscribed from all topics
2020-08-14 11:43:15.380 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group2-4, groupId=topic.group2] Unsubscribed all topics or patterns and assigned partitions
2020-08-14 11:43:15.380 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group2-5, groupId=topic.group2] Unsubscribed all topics or patterns and assigned partitions
2020-08-14 11:43:15.380 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Shutting down ExecutorService
2020-08-14 11:43:15.380 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Shutting down ExecutorService
2020-08-14 11:43:15.380 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-6, groupId=topic.group1] Member consumer-topic.group1-6-1578279e-a985-4a45-9340-32ed782e886b sending LeaveGroup request to coordinator ops-basic02.lingda.com:6667 (id: 2147483646 rack: null) due to the consumer unsubscribed from all topics
2020-08-14 11:43:15.381 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group2-2, groupId=topic.group2] Unsubscribed all topics or patterns and assigned partitions
2020-08-14 11:43:15.381 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Shutting down ExecutorService
2020-08-14 11:43:15.381 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group1-10, groupId=topic.group1] Revoke previously assigned partitions topic.test-0, topic.test-1
2020-08-14 11:43:15.381 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group1-6, groupId=topic.group1] Unsubscribed all topics or patterns and assigned partitions
2020-08-14 11:43:15.381 [org.springframework.kafka.KafkaListenerEndpointContainer#1-1-C-1] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group1-7, groupId=topic.group1] Unsubscribed all topics or patterns and assigned partitions
2020-08-14 11:43:15.381 [org.springframework.kafka.KafkaListenerEndpointContainer#1-3-C-1] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group1-9, groupId=topic.group1] Unsubscribed all topics or patterns and assigned partitions
2020-08-14 11:43:15.381 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Shutting down ExecutorService
2020-08-14 11:43:15.381 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - topic.group1: partitions revoked: [topic.test-0, topic.test-1]
2020-08-14 11:43:15.382 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-10, groupId=topic.group1] Member consumer-topic.group1-10-02fbd766-2d98-402f-a7ca-a6422b46edee sending LeaveGroup request to coordinator ops-basic02.lingda.com:6667 (id: 2147483646 rack: null) due to the consumer unsubscribed from all topics
2020-08-14 11:43:15.382 [org.springframework.kafka.KafkaListenerEndpointContainer#1-3-C-1] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Shutting down ExecutorService
2020-08-14 11:43:15.382 [org.springframework.kafka.KafkaListenerEndpointContainer#1-1-C-1] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Shutting down ExecutorService
2020-08-14 11:43:15.383 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group1-10, groupId=topic.group1] Unsubscribed all topics or patterns and assigned partitions
2020-08-14 11:43:15.386 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Shutting down ExecutorService
2020-08-14 11:43:15.384 [org.springframework.kafka.KafkaListenerEndpointContainer#1-2-C-1] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group1-8, groupId=topic.group1] Unsubscribed all topics or patterns and assigned partitions
2020-08-14 11:43:15.386 [org.springframework.kafka.KafkaListenerEndpointContainer#1-2-C-1] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Shutting down ExecutorService
2020-08-14 11:43:15.403 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - topic.group2: Consumer stopped
2020-08-14 11:43:15.407 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - topic.group2: Consumer stopped
2020-08-14 11:43:15.409 [org.springframework.kafka.KafkaListenerEndpointContainer#1-1-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - topic.group1: Consumer stopped
2020-08-14 11:43:15.409 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - topic.group1: Consumer stopped
2020-08-14 11:43:15.414 [org.springframework.kafka.KafkaListenerEndpointContainer#1-2-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - topic.group1: Consumer stopped
2020-08-14 11:43:15.414 [org.springframework.kafka.KafkaListenerEndpointContainer#1-3-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - topic.group1: Consumer stopped
2020-08-14 11:43:15.417 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - topic.group1: Consumer stopped
2020-08-14 11:43:15.417 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - topic.group2: Consumer stopped
2020-08-14 11:43:15.416 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - topic.group2: Consumer stopped
2020-08-14 11:43:15.417 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - topic.group2: Consumer stopped
2020-08-14 11:43:15.421 [SpringContextShutdownHook] INFO  o.s.scheduling.concurrent.ThreadPoolTaskExecutor - Shutting down ExecutorService 'applicationTaskExecutor'
2020-08-14 13:31:14.829 [main] INFO  com.kafka.demo.test.KafkaProducerSerTest - Starting KafkaProducerSerTest on LAPTOP-NFQDMTR9 with PID 13744 (started by sq in E:\otherProjects\kafkaDemo)
2020-08-14 13:31:14.830 [main] INFO  com.kafka.demo.test.KafkaProducerSerTest - No active profile set, falling back to default profiles: default
2020-08-14 13:31:15.964 [main] INFO  com.kafka.demo.clients.KafkaProducerSevice - 初始化:producer
2020-08-14 13:31:16.033 [main] INFO  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [192.168.100.213:6667, 192.168.100.214:6667, 192.168.100.215:6667]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 500
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2020-08-14 13:31:16.649 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.5.0
2020-08-14 13:31:16.651 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 66563e712b0b9f84
2020-08-14 13:31:16.652 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1597383076647
2020-08-14 13:31:16.812 [main] INFO  org.apache.kafka.clients.admin.AdminClientConfig - AdminClientConfig values: 
	bootstrap.servers = [127.0.0.1:9092]
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2020-08-14 13:31:17.138 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.5.0
2020-08-14 13:31:17.139 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 66563e712b0b9f84
2020-08-14 13:31:17.139 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1597383077138
2020-08-14 13:31:17.655 [main] INFO  o.s.scheduling.concurrent.ThreadPoolTaskExecutor - Initializing ExecutorService 'applicationTaskExecutor'
2020-08-14 13:31:18.206 [main] INFO  org.apache.kafka.clients.admin.AdminClientConfig - AdminClientConfig values: 
	bootstrap.servers = [127.0.0.1:9092]
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2020-08-14 13:31:18.214 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.5.0
2020-08-14 13:31:18.214 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 66563e712b0b9f84
2020-08-14 13:31:18.214 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1597383078214
2020-08-14 13:31:38.105 [kafka-producer-network-thread | producer-1] INFO  org.apache.kafka.clients.Metadata - [Producer clientId=producer-1] Cluster ID: JcD5Rmr-Rmu4LUPRR7vWMw
2020-08-14 13:32:53.924 [main] INFO  com.kafka.demo.test.KafkaProducerSerTest - Starting KafkaProducerSerTest on LAPTOP-NFQDMTR9 with PID 20156 (started by sq in E:\otherProjects\kafkaDemo)
2020-08-14 13:32:53.926 [main] INFO  com.kafka.demo.test.KafkaProducerSerTest - No active profile set, falling back to default profiles: default
2020-08-14 13:32:55.011 [main] INFO  com.kafka.demo.clients.KafkaProducerSevice - 初始化:producer
2020-08-14 13:32:55.044 [main] INFO  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [192.168.100.213:6667, 192.168.100.214:6667, 192.168.100.215:6667]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 500
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2020-08-14 13:32:55.543 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.5.0
2020-08-14 13:32:55.546 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 66563e712b0b9f84
2020-08-14 13:32:55.546 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1597383175542
2020-08-14 13:32:55.587 [main] INFO  org.apache.kafka.clients.admin.AdminClientConfig - AdminClientConfig values: 
	bootstrap.servers = [192.168.100.213:6667, 192.168.100.214:6667, 192.168.100.215:6667]
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2020-08-14 13:32:55.617 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.5.0
2020-08-14 13:32:55.617 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 66563e712b0b9f84
2020-08-14 13:32:55.617 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1597383175617
2020-08-14 13:32:56.043 [kafka-producer-network-thread | producer-1] INFO  org.apache.kafka.clients.Metadata - [Producer clientId=producer-1] Cluster ID: JcD5Rmr-Rmu4LUPRR7vWMw
2020-08-14 13:32:56.264 [main] INFO  o.s.scheduling.concurrent.ThreadPoolTaskExecutor - Initializing ExecutorService 'applicationTaskExecutor'
2020-08-14 13:32:56.721 [main] INFO  org.apache.kafka.clients.admin.AdminClientConfig - AdminClientConfig values: 
	bootstrap.servers = [192.168.100.213:6667, 192.168.100.214:6667, 192.168.100.215:6667]
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2020-08-14 13:32:56.726 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.5.0
2020-08-14 13:32:56.726 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 66563e712b0b9f84
2020-08-14 13:32:56.727 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1597383176726
2020-08-14 13:33:57.819 [kafka-admin-client-thread | adminclient-2] INFO  org.apache.kafka.clients.admin.KafkaAdminClient - [AdminClient clientId=adminclient-2] Forcing a hard I/O thread shutdown. Requests in progress will be aborted.
2020-08-14 13:33:57.946 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [192.168.100.213:6667, 192.168.100.214:6667, 192.168.100.215:6667]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = topic.group1
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 100
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-08-14 13:33:58.003 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.5.0
2020-08-14 13:33:58.004 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 66563e712b0b9f84
2020-08-14 13:33:58.004 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1597383238003
2020-08-14 13:33:58.006 [main] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group1-1, groupId=topic.group1] Subscribed to topic(s): topic.test
2020-08-14 13:33:58.010 [main] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Initializing ExecutorService
2020-08-14 13:33:58.020 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [192.168.100.213:6667, 192.168.100.214:6667, 192.168.100.215:6667]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = topic.group1
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 100
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-08-14 13:33:58.032 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.5.0
2020-08-14 13:33:58.033 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 66563e712b0b9f84
2020-08-14 13:33:58.033 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1597383238032
2020-08-14 13:33:58.033 [main] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group1-2, groupId=topic.group1] Subscribed to topic(s): topic.test
2020-08-14 13:33:58.034 [main] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Initializing ExecutorService
2020-08-14 13:33:58.037 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [192.168.100.213:6667, 192.168.100.214:6667, 192.168.100.215:6667]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = topic.group1
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 100
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-08-14 13:33:58.050 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-topic.group1-1, groupId=topic.group1] Cluster ID: JcD5Rmr-Rmu4LUPRR7vWMw
2020-08-14 13:33:58.051 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-1, groupId=topic.group1] Discovered group coordinator ops-basic02.lingda.com:6667 (id: 2147483646 rack: null)
2020-08-14 13:33:58.055 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.5.0
2020-08-14 13:33:58.055 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 66563e712b0b9f84
2020-08-14 13:33:58.055 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1597383238055
2020-08-14 13:33:58.056 [main] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group1-3, groupId=topic.group1] Subscribed to topic(s): topic.test
2020-08-14 13:33:58.056 [main] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Initializing ExecutorService
2020-08-14 13:33:58.060 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-1, groupId=topic.group1] (Re-)joining group
2020-08-14 13:33:58.059 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [192.168.100.213:6667, 192.168.100.214:6667, 192.168.100.215:6667]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = topic.group1
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 100
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-08-14 13:33:58.078 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.5.0
2020-08-14 13:33:58.078 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 66563e712b0b9f84
2020-08-14 13:33:58.079 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1597383238078
2020-08-14 13:33:58.079 [main] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group1-4, groupId=topic.group1] Subscribed to topic(s): topic.test
2020-08-14 13:33:58.079 [main] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Initializing ExecutorService
2020-08-14 13:33:58.081 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group1-1, groupId=topic.group1] Finished assignment for group at generation 1: {consumer-topic.group1-1-d1d0d08b-d8d9-4f52-bc23-3ae3ea1a71c8=Assignment(partitions=[topic.test-0, topic.test-1, topic.test-2])}
2020-08-14 13:33:58.082 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [192.168.100.213:6667, 192.168.100.214:6667, 192.168.100.215:6667]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = topic.group1
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 100
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-08-14 13:33:58.094 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-topic.group1-4, groupId=topic.group1] Cluster ID: JcD5Rmr-Rmu4LUPRR7vWMw
2020-08-14 13:33:58.095 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-4, groupId=topic.group1] Discovered group coordinator ops-basic02.lingda.com:6667 (id: 2147483646 rack: null)
2020-08-14 13:33:58.097 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-4, groupId=topic.group1] (Re-)joining group
2020-08-14 13:33:58.097 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-1, groupId=topic.group1] Successfully joined group with generation 1
2020-08-14 13:33:58.105 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.5.0
2020-08-14 13:33:58.106 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group1-1, groupId=topic.group1] Adding newly assigned partitions: topic.test-0, topic.test-1, topic.test-2
2020-08-14 13:33:58.106 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 66563e712b0b9f84
2020-08-14 13:33:58.106 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1597383238105
2020-08-14 13:33:58.106 [main] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group1-5, groupId=topic.group1] Subscribed to topic(s): topic.test
2020-08-14 13:33:58.107 [main] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Initializing ExecutorService
2020-08-14 13:33:58.110 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [192.168.100.213:6667, 192.168.100.214:6667, 192.168.100.215:6667]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = topic.group2
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 100
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-08-14 13:33:58.119 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-topic.group1-5, groupId=topic.group1] Cluster ID: JcD5Rmr-Rmu4LUPRR7vWMw
2020-08-14 13:33:58.120 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-5, groupId=topic.group1] Discovered group coordinator ops-basic02.lingda.com:6667 (id: 2147483646 rack: null)
2020-08-14 13:33:58.120 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group1-1, groupId=topic.group1] Found no committed offset for partition topic.test-0
2020-08-14 13:33:58.120 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group1-1, groupId=topic.group1] Found no committed offset for partition topic.test-1
2020-08-14 13:33:58.120 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group1-1, groupId=topic.group1] Found no committed offset for partition topic.test-2
2020-08-14 13:33:58.122 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-5, groupId=topic.group1] (Re-)joining group
2020-08-14 13:33:58.133 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.5.0
2020-08-14 13:33:58.133 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 66563e712b0b9f84
2020-08-14 13:33:58.133 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1597383238133
2020-08-14 13:33:58.134 [main] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group2-6, groupId=topic.group2] Subscribed to topic(s): topic.test
2020-08-14 13:33:58.134 [main] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Initializing ExecutorService
2020-08-14 13:33:58.139 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [192.168.100.213:6667, 192.168.100.214:6667, 192.168.100.215:6667]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = topic.group2
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 100
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-08-14 13:33:58.144 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.clients.consumer.internals.SubscriptionState - [Consumer clientId=consumer-topic.group1-1, groupId=topic.group1] Resetting offset for partition topic.test-2 to offset 1.
2020-08-14 13:33:58.146 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.clients.consumer.internals.SubscriptionState - [Consumer clientId=consumer-topic.group1-1, groupId=topic.group1] Resetting offset for partition topic.test-1 to offset 0.
2020-08-14 13:33:58.150 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-topic.group2-6, groupId=topic.group2] Cluster ID: JcD5Rmr-Rmu4LUPRR7vWMw
2020-08-14 13:33:58.151 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.5.0
2020-08-14 13:33:58.151 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-6, groupId=topic.group2] Discovered group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null)
2020-08-14 13:33:58.151 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 66563e712b0b9f84
2020-08-14 13:33:58.151 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1597383238151
2020-08-14 13:33:58.151 [main] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group2-7, groupId=topic.group2] Subscribed to topic(s): topic.test
2020-08-14 13:33:58.151 [main] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Initializing ExecutorService
2020-08-14 13:33:58.154 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-6, groupId=topic.group2] (Re-)joining group
2020-08-14 13:33:58.157 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [192.168.100.213:6667, 192.168.100.214:6667, 192.168.100.215:6667]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = topic.group2
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 100
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-08-14 13:33:58.165 [org.springframework.kafka.KafkaListenerEndpointContainer#1-1-C-1] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-topic.group2-7, groupId=topic.group2] Cluster ID: JcD5Rmr-Rmu4LUPRR7vWMw
2020-08-14 13:33:58.165 [org.springframework.kafka.KafkaListenerEndpointContainer#1-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-7, groupId=topic.group2] Discovered group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null)
2020-08-14 13:33:58.167 [org.springframework.kafka.KafkaListenerEndpointContainer#1-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-7, groupId=topic.group2] (Re-)joining group
2020-08-14 13:33:58.170 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.5.0
2020-08-14 13:33:58.170 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 66563e712b0b9f84
2020-08-14 13:33:58.170 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1597383238170
2020-08-14 13:33:58.171 [main] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group2-8, groupId=topic.group2] Subscribed to topic(s): topic.test
2020-08-14 13:33:58.171 [main] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Initializing ExecutorService
2020-08-14 13:33:58.173 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [192.168.100.213:6667, 192.168.100.214:6667, 192.168.100.215:6667]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = topic.group2
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 100
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-08-14 13:33:58.181 [org.springframework.kafka.KafkaListenerEndpointContainer#1-2-C-1] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-topic.group2-8, groupId=topic.group2] Cluster ID: JcD5Rmr-Rmu4LUPRR7vWMw
2020-08-14 13:33:58.182 [org.springframework.kafka.KafkaListenerEndpointContainer#1-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-8, groupId=topic.group2] Discovered group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null)
2020-08-14 13:33:58.184 [org.springframework.kafka.KafkaListenerEndpointContainer#1-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-8, groupId=topic.group2] (Re-)joining group
2020-08-14 13:33:58.184 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.5.0
2020-08-14 13:33:58.185 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 66563e712b0b9f84
2020-08-14 13:33:58.185 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1597383238184
2020-08-14 13:33:58.185 [main] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group2-9, groupId=topic.group2] Subscribed to topic(s): topic.test
2020-08-14 13:33:58.185 [main] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Initializing ExecutorService
2020-08-14 13:33:58.187 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [192.168.100.213:6667, 192.168.100.214:6667, 192.168.100.215:6667]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = topic.group2
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 100
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-08-14 13:33:58.197 [org.springframework.kafka.KafkaListenerEndpointContainer#1-3-C-1] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-topic.group2-9, groupId=topic.group2] Cluster ID: JcD5Rmr-Rmu4LUPRR7vWMw
2020-08-14 13:33:58.198 [org.springframework.kafka.KafkaListenerEndpointContainer#1-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-9, groupId=topic.group2] Discovered group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null)
2020-08-14 13:33:58.199 [org.springframework.kafka.KafkaListenerEndpointContainer#1-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-9, groupId=topic.group2] (Re-)joining group
2020-08-14 13:33:58.201 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.5.0
2020-08-14 13:33:58.202 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 66563e712b0b9f84
2020-08-14 13:33:58.202 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1597383238201
2020-08-14 13:33:58.202 [main] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group2-10, groupId=topic.group2] Subscribed to topic(s): topic.test
2020-08-14 13:33:58.202 [main] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Initializing ExecutorService
2020-08-14 13:33:58.215 [main] INFO  com.kafka.demo.test.KafkaProducerSerTest - Started KafkaProducerSerTest in 65.121 seconds (JVM running for 66.49)
2020-08-14 13:33:58.221 [pool-2-thread-1] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [192.168.100.213:6667, 192.168.100.214:6667, 192.168.100.215:6667]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = new
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 100
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-08-14 13:33:58.232 [pool-2-thread-1] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.5.0
2020-08-14 13:33:58.233 [pool-2-thread-1] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 66563e712b0b9f84
2020-08-14 13:33:58.233 [pool-2-thread-1] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1597383238232
2020-08-14 13:33:58.234 [pool-2-thread-1] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-new-11, groupId=new] Subscribed to topic(s): topic.quick.initial
2020-08-14 13:33:58.284 [pool-2-thread-1] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-new-11, groupId=new] Cluster ID: JcD5Rmr-Rmu4LUPRR7vWMw
2020-08-14 13:33:58.285 [pool-2-thread-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-new-11, groupId=new] Discovered group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null)
2020-08-14 13:33:58.287 [pool-2-thread-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-new-11, groupId=new] (Re-)joining group
2020-08-14 13:34:01.330 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-1, groupId=topic.group1] Attempt to heartbeat failed since group is rebalancing
2020-08-14 13:34:01.758 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group1-2, groupId=topic.group1] Unsubscribed all topics or patterns and assigned partitions
2020-08-14 13:34:01.758 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group1-1, groupId=topic.group1] Revoke previously assigned partitions topic.test-0, topic.test-1, topic.test-2
2020-08-14 13:34:01.758 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Shutting down ExecutorService
2020-08-14 13:34:01.759 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - topic.group1: partitions revoked: [topic.test-0, topic.test-1, topic.test-2]
2020-08-14 13:34:01.760 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-1, groupId=topic.group1] Member consumer-topic.group1-1-d1d0d08b-d8d9-4f52-bc23-3ae3ea1a71c8 sending LeaveGroup request to coordinator ops-basic02.lingda.com:6667 (id: 2147483646 rack: null) due to the consumer unsubscribed from all topics
2020-08-14 13:34:01.762 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group1-1, groupId=topic.group1] Unsubscribed all topics or patterns and assigned partitions
2020-08-14 13:34:01.763 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group1-4, groupId=topic.group1] Unsubscribed all topics or patterns and assigned partitions
2020-08-14 13:34:01.763 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Shutting down ExecutorService
2020-08-14 13:34:01.763 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Shutting down ExecutorService
2020-08-14 13:34:01.765 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - topic.group1: Consumer stopped
2020-08-14 13:34:01.765 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group1-5, groupId=topic.group1] Unsubscribed all topics or patterns and assigned partitions
2020-08-14 13:34:01.765 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Shutting down ExecutorService
2020-08-14 13:34:01.770 [org.springframework.kafka.KafkaListenerEndpointContainer#1-1-C-1] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group2-7, groupId=topic.group2] Unsubscribed all topics or patterns and assigned partitions
2020-08-14 13:34:01.770 [org.springframework.kafka.KafkaListenerEndpointContainer#1-1-C-1] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Shutting down ExecutorService
2020-08-14 13:34:01.770 [org.springframework.kafka.KafkaListenerEndpointContainer#1-2-C-1] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group2-8, groupId=topic.group2] Unsubscribed all topics or patterns and assigned partitions
2020-08-14 13:34:01.771 [org.springframework.kafka.KafkaListenerEndpointContainer#1-2-C-1] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Shutting down ExecutorService
2020-08-14 13:34:01.771 [org.springframework.kafka.KafkaListenerEndpointContainer#1-3-C-1] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group2-9, groupId=topic.group2] Unsubscribed all topics or patterns and assigned partitions
2020-08-14 13:34:01.771 [org.springframework.kafka.KafkaListenerEndpointContainer#1-3-C-1] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Shutting down ExecutorService
2020-08-14 13:34:01.770 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group1-3, groupId=topic.group1] Unsubscribed all topics or patterns and assigned partitions
2020-08-14 13:34:01.773 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Shutting down ExecutorService
2020-08-14 13:34:01.770 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group2-10, groupId=topic.group2] Unsubscribed all topics or patterns and assigned partitions
2020-08-14 13:34:01.770 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group2-6, groupId=topic.group2] Unsubscribed all topics or patterns and assigned partitions
2020-08-14 13:34:01.777 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Shutting down ExecutorService
2020-08-14 13:34:01.777 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Shutting down ExecutorService
2020-08-14 13:34:01.777 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - topic.group1: Consumer stopped
2020-08-14 13:34:01.781 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - topic.group1: Consumer stopped
2020-08-14 13:34:01.782 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - topic.group2: Consumer stopped
2020-08-14 13:34:01.785 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - topic.group1: Consumer stopped
2020-08-14 13:34:01.786 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - topic.group1: Consumer stopped
2020-08-14 13:34:19.178 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-6, groupId=topic.group2] Group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2020-08-14 13:34:19.180 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - topic.group2: Consumer stopped
2020-08-14 13:34:19.193 [org.springframework.kafka.KafkaListenerEndpointContainer#1-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-7, groupId=topic.group2] Group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2020-08-14 13:34:19.195 [org.springframework.kafka.KafkaListenerEndpointContainer#1-1-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - topic.group2: Consumer stopped
2020-08-14 13:34:19.209 [org.springframework.kafka.KafkaListenerEndpointContainer#1-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-8, groupId=topic.group2] Group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2020-08-14 13:34:19.210 [org.springframework.kafka.KafkaListenerEndpointContainer#1-2-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - topic.group2: Consumer stopped
2020-08-14 13:34:19.224 [org.springframework.kafka.KafkaListenerEndpointContainer#1-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-9, groupId=topic.group2] Group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2020-08-14 13:34:19.225 [org.springframework.kafka.KafkaListenerEndpointContainer#1-3-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - topic.group2: Consumer stopped
2020-08-14 13:34:19.227 [SpringContextShutdownHook] INFO  o.s.scheduling.concurrent.ThreadPoolTaskExecutor - Shutting down ExecutorService 'applicationTaskExecutor'
2020-08-14 13:37:07.297 [main] INFO  com.kafka.demo.test.KafkaProducerSerTest - Starting KafkaProducerSerTest on LAPTOP-NFQDMTR9 with PID 17668 (started by sq in E:\otherProjects\kafkaDemo)
2020-08-14 13:37:07.299 [main] INFO  com.kafka.demo.test.KafkaProducerSerTest - No active profile set, falling back to default profiles: default
2020-08-14 13:37:08.426 [main] INFO  com.kafka.demo.clients.KafkaProducerSevice - 初始化:producer
2020-08-14 13:37:08.473 [main] INFO  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [192.168.100.213:6667, 192.168.100.214:6667, 192.168.100.215:6667]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 500
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2020-08-14 13:37:09.021 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.5.0
2020-08-14 13:37:09.023 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 66563e712b0b9f84
2020-08-14 13:37:09.023 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1597383429020
2020-08-14 13:37:09.063 [main] INFO  org.apache.kafka.clients.admin.AdminClientConfig - AdminClientConfig values: 
	bootstrap.servers = [192.168.100.213:6667, 192.168.100.214:6667, 192.168.100.215:6667]
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2020-08-14 13:37:09.101 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.5.0
2020-08-14 13:37:09.101 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 66563e712b0b9f84
2020-08-14 13:37:09.101 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1597383429101
2020-08-14 13:37:09.510 [kafka-producer-network-thread | producer-1] INFO  org.apache.kafka.clients.Metadata - [Producer clientId=producer-1] Cluster ID: JcD5Rmr-Rmu4LUPRR7vWMw
2020-08-14 13:37:09.809 [main] INFO  o.s.scheduling.concurrent.ThreadPoolTaskExecutor - Initializing ExecutorService 'applicationTaskExecutor'
2020-08-14 13:37:10.330 [main] INFO  org.apache.kafka.clients.admin.AdminClientConfig - AdminClientConfig values: 
	bootstrap.servers = [192.168.100.213:6667, 192.168.100.214:6667, 192.168.100.215:6667]
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2020-08-14 13:37:10.336 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.5.0
2020-08-14 13:37:10.336 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 66563e712b0b9f84
2020-08-14 13:37:10.337 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1597383430336
2020-08-14 13:37:31.410 [main] INFO  org.springframework.kafka.core.KafkaAdmin - Topic 'topic.quick.initial' exists but has a different partition count: 3 not 4, increasing if the broker supports it
2020-08-14 13:38:11.443 [kafka-admin-client-thread | adminclient-2] INFO  org.apache.kafka.clients.admin.KafkaAdminClient - [AdminClient clientId=adminclient-2] Forcing a hard I/O thread shutdown. Requests in progress will be aborted.
2020-08-14 13:38:11.531 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [192.168.100.213:6667, 192.168.100.214:6667, 192.168.100.215:6667]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = topic.group2
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 100
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-08-14 13:38:11.586 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.5.0
2020-08-14 13:38:11.586 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 66563e712b0b9f84
2020-08-14 13:38:11.586 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1597383491586
2020-08-14 13:38:11.588 [main] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group2-1, groupId=topic.group2] Subscribed to topic(s): topic.test
2020-08-14 13:38:11.592 [main] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Initializing ExecutorService
2020-08-14 13:38:11.600 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [192.168.100.213:6667, 192.168.100.214:6667, 192.168.100.215:6667]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = topic.group2
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 100
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-08-14 13:38:11.614 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.5.0
2020-08-14 13:38:11.614 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 66563e712b0b9f84
2020-08-14 13:38:11.614 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1597383491614
2020-08-14 13:38:11.615 [main] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group2-2, groupId=topic.group2] Subscribed to topic(s): topic.test
2020-08-14 13:38:11.615 [main] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Initializing ExecutorService
2020-08-14 13:38:11.617 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [192.168.100.213:6667, 192.168.100.214:6667, 192.168.100.215:6667]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = topic.group2
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 100
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-08-14 13:38:11.631 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.5.0
2020-08-14 13:38:11.631 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-topic.group2-2, groupId=topic.group2] Cluster ID: JcD5Rmr-Rmu4LUPRR7vWMw
2020-08-14 13:38:11.631 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 66563e712b0b9f84
2020-08-14 13:38:11.631 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1597383491631
2020-08-14 13:38:11.632 [main] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group2-3, groupId=topic.group2] Subscribed to topic(s): topic.test
2020-08-14 13:38:11.632 [main] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Initializing ExecutorService
2020-08-14 13:38:11.632 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-2, groupId=topic.group2] Discovered group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null)
2020-08-14 13:38:11.636 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [192.168.100.213:6667, 192.168.100.214:6667, 192.168.100.215:6667]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = topic.group2
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 100
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-08-14 13:38:11.640 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-2, groupId=topic.group2] (Re-)joining group
2020-08-14 13:38:11.654 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.5.0
2020-08-14 13:38:11.654 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 66563e712b0b9f84
2020-08-14 13:38:11.654 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1597383491654
2020-08-14 13:38:11.654 [main] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group2-4, groupId=topic.group2] Subscribed to topic(s): topic.test
2020-08-14 13:38:11.655 [main] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Initializing ExecutorService
2020-08-14 13:38:11.658 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [192.168.100.213:6667, 192.168.100.214:6667, 192.168.100.215:6667]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = topic.group2
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 100
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-08-14 13:38:11.666 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.5.0
2020-08-14 13:38:11.667 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 66563e712b0b9f84
2020-08-14 13:38:11.667 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1597383491666
2020-08-14 13:38:11.668 [main] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group2-5, groupId=topic.group2] Subscribed to topic(s): topic.test
2020-08-14 13:38:11.668 [main] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Initializing ExecutorService
2020-08-14 13:38:11.669 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [192.168.100.213:6667, 192.168.100.214:6667, 192.168.100.215:6667]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = topic.group1
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 100
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-08-14 13:38:11.677 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.5.0
2020-08-14 13:38:11.678 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 66563e712b0b9f84
2020-08-14 13:38:11.678 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1597383491677
2020-08-14 13:38:11.678 [main] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group1-6, groupId=topic.group1] Subscribed to topic(s): topic.test
2020-08-14 13:38:11.678 [main] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Initializing ExecutorService
2020-08-14 13:38:11.680 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [192.168.100.213:6667, 192.168.100.214:6667, 192.168.100.215:6667]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = topic.group1
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 100
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-08-14 13:38:11.689 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.5.0
2020-08-14 13:38:11.689 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 66563e712b0b9f84
2020-08-14 13:38:11.689 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1597383491689
2020-08-14 13:38:11.690 [main] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group1-7, groupId=topic.group1] Subscribed to topic(s): topic.test
2020-08-14 13:38:11.690 [main] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Initializing ExecutorService
2020-08-14 13:38:11.690 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-topic.group1-6, groupId=topic.group1] Cluster ID: JcD5Rmr-Rmu4LUPRR7vWMw
2020-08-14 13:38:11.692 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-6, groupId=topic.group1] Discovered group coordinator ops-basic02.lingda.com:6667 (id: 2147483646 rack: null)
2020-08-14 13:38:11.692 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [192.168.100.213:6667, 192.168.100.214:6667, 192.168.100.215:6667]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = topic.group1
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 100
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-08-14 13:38:11.695 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-6, groupId=topic.group1] (Re-)joining group
2020-08-14 13:38:11.706 [org.springframework.kafka.KafkaListenerEndpointContainer#1-1-C-1] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-topic.group1-7, groupId=topic.group1] Cluster ID: JcD5Rmr-Rmu4LUPRR7vWMw
2020-08-14 13:38:11.706 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.5.0
2020-08-14 13:38:11.706 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 66563e712b0b9f84
2020-08-14 13:38:11.707 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1597383491705
2020-08-14 13:38:11.707 [main] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group1-8, groupId=topic.group1] Subscribed to topic(s): topic.test
2020-08-14 13:38:11.707 [main] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Initializing ExecutorService
2020-08-14 13:38:11.707 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group1-6, groupId=topic.group1] Finished assignment for group at generation 4: {consumer-topic.group1-6-4cc38fa3-b76a-429f-8ada-32ae6a76e329=Assignment(partitions=[topic.test-0, topic.test-1, topic.test-2])}
2020-08-14 13:38:11.708 [org.springframework.kafka.KafkaListenerEndpointContainer#1-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-7, groupId=topic.group1] Discovered group coordinator ops-basic02.lingda.com:6667 (id: 2147483646 rack: null)
2020-08-14 13:38:11.711 [org.springframework.kafka.KafkaListenerEndpointContainer#1-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-7, groupId=topic.group1] (Re-)joining group
2020-08-14 13:38:11.715 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [192.168.100.213:6667, 192.168.100.214:6667, 192.168.100.215:6667]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = topic.group1
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 100
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-08-14 13:38:11.720 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-6, groupId=topic.group1] Join group failed with org.apache.kafka.common.errors.RebalanceInProgressException: The group is rebalancing, so a rejoin is needed.
2020-08-14 13:38:11.722 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-6, groupId=topic.group1] (Re-)joining group
2020-08-14 13:38:11.727 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group1-6, groupId=topic.group1] Finished assignment for group at generation 5: {consumer-topic.group1-7-3a1e7b90-f164-4781-8b3a-9aa3e5bd4283=Assignment(partitions=[topic.test-2]), consumer-topic.group1-6-4cc38fa3-b76a-429f-8ada-32ae6a76e329=Assignment(partitions=[topic.test-0, topic.test-1])}
2020-08-14 13:38:11.727 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.5.0
2020-08-14 13:38:11.728 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 66563e712b0b9f84
2020-08-14 13:38:11.728 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1597383491727
2020-08-14 13:38:11.728 [main] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group1-9, groupId=topic.group1] Subscribed to topic(s): topic.test
2020-08-14 13:38:11.728 [main] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Initializing ExecutorService
2020-08-14 13:38:11.732 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [192.168.100.213:6667, 192.168.100.214:6667, 192.168.100.215:6667]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = topic.group1
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 100
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-08-14 13:38:11.738 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-6, groupId=topic.group1] Successfully joined group with generation 5
2020-08-14 13:38:11.740 [org.springframework.kafka.KafkaListenerEndpointContainer#1-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-7, groupId=topic.group1] Successfully joined group with generation 5
2020-08-14 13:38:11.740 [org.springframework.kafka.KafkaListenerEndpointContainer#1-3-C-1] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-topic.group1-9, groupId=topic.group1] Cluster ID: JcD5Rmr-Rmu4LUPRR7vWMw
2020-08-14 13:38:11.741 [org.springframework.kafka.KafkaListenerEndpointContainer#1-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-9, groupId=topic.group1] Discovered group coordinator ops-basic02.lingda.com:6667 (id: 2147483646 rack: null)
2020-08-14 13:38:11.742 [org.springframework.kafka.KafkaListenerEndpointContainer#1-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-9, groupId=topic.group1] (Re-)joining group
2020-08-14 13:38:11.745 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.5.0
2020-08-14 13:38:11.746 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 66563e712b0b9f84
2020-08-14 13:38:11.746 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1597383491745
2020-08-14 13:38:11.746 [main] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group1-10, groupId=topic.group1] Subscribed to topic(s): topic.test
2020-08-14 13:38:11.747 [main] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Initializing ExecutorService
2020-08-14 13:38:11.753 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group1-6, groupId=topic.group1] Adding newly assigned partitions: topic.test-0, topic.test-1
2020-08-14 13:38:11.754 [org.springframework.kafka.KafkaListenerEndpointContainer#1-1-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group1-7, groupId=topic.group1] Adding newly assigned partitions: topic.test-2
2020-08-14 13:38:11.773 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-topic.group1-10, groupId=topic.group1] Cluster ID: JcD5Rmr-Rmu4LUPRR7vWMw
2020-08-14 13:38:11.775 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-10, groupId=topic.group1] Discovered group coordinator ops-basic02.lingda.com:6667 (id: 2147483646 rack: null)
2020-08-14 13:38:11.778 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-10, groupId=topic.group1] (Re-)joining group
2020-08-14 13:38:11.781 [org.springframework.kafka.KafkaListenerEndpointContainer#1-1-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group1-7, groupId=topic.group1] Found no committed offset for partition topic.test-2
2020-08-14 13:38:11.783 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group1-6, groupId=topic.group1] Found no committed offset for partition topic.test-0
2020-08-14 13:38:11.784 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group1-6, groupId=topic.group1] Found no committed offset for partition topic.test-1
2020-08-14 13:38:11.791 [main] INFO  com.kafka.demo.test.KafkaProducerSerTest - Started KafkaProducerSerTest in 65.487 seconds (JVM running for 66.84)
2020-08-14 13:38:11.805 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.a.k.clients.consumer.internals.SubscriptionState - [Consumer clientId=consumer-topic.group1-6, groupId=topic.group1] Resetting offset for partition topic.test-1 to offset 0.
2020-08-14 13:38:11.810 [pool-2-thread-1] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [192.168.100.213:6667, 192.168.100.214:6667, 192.168.100.215:6667]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = new
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 100
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-08-14 13:38:11.812 [org.springframework.kafka.KafkaListenerEndpointContainer#1-1-C-1] INFO  o.a.k.clients.consumer.internals.SubscriptionState - [Consumer clientId=consumer-topic.group1-7, groupId=topic.group1] Resetting offset for partition topic.test-2 to offset 1.
2020-08-14 13:38:11.813 [org.springframework.kafka.KafkaListenerEndpointContainer#1-1-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - topic.group1: partitions assigned: [topic.test-2]
2020-08-14 13:38:11.832 [pool-2-thread-1] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.5.0
2020-08-14 13:38:11.834 [pool-2-thread-1] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 66563e712b0b9f84
2020-08-14 13:38:11.835 [pool-2-thread-1] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1597383491832
2020-08-14 13:38:11.836 [pool-2-thread-1] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-new-11, groupId=new] Subscribed to topic(s): topic.quick.initial
2020-08-14 13:38:11.867 [pool-2-thread-1] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-new-11, groupId=new] Cluster ID: JcD5Rmr-Rmu4LUPRR7vWMw
2020-08-14 13:38:11.867 [pool-2-thread-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-new-11, groupId=new] Discovered group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null)
2020-08-14 13:38:11.869 [pool-2-thread-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-new-11, groupId=new] (Re-)joining group
2020-08-14 13:38:14.761 [org.springframework.kafka.KafkaListenerEndpointContainer#1-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-7, groupId=topic.group1] Attempt to heartbeat failed since group is rebalancing
2020-08-14 13:38:14.763 [org.springframework.kafka.KafkaListenerEndpointContainer#1-1-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group1-7, groupId=topic.group1] Revoke previously assigned partitions topic.test-2
2020-08-14 13:38:14.763 [org.springframework.kafka.KafkaListenerEndpointContainer#1-1-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - topic.group1: partitions revoked: [topic.test-2]
2020-08-14 13:38:14.764 [org.springframework.kafka.KafkaListenerEndpointContainer#1-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-7, groupId=topic.group1] (Re-)joining group
2020-08-14 13:38:14.881 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-6, groupId=topic.group1] Attempt to heartbeat failed since group is rebalancing
2020-08-14 13:38:15.275 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group2-4, groupId=topic.group2] Unsubscribed all topics or patterns and assigned partitions
2020-08-14 13:38:15.275 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group2-3, groupId=topic.group2] Unsubscribed all topics or patterns and assigned partitions
2020-08-14 13:38:15.275 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Shutting down ExecutorService
2020-08-14 13:38:15.275 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Shutting down ExecutorService
2020-08-14 13:38:15.277 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group2-5, groupId=topic.group2] Unsubscribed all topics or patterns and assigned partitions
2020-08-14 13:38:15.278 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Shutting down ExecutorService
2020-08-14 13:38:15.275 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group2-1, groupId=topic.group2] Unsubscribed all topics or patterns and assigned partitions
2020-08-14 13:38:15.278 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Shutting down ExecutorService
2020-08-14 13:38:15.278 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group2-2, groupId=topic.group2] Unsubscribed all topics or patterns and assigned partitions
2020-08-14 13:38:15.279 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Shutting down ExecutorService
2020-08-14 13:38:15.280 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group1-6, groupId=topic.group1] Revoke previously assigned partitions topic.test-0, topic.test-1
2020-08-14 13:38:15.280 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - topic.group1: partitions revoked: [topic.test-0, topic.test-1]
2020-08-14 13:38:15.280 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-6, groupId=topic.group1] Member consumer-topic.group1-6-4cc38fa3-b76a-429f-8ada-32ae6a76e329 sending LeaveGroup request to coordinator ops-basic02.lingda.com:6667 (id: 2147483646 rack: null) due to the consumer unsubscribed from all topics
2020-08-14 13:38:15.281 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - topic.group2: Consumer stopped
2020-08-14 13:38:15.282 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group1-6, groupId=topic.group1] Unsubscribed all topics or patterns and assigned partitions
2020-08-14 13:38:15.282 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Shutting down ExecutorService
2020-08-14 13:38:15.283 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - topic.group2: Consumer stopped
2020-08-14 13:38:15.285 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - topic.group2: Consumer stopped
2020-08-14 13:38:15.285 [org.springframework.kafka.KafkaListenerEndpointContainer#1-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-7, groupId=topic.group1] Member consumer-topic.group1-7-3a1e7b90-f164-4781-8b3a-9aa3e5bd4283 sending LeaveGroup request to coordinator ops-basic02.lingda.com:6667 (id: 2147483646 rack: null) due to the consumer unsubscribed from all topics
2020-08-14 13:38:15.286 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - topic.group2: Consumer stopped
2020-08-14 13:38:15.286 [org.springframework.kafka.KafkaListenerEndpointContainer#1-1-C-1] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group1-7, groupId=topic.group1] Unsubscribed all topics or patterns and assigned partitions
2020-08-14 13:38:15.286 [org.springframework.kafka.KafkaListenerEndpointContainer#1-1-C-1] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Shutting down ExecutorService
2020-08-14 13:38:15.286 [org.springframework.kafka.KafkaListenerEndpointContainer#1-2-C-1] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group1-8, groupId=topic.group1] Unsubscribed all topics or patterns and assigned partitions
2020-08-14 13:38:15.287 [org.springframework.kafka.KafkaListenerEndpointContainer#1-2-C-1] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Shutting down ExecutorService
2020-08-14 13:38:15.287 [org.springframework.kafka.KafkaListenerEndpointContainer#1-3-C-1] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group1-9, groupId=topic.group1] Unsubscribed all topics or patterns and assigned partitions
2020-08-14 13:38:15.288 [org.springframework.kafka.KafkaListenerEndpointContainer#1-3-C-1] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Shutting down ExecutorService
2020-08-14 13:38:15.288 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group1-10, groupId=topic.group1] Finished assignment for group at generation 6: {consumer-topic.group1-7-3a1e7b90-f164-4781-8b3a-9aa3e5bd4283=Assignment(partitions=[topic.test-1]), consumer-topic.group1-9-50a84677-6b25-4bf6-9e81-697b5ec8f4da=Assignment(partitions=[topic.test-2]), consumer-topic.group1-10-c32b4114-1750-43fb-8929-667b7152f218=Assignment(partitions=[topic.test-0])}
2020-08-14 13:38:15.297 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-10, groupId=topic.group1] Member consumer-topic.group1-10-c32b4114-1750-43fb-8929-667b7152f218 sending LeaveGroup request to coordinator ops-basic02.lingda.com:6667 (id: 2147483646 rack: null) due to the consumer unsubscribed from all topics
2020-08-14 13:38:15.297 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group1-10, groupId=topic.group1] Unsubscribed all topics or patterns and assigned partitions
2020-08-14 13:38:15.297 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Shutting down ExecutorService
2020-08-14 13:38:15.298 [org.springframework.kafka.KafkaListenerEndpointContainer#1-1-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - topic.group1: Consumer stopped
2020-08-14 13:38:15.299 [org.springframework.kafka.KafkaListenerEndpointContainer#1-2-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - topic.group1: Consumer stopped
2020-08-14 13:38:15.300 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - topic.group1: Consumer stopped
2020-08-14 13:38:15.301 [org.springframework.kafka.KafkaListenerEndpointContainer#1-3-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - topic.group1: Consumer stopped
2020-08-14 13:38:15.305 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - topic.group1: Consumer stopped
2020-08-14 13:38:32.680 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-2, groupId=topic.group2] Group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2020-08-14 13:38:32.686 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - topic.group2: Consumer stopped
2020-08-14 13:38:32.691 [SpringContextShutdownHook] INFO  o.s.scheduling.concurrent.ThreadPoolTaskExecutor - Shutting down ExecutorService 'applicationTaskExecutor'
2020-08-14 13:38:44.504 [main] INFO  com.kafka.demo.test.KafkaProducerSerTest - Starting KafkaProducerSerTest on LAPTOP-NFQDMTR9 with PID 22496 (started by sq in E:\otherProjects\kafkaDemo)
2020-08-14 13:38:44.506 [main] INFO  com.kafka.demo.test.KafkaProducerSerTest - No active profile set, falling back to default profiles: default
2020-08-14 13:38:45.469 [main] INFO  com.kafka.demo.clients.KafkaProducerSevice - 初始化:producer
2020-08-14 13:38:45.498 [main] INFO  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [192.168.100.213:6667, 192.168.100.214:6667, 192.168.100.215:6667]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 500
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2020-08-14 13:38:45.923 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.5.0
2020-08-14 13:38:45.925 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 66563e712b0b9f84
2020-08-14 13:38:45.925 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1597383525922
2020-08-14 13:38:46.390 [kafka-producer-network-thread | producer-1] INFO  org.apache.kafka.clients.Metadata - [Producer clientId=producer-1] Cluster ID: JcD5Rmr-Rmu4LUPRR7vWMw
2020-08-14 13:38:46.447 [main] INFO  o.s.scheduling.concurrent.ThreadPoolTaskExecutor - Initializing ExecutorService 'applicationTaskExecutor'
2020-08-14 13:38:46.917 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [192.168.100.213:6667, 192.168.100.214:6667, 192.168.100.215:6667]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = topic.group2
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 100
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-08-14 13:38:46.963 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.5.0
2020-08-14 13:38:46.963 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 66563e712b0b9f84
2020-08-14 13:38:46.963 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1597383526963
2020-08-14 13:38:46.965 [main] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group2-1, groupId=topic.group2] Subscribed to topic(s): topic.test
2020-08-14 13:38:46.967 [main] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Initializing ExecutorService
2020-08-14 13:38:46.973 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [192.168.100.213:6667, 192.168.100.214:6667, 192.168.100.215:6667]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = topic.group2
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 100
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-08-14 13:38:46.983 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.5.0
2020-08-14 13:38:46.983 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 66563e712b0b9f84
2020-08-14 13:38:46.983 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1597383526983
2020-08-14 13:38:46.984 [main] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group2-2, groupId=topic.group2] Subscribed to topic(s): topic.test
2020-08-14 13:38:46.984 [main] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Initializing ExecutorService
2020-08-14 13:38:46.985 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [192.168.100.213:6667, 192.168.100.214:6667, 192.168.100.215:6667]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = topic.group2
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 100
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-08-14 13:38:46.996 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.5.0
2020-08-14 13:38:46.996 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 66563e712b0b9f84
2020-08-14 13:38:46.996 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1597383526996
2020-08-14 13:38:46.997 [main] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group2-3, groupId=topic.group2] Subscribed to topic(s): topic.test
2020-08-14 13:38:46.997 [main] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Initializing ExecutorService
2020-08-14 13:38:46.998 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-topic.group2-1, groupId=topic.group2] Cluster ID: JcD5Rmr-Rmu4LUPRR7vWMw
2020-08-14 13:38:46.998 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-topic.group2-2, groupId=topic.group2] Cluster ID: JcD5Rmr-Rmu4LUPRR7vWMw
2020-08-14 13:38:46.998 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [192.168.100.213:6667, 192.168.100.214:6667, 192.168.100.215:6667]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = topic.group2
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 100
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-08-14 13:38:47.000 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-2, groupId=topic.group2] Discovered group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null)
2020-08-14 13:38:47.000 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-1, groupId=topic.group2] Discovered group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null)
2020-08-14 13:38:47.003 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-1, groupId=topic.group2] (Re-)joining group
2020-08-14 13:38:47.003 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-2, groupId=topic.group2] (Re-)joining group
2020-08-14 13:38:47.008 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.5.0
2020-08-14 13:38:47.009 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 66563e712b0b9f84
2020-08-14 13:38:47.009 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1597383527008
2020-08-14 13:38:47.009 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-topic.group2-3, groupId=topic.group2] Cluster ID: JcD5Rmr-Rmu4LUPRR7vWMw
2020-08-14 13:38:47.009 [main] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group2-4, groupId=topic.group2] Subscribed to topic(s): topic.test
2020-08-14 13:38:47.009 [main] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Initializing ExecutorService
2020-08-14 13:38:47.010 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-3, groupId=topic.group2] Discovered group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null)
2020-08-14 13:38:47.011 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-3, groupId=topic.group2] (Re-)joining group
2020-08-14 13:38:47.011 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [192.168.100.213:6667, 192.168.100.214:6667, 192.168.100.215:6667]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = topic.group2
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 100
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-08-14 13:38:47.030 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.5.0
2020-08-14 13:38:47.030 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-topic.group2-4, groupId=topic.group2] Cluster ID: JcD5Rmr-Rmu4LUPRR7vWMw
2020-08-14 13:38:47.030 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 66563e712b0b9f84
2020-08-14 13:38:47.030 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1597383527030
2020-08-14 13:38:47.030 [main] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group2-5, groupId=topic.group2] Subscribed to topic(s): topic.test
2020-08-14 13:38:47.031 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-4, groupId=topic.group2] Discovered group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null)
2020-08-14 13:38:47.031 [main] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Initializing ExecutorService
2020-08-14 13:38:47.032 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-4, groupId=topic.group2] (Re-)joining group
2020-08-14 13:38:47.032 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [192.168.100.213:6667, 192.168.100.214:6667, 192.168.100.215:6667]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = topic.group1
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 100
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-08-14 13:38:47.041 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.5.0
2020-08-14 13:38:47.041 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 66563e712b0b9f84
2020-08-14 13:38:47.041 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1597383527041
2020-08-14 13:38:47.041 [main] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group1-6, groupId=topic.group1] Subscribed to topic(s): topic.test
2020-08-14 13:38:47.042 [main] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Initializing ExecutorService
2020-08-14 13:38:47.043 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [192.168.100.213:6667, 192.168.100.214:6667, 192.168.100.215:6667]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = topic.group1
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 100
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-08-14 13:38:47.048 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.5.0
2020-08-14 13:38:47.048 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 66563e712b0b9f84
2020-08-14 13:38:47.048 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1597383527048
2020-08-14 13:38:47.049 [main] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group1-7, groupId=topic.group1] Subscribed to topic(s): topic.test
2020-08-14 13:38:47.049 [main] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Initializing ExecutorService
2020-08-14 13:38:47.051 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [192.168.100.213:6667, 192.168.100.214:6667, 192.168.100.215:6667]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = topic.group1
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 100
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-08-14 13:38:47.057 [org.springframework.kafka.KafkaListenerEndpointContainer#1-1-C-1] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-topic.group1-7, groupId=topic.group1] Cluster ID: JcD5Rmr-Rmu4LUPRR7vWMw
2020-08-14 13:38:47.058 [org.springframework.kafka.KafkaListenerEndpointContainer#1-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-7, groupId=topic.group1] Discovered group coordinator ops-basic02.lingda.com:6667 (id: 2147483646 rack: null)
2020-08-14 13:38:47.058 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.5.0
2020-08-14 13:38:47.058 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 66563e712b0b9f84
2020-08-14 13:38:47.058 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1597383527058
2020-08-14 13:38:47.059 [main] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group1-8, groupId=topic.group1] Subscribed to topic(s): topic.test
2020-08-14 13:38:47.059 [main] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Initializing ExecutorService
2020-08-14 13:38:47.059 [org.springframework.kafka.KafkaListenerEndpointContainer#1-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-7, groupId=topic.group1] (Re-)joining group
2020-08-14 13:38:47.061 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [192.168.100.213:6667, 192.168.100.214:6667, 192.168.100.215:6667]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = topic.group1
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 100
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-08-14 13:38:47.066 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.5.0
2020-08-14 13:38:47.066 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 66563e712b0b9f84
2020-08-14 13:38:47.066 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1597383527066
2020-08-14 13:38:47.067 [main] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group1-9, groupId=topic.group1] Subscribed to topic(s): topic.test
2020-08-14 13:38:47.067 [main] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Initializing ExecutorService
2020-08-14 13:38:47.068 [org.springframework.kafka.KafkaListenerEndpointContainer#1-2-C-1] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-topic.group1-8, groupId=topic.group1] Cluster ID: JcD5Rmr-Rmu4LUPRR7vWMw
2020-08-14 13:38:47.068 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [192.168.100.213:6667, 192.168.100.214:6667, 192.168.100.215:6667]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = topic.group1
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 100
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-08-14 13:38:47.068 [org.springframework.kafka.KafkaListenerEndpointContainer#1-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-8, groupId=topic.group1] Discovered group coordinator ops-basic02.lingda.com:6667 (id: 2147483646 rack: null)
2020-08-14 13:38:47.069 [org.springframework.kafka.KafkaListenerEndpointContainer#1-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-8, groupId=topic.group1] (Re-)joining group
2020-08-14 13:38:47.070 [org.springframework.kafka.KafkaListenerEndpointContainer#1-1-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group1-7, groupId=topic.group1] Finished assignment for group at generation 8: {consumer-topic.group1-7-60b13803-962c-492a-ad89-c32ee3daba37=Assignment(partitions=[topic.test-0, topic.test-1, topic.test-2])}
2020-08-14 13:38:47.076 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.5.0
2020-08-14 13:38:47.076 [org.springframework.kafka.KafkaListenerEndpointContainer#1-3-C-1] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-topic.group1-9, groupId=topic.group1] Cluster ID: JcD5Rmr-Rmu4LUPRR7vWMw
2020-08-14 13:38:47.076 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 66563e712b0b9f84
2020-08-14 13:38:47.076 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1597383527076
2020-08-14 13:38:47.076 [org.springframework.kafka.KafkaListenerEndpointContainer#1-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-9, groupId=topic.group1] Discovered group coordinator ops-basic02.lingda.com:6667 (id: 2147483646 rack: null)
2020-08-14 13:38:47.076 [main] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group1-10, groupId=topic.group1] Subscribed to topic(s): topic.test
2020-08-14 13:38:47.076 [main] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Initializing ExecutorService
2020-08-14 13:38:47.077 [org.springframework.kafka.KafkaListenerEndpointContainer#1-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-9, groupId=topic.group1] (Re-)joining group
2020-08-14 13:38:47.077 [org.springframework.kafka.KafkaListenerEndpointContainer#1-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-7, groupId=topic.group1] Join group failed with org.apache.kafka.common.errors.RebalanceInProgressException: The group is rebalancing, so a rejoin is needed.
2020-08-14 13:38:47.078 [org.springframework.kafka.KafkaListenerEndpointContainer#1-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-7, groupId=topic.group1] (Re-)joining group
2020-08-14 13:38:47.080 [org.springframework.kafka.KafkaListenerEndpointContainer#1-1-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group1-7, groupId=topic.group1] Finished assignment for group at generation 9: {consumer-topic.group1-7-60b13803-962c-492a-ad89-c32ee3daba37=Assignment(partitions=[topic.test-0, topic.test-1]), consumer-topic.group1-8-60cf36ed-e383-4bcc-b862-2ee5023886f5=Assignment(partitions=[topic.test-2])}
2020-08-14 13:38:47.084 [org.springframework.kafka.KafkaListenerEndpointContainer#1-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-7, groupId=topic.group1] Join group failed with org.apache.kafka.common.errors.RebalanceInProgressException: The group is rebalancing, so a rejoin is needed.
2020-08-14 13:38:47.084 [org.springframework.kafka.KafkaListenerEndpointContainer#1-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-8, groupId=topic.group1] Join group failed with org.apache.kafka.common.errors.RebalanceInProgressException: The group is rebalancing, so a rejoin is needed.
2020-08-14 13:38:47.084 [org.springframework.kafka.KafkaListenerEndpointContainer#1-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-7, groupId=topic.group1] (Re-)joining group
2020-08-14 13:38:47.084 [org.springframework.kafka.KafkaListenerEndpointContainer#1-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-8, groupId=topic.group1] (Re-)joining group
2020-08-14 13:38:47.087 [org.springframework.kafka.KafkaListenerEndpointContainer#1-1-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group1-7, groupId=topic.group1] Finished assignment for group at generation 10: {consumer-topic.group1-7-60b13803-962c-492a-ad89-c32ee3daba37=Assignment(partitions=[topic.test-0]), consumer-topic.group1-9-722085f5-a131-4979-98f2-cf0aaa53c35f=Assignment(partitions=[topic.test-2]), consumer-topic.group1-8-60cf36ed-e383-4bcc-b862-2ee5023886f5=Assignment(partitions=[topic.test-1])}
2020-08-14 13:38:47.088 [main] INFO  com.kafka.demo.test.KafkaProducerSerTest - Started KafkaProducerSerTest in 3.15 seconds (JVM running for 4.209)
2020-08-14 13:38:47.092 [pool-2-thread-1] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [192.168.100.213:6667, 192.168.100.214:6667, 192.168.100.215:6667]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = new
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 100
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-08-14 13:38:47.098 [org.springframework.kafka.KafkaListenerEndpointContainer#1-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-9, groupId=topic.group1] Successfully joined group with generation 10
2020-08-14 13:38:47.098 [org.springframework.kafka.KafkaListenerEndpointContainer#1-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-7, groupId=topic.group1] Successfully joined group with generation 10
2020-08-14 13:38:47.098 [org.springframework.kafka.KafkaListenerEndpointContainer#1-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-8, groupId=topic.group1] Successfully joined group with generation 10
2020-08-14 13:38:47.100 [pool-2-thread-1] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.5.0
2020-08-14 13:38:47.100 [pool-2-thread-1] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 66563e712b0b9f84
2020-08-14 13:38:47.100 [pool-2-thread-1] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1597383527100
2020-08-14 13:38:47.101 [pool-2-thread-1] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-new-11, groupId=new] Subscribed to topic(s): topic.quick.initial
2020-08-14 13:38:47.103 [org.springframework.kafka.KafkaListenerEndpointContainer#1-1-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group1-7, groupId=topic.group1] Adding newly assigned partitions: topic.test-0
2020-08-14 13:38:47.103 [org.springframework.kafka.KafkaListenerEndpointContainer#1-3-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group1-9, groupId=topic.group1] Adding newly assigned partitions: topic.test-2
2020-08-14 13:38:47.103 [org.springframework.kafka.KafkaListenerEndpointContainer#1-2-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group1-8, groupId=topic.group1] Adding newly assigned partitions: topic.test-1
2020-08-14 13:38:47.109 [pool-2-thread-1] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-new-11, groupId=new] Cluster ID: JcD5Rmr-Rmu4LUPRR7vWMw
2020-08-14 13:38:47.110 [pool-2-thread-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-new-11, groupId=new] Discovered group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null)
2020-08-14 13:38:47.112 [pool-2-thread-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-new-11, groupId=new] (Re-)joining group
2020-08-14 13:38:47.115 [org.springframework.kafka.KafkaListenerEndpointContainer#1-1-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group1-7, groupId=topic.group1] Found no committed offset for partition topic.test-0
2020-08-14 13:38:47.115 [org.springframework.kafka.KafkaListenerEndpointContainer#1-3-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group1-9, groupId=topic.group1] Found no committed offset for partition topic.test-2
2020-08-14 13:38:47.115 [org.springframework.kafka.KafkaListenerEndpointContainer#1-2-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group1-8, groupId=topic.group1] Found no committed offset for partition topic.test-1
2020-08-14 13:38:47.130 [org.springframework.kafka.KafkaListenerEndpointContainer#1-3-C-1] INFO  o.a.k.clients.consumer.internals.SubscriptionState - [Consumer clientId=consumer-topic.group1-9, groupId=topic.group1] Resetting offset for partition topic.test-2 to offset 1.
2020-08-14 13:38:47.130 [org.springframework.kafka.KafkaListenerEndpointContainer#1-2-C-1] INFO  o.a.k.clients.consumer.internals.SubscriptionState - [Consumer clientId=consumer-topic.group1-8, groupId=topic.group1] Resetting offset for partition topic.test-1 to offset 0.
2020-08-14 13:38:47.131 [org.springframework.kafka.KafkaListenerEndpointContainer#1-2-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - topic.group1: partitions assigned: [topic.test-1]
2020-08-14 13:38:47.131 [org.springframework.kafka.KafkaListenerEndpointContainer#1-3-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - topic.group1: partitions assigned: [topic.test-2]
2020-08-14 13:39:08.044 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-1, groupId=topic.group2] Group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2020-08-14 13:39:08.044 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-3, groupId=topic.group2] Group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2020-08-14 13:39:08.044 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-1, groupId=topic.group2] Join group failed with org.apache.kafka.common.errors.DisconnectException
2020-08-14 13:39:08.053 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-1, groupId=topic.group2] Discovered group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null)
2020-08-14 13:39:08.054 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-1, groupId=topic.group2] Group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2020-08-14 13:39:08.056 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-1, groupId=topic.group2] Discovered group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null)
2020-08-14 13:39:08.056 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-1, groupId=topic.group2] Group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2020-08-14 13:39:08.057 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-1, groupId=topic.group2] Discovered group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null)
2020-08-14 13:39:08.058 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-1, groupId=topic.group2] Group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2020-08-14 13:39:08.059 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-1, groupId=topic.group2] Discovered group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null)
2020-08-14 13:39:08.059 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-1, groupId=topic.group2] Group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2020-08-14 13:39:08.060 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-1, groupId=topic.group2] Discovered group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null)
2020-08-14 13:39:08.061 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-1, groupId=topic.group2] Group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2020-08-14 13:39:08.062 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-1, groupId=topic.group2] Discovered group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null)
2020-08-14 13:39:08.062 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-1, groupId=topic.group2] Group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2020-08-14 13:39:08.063 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-1, groupId=topic.group2] Discovered group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null)
2020-08-14 13:39:08.064 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-1, groupId=topic.group2] Group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2020-08-14 13:39:08.065 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-1, groupId=topic.group2] Discovered group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null)
2020-08-14 13:39:08.065 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-1, groupId=topic.group2] Group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2020-08-14 13:39:08.066 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-1, groupId=topic.group2] Discovered group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null)
2020-08-14 13:39:08.067 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-1, groupId=topic.group2] Group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2020-08-14 13:39:08.068 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-1, groupId=topic.group2] Discovered group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null)
2020-08-14 13:39:08.068 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-1, groupId=topic.group2] Group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2020-08-14 13:39:08.069 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-1, groupId=topic.group2] Discovered group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null)
2020-08-14 13:39:08.069 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-1, groupId=topic.group2] Group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2020-08-14 13:39:08.070 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-2, groupId=topic.group2] Group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2020-08-14 13:39:08.070 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-1, groupId=topic.group2] Discovered group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null)
2020-08-14 13:39:08.071 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-1, groupId=topic.group2] Group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2020-08-14 13:39:08.072 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-4, groupId=topic.group2] Group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2020-08-14 13:39:08.072 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-1, groupId=topic.group2] Discovered group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null)
2020-08-14 13:39:08.072 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-4, groupId=topic.group2] Join group failed with org.apache.kafka.common.errors.DisconnectException
2020-08-14 13:39:08.072 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-1, groupId=topic.group2] Group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2020-08-14 13:39:08.073 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-1, groupId=topic.group2] Discovered group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null)
2020-08-14 13:39:08.074 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-1, groupId=topic.group2] Group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2020-08-14 13:39:08.075 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-1, groupId=topic.group2] Discovered group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null)
2020-08-14 13:39:08.075 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-1, groupId=topic.group2] Group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2020-08-14 13:39:08.075 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-5, groupId=topic.group2] Discovered group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null)
2020-08-14 13:39:08.076 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-1, groupId=topic.group2] Discovered group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null)
2020-08-14 13:39:08.077 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-5, groupId=topic.group2] (Re-)joining group
2020-08-14 13:39:08.077 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-1, groupId=topic.group2] Group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2020-08-14 13:39:08.079 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-1, groupId=topic.group2] Discovered group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null)
2020-08-14 13:39:08.079 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-4, groupId=topic.group2] Discovered group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null)
2020-08-14 13:39:08.079 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-1, groupId=topic.group2] Group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2020-08-14 13:39:08.079 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-4, groupId=topic.group2] Group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2020-08-14 13:39:08.080 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-1, groupId=topic.group2] Discovered group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null)
2020-08-14 13:39:08.080 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-1, groupId=topic.group2] Group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2020-08-14 13:39:08.080 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-4, groupId=topic.group2] Discovered group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null)
2020-08-14 13:39:08.081 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-4, groupId=topic.group2] Group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2020-08-14 13:39:08.081 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-1, groupId=topic.group2] Discovered group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null)
2020-08-14 13:39:08.082 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-4, groupId=topic.group2] Discovered group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null)
2020-08-14 13:39:08.082 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-1, groupId=topic.group2] Group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2020-08-14 13:39:08.082 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-4, groupId=topic.group2] Group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2020-08-14 13:39:08.083 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-4, groupId=topic.group2] Discovered group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null)
2020-08-14 13:39:08.084 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-1, groupId=topic.group2] Discovered group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null)
2020-08-14 13:39:08.085 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-4, groupId=topic.group2] Group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2020-08-14 13:39:08.085 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-1, groupId=topic.group2] (Re-)joining group
2020-08-14 13:39:08.086 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-4, groupId=topic.group2] Discovered group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null)
2020-08-14 13:39:08.086 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-4, groupId=topic.group2] Group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2020-08-14 13:39:08.087 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-4, groupId=topic.group2] Discovered group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null)
2020-08-14 13:39:08.087 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-4, groupId=topic.group2] Group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2020-08-14 13:39:08.088 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-4, groupId=topic.group2] Discovered group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null)
2020-08-14 13:39:08.089 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-4, groupId=topic.group2] Group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2020-08-14 13:39:08.090 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-4, groupId=topic.group2] Discovered group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null)
2020-08-14 13:39:08.090 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-4, groupId=topic.group2] Group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2020-08-14 13:39:08.091 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-4, groupId=topic.group2] Discovered group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null)
2020-08-14 13:39:08.091 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-4, groupId=topic.group2] Group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2020-08-14 13:39:08.092 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-4, groupId=topic.group2] Discovered group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null)
2020-08-14 13:39:08.093 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-4, groupId=topic.group2] Group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2020-08-14 13:39:08.094 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-4, groupId=topic.group2] Discovered group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null)
2020-08-14 13:39:08.094 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-4, groupId=topic.group2] Group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2020-08-14 13:39:08.095 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-4, groupId=topic.group2] Discovered group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null)
2020-08-14 13:39:08.095 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-4, groupId=topic.group2] Group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2020-08-14 13:39:08.096 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-4, groupId=topic.group2] Discovered group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null)
2020-08-14 13:39:08.096 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-4, groupId=topic.group2] Group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2020-08-14 13:39:08.097 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-4, groupId=topic.group2] Discovered group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null)
2020-08-14 13:39:08.098 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-4, groupId=topic.group2] Group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2020-08-14 13:39:08.099 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-4, groupId=topic.group2] Discovered group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null)
2020-08-14 13:39:08.099 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-4, groupId=topic.group2] Group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2020-08-14 13:39:08.100 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-4, groupId=topic.group2] Discovered group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null)
2020-08-14 13:39:08.100 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-4, groupId=topic.group2] Group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2020-08-14 13:39:08.101 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-4, groupId=topic.group2] Discovered group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null)
2020-08-14 13:39:08.102 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-4, groupId=topic.group2] Group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2020-08-14 13:39:08.103 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-4, groupId=topic.group2] Discovered group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null)
2020-08-14 13:39:08.103 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-4, groupId=topic.group2] Group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2020-08-14 13:39:08.104 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-4, groupId=topic.group2] Discovered group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null)
2020-08-14 13:39:08.105 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-10, groupId=topic.group1] Discovered group coordinator ops-basic02.lingda.com:6667 (id: 2147483646 rack: null)
2020-08-14 13:39:08.105 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-4, groupId=topic.group2] Group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2020-08-14 13:39:08.106 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-4, groupId=topic.group2] Discovered group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null)
2020-08-14 13:39:08.106 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-10, groupId=topic.group1] (Re-)joining group
2020-08-14 13:39:08.106 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-4, groupId=topic.group2] Group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2020-08-14 13:39:08.107 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-4, groupId=topic.group2] Discovered group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null)
2020-08-14 13:39:08.107 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-4, groupId=topic.group2] Group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2020-08-14 13:39:08.109 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-4, groupId=topic.group2] Discovered group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null)
2020-08-14 13:39:08.109 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-4, groupId=topic.group2] Group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2020-08-14 13:39:08.110 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-4, groupId=topic.group2] Discovered group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null)
2020-08-14 13:39:08.110 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-4, groupId=topic.group2] Group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2020-08-14 13:39:08.111 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-4, groupId=topic.group2] Discovered group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null)
2020-08-14 13:39:08.111 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-4, groupId=topic.group2] Group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2020-08-14 13:39:08.112 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-4, groupId=topic.group2] Discovered group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null)
2020-08-14 13:39:08.113 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-4, groupId=topic.group2] Group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2020-08-14 13:39:08.114 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-4, groupId=topic.group2] Discovered group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null)
2020-08-14 13:39:08.114 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-4, groupId=topic.group2] Group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2020-08-14 13:39:08.115 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-4, groupId=topic.group2] Discovered group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null)
2020-08-14 13:39:08.115 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-4, groupId=topic.group2] Group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2020-08-14 13:39:08.116 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-4, groupId=topic.group2] Discovered group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null)
2020-08-14 13:39:08.117 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-4, groupId=topic.group2] Group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2020-08-14 13:39:08.118 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-4, groupId=topic.group2] Discovered group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null)
2020-08-14 13:39:08.118 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-4, groupId=topic.group2] Group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2020-08-14 13:39:08.119 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-4, groupId=topic.group2] Discovered group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null)
2020-08-14 13:39:08.120 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-4, groupId=topic.group2] Group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2020-08-14 13:39:08.121 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-4, groupId=topic.group2] Discovered group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null)
2020-08-14 13:39:08.121 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-4, groupId=topic.group2] Group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2020-08-14 13:39:08.122 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-4, groupId=topic.group2] Discovered group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null)
2020-08-14 13:39:08.122 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-4, groupId=topic.group2] Group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2020-08-14 13:39:08.123 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-4, groupId=topic.group2] Discovered group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null)
2020-08-14 13:39:08.123 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-4, groupId=topic.group2] Group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2020-08-14 13:39:08.124 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-4, groupId=topic.group2] Discovered group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null)
2020-08-14 13:39:08.124 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-4, groupId=topic.group2] Group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2020-08-14 13:39:08.125 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-4, groupId=topic.group2] Discovered group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null)
2020-08-14 13:39:08.127 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-4, groupId=topic.group2] (Re-)joining group
2020-08-14 13:39:08.130 [pool-2-thread-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-new-11, groupId=new] Group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2020-08-14 13:39:08.130 [pool-2-thread-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-new-11, groupId=new] Join group failed with org.apache.kafka.common.errors.DisconnectException
2020-08-14 13:39:08.146 [org.springframework.kafka.KafkaListenerEndpointContainer#1-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-8, groupId=topic.group1] Attempt to heartbeat failed since group is rebalancing
2020-08-14 13:39:08.146 [org.springframework.kafka.KafkaListenerEndpointContainer#1-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-9, groupId=topic.group1] Attempt to heartbeat failed since group is rebalancing
2020-08-14 13:39:08.151 [org.springframework.kafka.KafkaListenerEndpointContainer#1-2-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group1-8, groupId=topic.group1] Revoke previously assigned partitions topic.test-1
2020-08-14 13:39:08.151 [org.springframework.kafka.KafkaListenerEndpointContainer#1-3-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group1-9, groupId=topic.group1] Revoke previously assigned partitions topic.test-2
2020-08-14 13:39:08.152 [org.springframework.kafka.KafkaListenerEndpointContainer#1-2-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - topic.group1: partitions revoked: [topic.test-1]
2020-08-14 13:39:08.152 [org.springframework.kafka.KafkaListenerEndpointContainer#1-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-8, groupId=topic.group1] (Re-)joining group
2020-08-14 13:39:08.152 [org.springframework.kafka.KafkaListenerEndpointContainer#1-3-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - topic.group1: partitions revoked: [topic.test-2]
2020-08-14 13:39:08.152 [org.springframework.kafka.KafkaListenerEndpointContainer#1-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-9, groupId=topic.group1] (Re-)joining group
2020-08-14 13:39:08.170 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-topic.group2-5, groupId=topic.group2] Cluster ID: JcD5Rmr-Rmu4LUPRR7vWMw
2020-08-14 13:39:08.196 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-topic.group1-6, groupId=topic.group1] Cluster ID: JcD5Rmr-Rmu4LUPRR7vWMw
2020-08-14 13:39:08.196 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-6, groupId=topic.group1] Discovered group coordinator ops-basic02.lingda.com:6667 (id: 2147483646 rack: null)
2020-08-14 13:39:08.197 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-6, groupId=topic.group1] (Re-)joining group
2020-08-14 13:39:08.202 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-topic.group1-10, groupId=topic.group1] Cluster ID: JcD5Rmr-Rmu4LUPRR7vWMw
2020-08-14 13:39:08.243 [pool-2-thread-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-new-11, groupId=new] Discovered group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null)
2020-08-14 13:39:08.244 [pool-2-thread-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-new-11, groupId=new] (Re-)joining group
2020-08-14 13:39:09.709 [org.springframework.kafka.KafkaListenerEndpointContainer#1-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-7, groupId=topic.group1] Attempt to heartbeat failed since group is rebalancing
2020-08-14 13:39:11.695 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group2-3, groupId=topic.group2] Unsubscribed all topics or patterns and assigned partitions
2020-08-14 13:39:11.695 [org.springframework.kafka.KafkaListenerEndpointContainer#1-1-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group1-7, groupId=topic.group1] Revoke previously assigned partitions topic.test-0
2020-08-14 13:39:11.695 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group1-6, groupId=topic.group1] Unsubscribed all topics or patterns and assigned partitions
2020-08-14 13:39:11.695 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group2-5, groupId=topic.group2] Unsubscribed all topics or patterns and assigned partitions
2020-08-14 13:39:11.696 [org.springframework.kafka.KafkaListenerEndpointContainer#1-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-9, groupId=topic.group1] Member consumer-topic.group1-9-722085f5-a131-4979-98f2-cf0aaa53c35f sending LeaveGroup request to coordinator ops-basic02.lingda.com:6667 (id: 2147483646 rack: null) due to the consumer unsubscribed from all topics
2020-08-14 13:39:11.695 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group2-4, groupId=topic.group2] Unsubscribed all topics or patterns and assigned partitions
2020-08-14 13:39:11.696 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Shutting down ExecutorService
2020-08-14 13:39:11.696 [org.springframework.kafka.KafkaListenerEndpointContainer#1-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-8, groupId=topic.group1] Member consumer-topic.group1-8-60cf36ed-e383-4bcc-b862-2ee5023886f5 sending LeaveGroup request to coordinator ops-basic02.lingda.com:6667 (id: 2147483646 rack: null) due to the consumer unsubscribed from all topics
2020-08-14 13:39:11.696 [org.springframework.kafka.KafkaListenerEndpointContainer#1-1-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - topic.group1: partitions revoked: [topic.test-0]
2020-08-14 13:39:11.696 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Shutting down ExecutorService
2020-08-14 13:39:11.696 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Shutting down ExecutorService
2020-08-14 13:39:11.695 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group2-2, groupId=topic.group2] Unsubscribed all topics or patterns and assigned partitions
2020-08-14 13:39:11.696 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Shutting down ExecutorService
2020-08-14 13:39:11.696 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group2-1, groupId=topic.group2] Unsubscribed all topics or patterns and assigned partitions
2020-08-14 13:39:11.696 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Shutting down ExecutorService
2020-08-14 13:39:11.697 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Shutting down ExecutorService
2020-08-14 13:39:11.696 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group1-10, groupId=topic.group1] Unsubscribed all topics or patterns and assigned partitions
2020-08-14 13:39:11.696 [org.springframework.kafka.KafkaListenerEndpointContainer#1-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-7, groupId=topic.group1] Member consumer-topic.group1-7-60b13803-962c-492a-ad89-c32ee3daba37 sending LeaveGroup request to coordinator ops-basic02.lingda.com:6667 (id: 2147483646 rack: null) due to the consumer unsubscribed from all topics
2020-08-14 13:39:11.697 [org.springframework.kafka.KafkaListenerEndpointContainer#1-3-C-1] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group1-9, groupId=topic.group1] Unsubscribed all topics or patterns and assigned partitions
2020-08-14 13:39:11.697 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Shutting down ExecutorService
2020-08-14 13:39:11.697 [org.springframework.kafka.KafkaListenerEndpointContainer#1-1-C-1] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group1-7, groupId=topic.group1] Unsubscribed all topics or patterns and assigned partitions
2020-08-14 13:39:11.697 [org.springframework.kafka.KafkaListenerEndpointContainer#1-3-C-1] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Shutting down ExecutorService
2020-08-14 13:39:11.697 [org.springframework.kafka.KafkaListenerEndpointContainer#1-1-C-1] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Shutting down ExecutorService
2020-08-14 13:39:11.698 [org.springframework.kafka.KafkaListenerEndpointContainer#1-2-C-1] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group1-8, groupId=topic.group1] Unsubscribed all topics or patterns and assigned partitions
2020-08-14 13:39:11.699 [org.springframework.kafka.KafkaListenerEndpointContainer#1-2-C-1] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Shutting down ExecutorService
2020-08-14 13:39:11.709 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - topic.group2: Consumer stopped
2020-08-14 13:39:11.711 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - topic.group1: Consumer stopped
2020-08-14 13:39:11.711 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - topic.group2: Consumer stopped
2020-08-14 13:39:11.712 [org.springframework.kafka.KafkaListenerEndpointContainer#1-3-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - topic.group1: Consumer stopped
2020-08-14 13:39:11.712 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - topic.group1: Consumer stopped
2020-08-14 13:39:11.713 [org.springframework.kafka.KafkaListenerEndpointContainer#1-1-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - topic.group1: Consumer stopped
2020-08-14 13:39:11.713 [org.springframework.kafka.KafkaListenerEndpointContainer#1-2-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - topic.group1: Consumer stopped
2020-08-14 13:39:29.107 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-5, groupId=topic.group2] Group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2020-08-14 13:39:29.109 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - topic.group2: Consumer stopped
2020-08-14 13:39:29.122 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-1, groupId=topic.group2] Group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2020-08-14 13:39:29.123 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - topic.group2: Consumer stopped
2020-08-14 13:39:29.169 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-4, groupId=topic.group2] Group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2020-08-14 13:39:29.170 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - topic.group2: Consumer stopped
2020-08-14 13:39:29.171 [SpringContextShutdownHook] INFO  o.s.scheduling.concurrent.ThreadPoolTaskExecutor - Shutting down ExecutorService 'applicationTaskExecutor'
2020-08-14 13:41:35.125 [main] INFO  com.kafka.demo.test.KafkaProducerSerTest - Starting KafkaProducerSerTest on LAPTOP-NFQDMTR9 with PID 6056 (started by sq in E:\otherProjects\kafkaDemo)
2020-08-14 13:41:35.126 [main] INFO  com.kafka.demo.test.KafkaProducerSerTest - No active profile set, falling back to default profiles: default
2020-08-14 13:41:36.036 [main] INFO  com.kafka.demo.clients.KafkaProducerSevice - 初始化:producer
2020-08-14 13:41:36.063 [main] INFO  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [192.168.100.213:6667, 192.168.100.214:6667, 192.168.100.215:6667]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 500
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2020-08-14 13:41:36.487 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.5.0
2020-08-14 13:41:36.489 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 66563e712b0b9f84
2020-08-14 13:41:36.489 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1597383696486
2020-08-14 13:41:36.916 [kafka-producer-network-thread | producer-1] INFO  org.apache.kafka.clients.Metadata - [Producer clientId=producer-1] Cluster ID: JcD5Rmr-Rmu4LUPRR7vWMw
2020-08-14 13:41:36.979 [main] INFO  o.s.scheduling.concurrent.ThreadPoolTaskExecutor - Initializing ExecutorService 'applicationTaskExecutor'
2020-08-14 13:41:37.423 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [192.168.100.213:6667, 192.168.100.214:6667, 192.168.100.215:6667]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = topic.group1
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 100
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-08-14 13:41:37.477 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.5.0
2020-08-14 13:41:37.478 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 66563e712b0b9f84
2020-08-14 13:41:37.478 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1597383697477
2020-08-14 13:41:37.479 [main] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group1-1, groupId=topic.group1] Subscribed to topic(s): topic.test
2020-08-14 13:41:37.481 [main] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Initializing ExecutorService
2020-08-14 13:41:37.487 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [192.168.100.213:6667, 192.168.100.214:6667, 192.168.100.215:6667]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = topic.group1
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 100
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-08-14 13:41:37.497 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.5.0
2020-08-14 13:41:37.498 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 66563e712b0b9f84
2020-08-14 13:41:37.499 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1597383697497
2020-08-14 13:41:37.500 [main] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group1-2, groupId=topic.group1] Subscribed to topic(s): topic.test
2020-08-14 13:41:37.500 [main] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Initializing ExecutorService
2020-08-14 13:41:37.501 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [192.168.100.213:6667, 192.168.100.214:6667, 192.168.100.215:6667]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = topic.group1
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 100
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-08-14 13:41:37.514 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-topic.group1-2, groupId=topic.group1] Cluster ID: JcD5Rmr-Rmu4LUPRR7vWMw
2020-08-14 13:41:37.514 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-topic.group1-1, groupId=topic.group1] Cluster ID: JcD5Rmr-Rmu4LUPRR7vWMw
2020-08-14 13:41:37.516 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-2, groupId=topic.group1] Discovered group coordinator ops-basic02.lingda.com:6667 (id: 2147483646 rack: null)
2020-08-14 13:41:37.516 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-1, groupId=topic.group1] Discovered group coordinator ops-basic02.lingda.com:6667 (id: 2147483646 rack: null)
2020-08-14 13:41:37.520 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.5.0
2020-08-14 13:41:37.520 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-2, groupId=topic.group1] (Re-)joining group
2020-08-14 13:41:37.520 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-1, groupId=topic.group1] (Re-)joining group
2020-08-14 13:41:37.520 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 66563e712b0b9f84
2020-08-14 13:41:37.520 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1597383697520
2020-08-14 13:41:37.521 [main] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group1-3, groupId=topic.group1] Subscribed to topic(s): topic.test
2020-08-14 13:41:37.521 [main] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Initializing ExecutorService
2020-08-14 13:41:37.524 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [192.168.100.213:6667, 192.168.100.214:6667, 192.168.100.215:6667]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = topic.group1
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 100
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-08-14 13:41:37.538 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-topic.group1-3, groupId=topic.group1] Cluster ID: JcD5Rmr-Rmu4LUPRR7vWMw
2020-08-14 13:41:37.539 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-3, groupId=topic.group1] Discovered group coordinator ops-basic02.lingda.com:6667 (id: 2147483646 rack: null)
2020-08-14 13:41:37.540 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-3, groupId=topic.group1] (Re-)joining group
2020-08-14 13:41:37.540 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.5.0
2020-08-14 13:41:37.540 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 66563e712b0b9f84
2020-08-14 13:41:37.541 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1597383697540
2020-08-14 13:41:37.541 [main] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group1-4, groupId=topic.group1] Subscribed to topic(s): topic.test
2020-08-14 13:41:37.541 [main] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Initializing ExecutorService
2020-08-14 13:41:37.543 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [192.168.100.213:6667, 192.168.100.214:6667, 192.168.100.215:6667]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = topic.group1
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 100
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-08-14 13:41:37.544 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group1-2, groupId=topic.group1] Finished assignment for group at generation 13: {consumer-topic.group1-2-7cd46234-d22f-4f2c-9d07-f4c7b5a32d85=Assignment(partitions=[topic.test-0, topic.test-1, topic.test-2])}
2020-08-14 13:41:37.548 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-2, groupId=topic.group1] Join group failed with org.apache.kafka.common.errors.RebalanceInProgressException: The group is rebalancing, so a rejoin is needed.
2020-08-14 13:41:37.548 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-2, groupId=topic.group1] (Re-)joining group
2020-08-14 13:41:37.550 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group1-2, groupId=topic.group1] Finished assignment for group at generation 14: {consumer-topic.group1-1-d75891d6-cb59-4b55-b6bc-ed56e163775f=Assignment(partitions=[topic.test-0]), consumer-topic.group1-3-51d9eab6-ad2c-4bee-9cfc-ac715283caa7=Assignment(partitions=[topic.test-2]), consumer-topic.group1-2-7cd46234-d22f-4f2c-9d07-f4c7b5a32d85=Assignment(partitions=[topic.test-1])}
2020-08-14 13:41:37.550 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-topic.group1-4, groupId=topic.group1] Cluster ID: JcD5Rmr-Rmu4LUPRR7vWMw
2020-08-14 13:41:37.551 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-4, groupId=topic.group1] Discovered group coordinator ops-basic02.lingda.com:6667 (id: 2147483646 rack: null)
2020-08-14 13:41:37.552 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-4, groupId=topic.group1] (Re-)joining group
2020-08-14 13:41:37.553 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.5.0
2020-08-14 13:41:37.553 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 66563e712b0b9f84
2020-08-14 13:41:37.554 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1597383697553
2020-08-14 13:41:37.554 [main] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group1-5, groupId=topic.group1] Subscribed to topic(s): topic.test
2020-08-14 13:41:37.554 [main] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Initializing ExecutorService
2020-08-14 13:41:37.556 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [192.168.100.213:6667, 192.168.100.214:6667, 192.168.100.215:6667]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = topic.group2
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 100
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-08-14 13:41:37.558 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-1, groupId=topic.group1] Join group failed with org.apache.kafka.common.errors.RebalanceInProgressException: The group is rebalancing, so a rejoin is needed.
2020-08-14 13:41:37.558 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-3, groupId=topic.group1] Join group failed with org.apache.kafka.common.errors.RebalanceInProgressException: The group is rebalancing, so a rejoin is needed.
2020-08-14 13:41:37.559 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-3, groupId=topic.group1] (Re-)joining group
2020-08-14 13:41:37.559 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-1, groupId=topic.group1] (Re-)joining group
2020-08-14 13:41:37.559 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-2, groupId=topic.group1] Join group failed with org.apache.kafka.common.errors.RebalanceInProgressException: The group is rebalancing, so a rejoin is needed.
2020-08-14 13:41:37.559 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-2, groupId=topic.group1] (Re-)joining group
2020-08-14 13:41:37.562 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group1-2, groupId=topic.group1] Finished assignment for group at generation 15: {consumer-topic.group1-4-ed467ea0-78e3-43d9-b4cb-43baf9529249=Assignment(partitions=[]), consumer-topic.group1-1-d75891d6-cb59-4b55-b6bc-ed56e163775f=Assignment(partitions=[topic.test-0]), consumer-topic.group1-3-51d9eab6-ad2c-4bee-9cfc-ac715283caa7=Assignment(partitions=[topic.test-2]), consumer-topic.group1-2-7cd46234-d22f-4f2c-9d07-f4c7b5a32d85=Assignment(partitions=[topic.test-1])}
2020-08-14 13:41:37.563 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-topic.group1-5, groupId=topic.group1] Cluster ID: JcD5Rmr-Rmu4LUPRR7vWMw
2020-08-14 13:41:37.564 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-5, groupId=topic.group1] Discovered group coordinator ops-basic02.lingda.com:6667 (id: 2147483646 rack: null)
2020-08-14 13:41:37.564 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.5.0
2020-08-14 13:41:37.565 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 66563e712b0b9f84
2020-08-14 13:41:37.565 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1597383697564
2020-08-14 13:41:37.565 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-5, groupId=topic.group1] (Re-)joining group
2020-08-14 13:41:37.565 [main] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group2-6, groupId=topic.group2] Subscribed to topic(s): topic.test
2020-08-14 13:41:37.566 [main] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Initializing ExecutorService
2020-08-14 13:41:37.567 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [192.168.100.213:6667, 192.168.100.214:6667, 192.168.100.215:6667]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = topic.group2
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 100
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-08-14 13:41:37.571 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-4, groupId=topic.group1] Join group failed with org.apache.kafka.common.errors.RebalanceInProgressException: The group is rebalancing, so a rejoin is needed.
2020-08-14 13:41:37.571 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-4, groupId=topic.group1] (Re-)joining group
2020-08-14 13:41:37.571 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-1, groupId=topic.group1] Join group failed with org.apache.kafka.common.errors.RebalanceInProgressException: The group is rebalancing, so a rejoin is needed.
2020-08-14 13:41:37.571 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-1, groupId=topic.group1] (Re-)joining group
2020-08-14 13:41:37.571 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-3, groupId=topic.group1] Join group failed with org.apache.kafka.common.errors.RebalanceInProgressException: The group is rebalancing, so a rejoin is needed.
2020-08-14 13:41:37.571 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-3, groupId=topic.group1] (Re-)joining group
2020-08-14 13:41:37.571 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-2, groupId=topic.group1] Join group failed with org.apache.kafka.common.errors.RebalanceInProgressException: The group is rebalancing, so a rejoin is needed.
2020-08-14 13:41:37.571 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-2, groupId=topic.group1] (Re-)joining group
2020-08-14 13:41:37.572 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-topic.group2-6, groupId=topic.group2] Cluster ID: JcD5Rmr-Rmu4LUPRR7vWMw
2020-08-14 13:41:37.573 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-6, groupId=topic.group2] Discovered group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null)
2020-08-14 13:41:37.573 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group1-2, groupId=topic.group1] Finished assignment for group at generation 16: {consumer-topic.group1-4-ed467ea0-78e3-43d9-b4cb-43baf9529249=Assignment(partitions=[]), consumer-topic.group1-1-d75891d6-cb59-4b55-b6bc-ed56e163775f=Assignment(partitions=[topic.test-0]), consumer-topic.group1-3-51d9eab6-ad2c-4bee-9cfc-ac715283caa7=Assignment(partitions=[topic.test-2]), consumer-topic.group1-5-de21e468-67b0-48ff-bf48-5ca31fb4111e=Assignment(partitions=[]), consumer-topic.group1-2-7cd46234-d22f-4f2c-9d07-f4c7b5a32d85=Assignment(partitions=[topic.test-1])}
2020-08-14 13:41:37.575 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-6, groupId=topic.group2] (Re-)joining group
2020-08-14 13:41:37.576 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.5.0
2020-08-14 13:41:37.576 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 66563e712b0b9f84
2020-08-14 13:41:37.576 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1597383697576
2020-08-14 13:41:37.577 [main] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group2-7, groupId=topic.group2] Subscribed to topic(s): topic.test
2020-08-14 13:41:37.577 [main] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Initializing ExecutorService
2020-08-14 13:41:37.578 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [192.168.100.213:6667, 192.168.100.214:6667, 192.168.100.215:6667]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = topic.group2
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 100
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-08-14 13:41:37.581 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-1, groupId=topic.group1] Successfully joined group with generation 16
2020-08-14 13:41:37.581 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-4, groupId=topic.group1] Successfully joined group with generation 16
2020-08-14 13:41:37.581 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-5, groupId=topic.group1] Successfully joined group with generation 16
2020-08-14 13:41:37.581 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-2, groupId=topic.group1] Successfully joined group with generation 16
2020-08-14 13:41:37.581 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-3, groupId=topic.group1] Successfully joined group with generation 16
2020-08-14 13:41:37.582 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group1-4, groupId=topic.group1] Adding newly assigned partitions: 
2020-08-14 13:41:37.582 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group1-5, groupId=topic.group1] Adding newly assigned partitions: 
2020-08-14 13:41:37.583 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - topic.group1: partitions assigned: []
2020-08-14 13:41:37.583 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - topic.group1: partitions assigned: []
2020-08-14 13:41:37.586 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group1-1, groupId=topic.group1] Adding newly assigned partitions: topic.test-0
2020-08-14 13:41:37.587 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group1-3, groupId=topic.group1] Adding newly assigned partitions: topic.test-2
2020-08-14 13:41:37.587 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group1-2, groupId=topic.group1] Adding newly assigned partitions: topic.test-1
2020-08-14 13:41:37.591 [org.springframework.kafka.KafkaListenerEndpointContainer#1-1-C-1] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-topic.group2-7, groupId=topic.group2] Cluster ID: JcD5Rmr-Rmu4LUPRR7vWMw
2020-08-14 13:41:37.592 [org.springframework.kafka.KafkaListenerEndpointContainer#1-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-7, groupId=topic.group2] Discovered group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null)
2020-08-14 13:41:37.593 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group1-1, groupId=topic.group1] Found no committed offset for partition topic.test-0
2020-08-14 13:41:37.593 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group1-3, groupId=topic.group1] Found no committed offset for partition topic.test-2
2020-08-14 13:41:37.593 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group1-2, groupId=topic.group1] Found no committed offset for partition topic.test-1
2020-08-14 13:41:37.593 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.5.0
2020-08-14 13:41:37.593 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 66563e712b0b9f84
2020-08-14 13:41:37.593 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1597383697593
2020-08-14 13:41:37.594 [main] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group2-8, groupId=topic.group2] Subscribed to topic(s): topic.test
2020-08-14 13:41:37.594 [main] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Initializing ExecutorService
2020-08-14 13:41:37.600 [org.springframework.kafka.KafkaListenerEndpointContainer#1-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-7, groupId=topic.group2] (Re-)joining group
2020-08-14 13:41:37.605 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [192.168.100.213:6667, 192.168.100.214:6667, 192.168.100.215:6667]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = topic.group2
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 100
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-08-14 13:41:37.607 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.a.k.clients.consumer.internals.SubscriptionState - [Consumer clientId=consumer-topic.group1-2, groupId=topic.group1] Resetting offset for partition topic.test-1 to offset 0.
2020-08-14 13:41:37.608 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - topic.group1: partitions assigned: [topic.test-1]
2020-08-14 13:41:37.610 [org.springframework.kafka.KafkaListenerEndpointContainer#1-2-C-1] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-topic.group2-8, groupId=topic.group2] Cluster ID: JcD5Rmr-Rmu4LUPRR7vWMw
2020-08-14 13:41:37.610 [org.springframework.kafka.KafkaListenerEndpointContainer#1-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-8, groupId=topic.group2] Discovered group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null)
2020-08-14 13:41:37.612 [org.springframework.kafka.KafkaListenerEndpointContainer#1-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-8, groupId=topic.group2] (Re-)joining group
2020-08-14 13:41:37.607 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  o.a.k.clients.consumer.internals.SubscriptionState - [Consumer clientId=consumer-topic.group1-3, groupId=topic.group1] Resetting offset for partition topic.test-2 to offset 1.
2020-08-14 13:41:37.613 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - topic.group1: partitions assigned: [topic.test-2]
2020-08-14 13:41:37.620 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.5.0
2020-08-14 13:41:37.620 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 66563e712b0b9f84
2020-08-14 13:41:37.620 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1597383697620
2020-08-14 13:41:37.621 [main] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group2-9, groupId=topic.group2] Subscribed to topic(s): topic.test
2020-08-14 13:41:37.621 [main] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Initializing ExecutorService
2020-08-14 13:41:37.623 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [192.168.100.213:6667, 192.168.100.214:6667, 192.168.100.215:6667]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = topic.group2
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 100
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-08-14 13:41:37.630 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.5.0
2020-08-14 13:41:37.631 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 66563e712b0b9f84
2020-08-14 13:41:37.631 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1597383697630
2020-08-14 13:41:37.631 [main] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group2-10, groupId=topic.group2] Subscribed to topic(s): topic.test
2020-08-14 13:41:37.631 [main] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Initializing ExecutorService
2020-08-14 13:41:37.638 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-topic.group2-10, groupId=topic.group2] Cluster ID: JcD5Rmr-Rmu4LUPRR7vWMw
2020-08-14 13:41:37.640 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-10, groupId=topic.group2] Discovered group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null)
2020-08-14 13:41:37.641 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-10, groupId=topic.group2] (Re-)joining group
2020-08-14 13:41:37.650 [main] INFO  com.kafka.demo.test.KafkaProducerSerTest - Started KafkaProducerSerTest in 3.108 seconds (JVM running for 4.051)
2020-08-14 13:41:37.658 [pool-2-thread-1] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [192.168.100.213:6667, 192.168.100.214:6667, 192.168.100.215:6667]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = new
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 100
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-08-14 13:41:37.666 [pool-2-thread-1] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.5.0
2020-08-14 13:41:37.666 [pool-2-thread-1] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 66563e712b0b9f84
2020-08-14 13:41:37.666 [pool-2-thread-1] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1597383697666
2020-08-14 13:41:37.667 [pool-2-thread-1] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-new-11, groupId=new] Subscribed to topic(s): topic.quick.initial
2020-08-14 13:41:37.673 [pool-2-thread-1] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-new-11, groupId=new] Cluster ID: JcD5Rmr-Rmu4LUPRR7vWMw
2020-08-14 13:41:37.673 [pool-2-thread-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-new-11, groupId=new] Discovered group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null)
2020-08-14 13:41:37.674 [pool-2-thread-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-new-11, groupId=new] (Re-)joining group
2020-08-14 13:41:41.038 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group1-1, groupId=topic.group1] Revoke previously assigned partitions topic.test-0
2020-08-14 13:41:41.039 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - topic.group1: partitions revoked: [topic.test-0]
2020-08-14 13:41:41.039 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-1, groupId=topic.group1] Member consumer-topic.group1-1-d75891d6-cb59-4b55-b6bc-ed56e163775f sending LeaveGroup request to coordinator ops-basic02.lingda.com:6667 (id: 2147483646 rack: null) due to the consumer unsubscribed from all topics
2020-08-14 13:41:41.040 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group1-1, groupId=topic.group1] Unsubscribed all topics or patterns and assigned partitions
2020-08-14 13:41:41.040 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-4, groupId=topic.group1] Member consumer-topic.group1-4-ed467ea0-78e3-43d9-b4cb-43baf9529249 sending LeaveGroup request to coordinator ops-basic02.lingda.com:6667 (id: 2147483646 rack: null) due to the consumer unsubscribed from all topics
2020-08-14 13:41:41.040 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Shutting down ExecutorService
2020-08-14 13:41:41.040 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group1-4, groupId=topic.group1] Unsubscribed all topics or patterns and assigned partitions
2020-08-14 13:41:41.041 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Shutting down ExecutorService
2020-08-14 13:41:41.041 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-5, groupId=topic.group1] Member consumer-topic.group1-5-de21e468-67b0-48ff-bf48-5ca31fb4111e sending LeaveGroup request to coordinator ops-basic02.lingda.com:6667 (id: 2147483646 rack: null) due to the consumer unsubscribed from all topics
2020-08-14 13:41:41.041 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group1-5, groupId=topic.group1] Unsubscribed all topics or patterns and assigned partitions
2020-08-14 13:41:41.041 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group2-6, groupId=topic.group2] Unsubscribed all topics or patterns and assigned partitions
2020-08-14 13:41:41.042 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Shutting down ExecutorService
2020-08-14 13:41:41.042 [org.springframework.kafka.KafkaListenerEndpointContainer#1-1-C-1] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group2-7, groupId=topic.group2] Unsubscribed all topics or patterns and assigned partitions
2020-08-14 13:41:41.042 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Shutting down ExecutorService
2020-08-14 13:41:41.042 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group1-2, groupId=topic.group1] Revoke previously assigned partitions topic.test-1
2020-08-14 13:41:41.042 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group1-3, groupId=topic.group1] Revoke previously assigned partitions topic.test-2
2020-08-14 13:41:41.042 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - topic.group1: partitions revoked: [topic.test-1]
2020-08-14 13:41:41.042 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - topic.group1: partitions revoked: [topic.test-2]
2020-08-14 13:41:41.042 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-2, groupId=topic.group1] Member consumer-topic.group1-2-7cd46234-d22f-4f2c-9d07-f4c7b5a32d85 sending LeaveGroup request to coordinator ops-basic02.lingda.com:6667 (id: 2147483646 rack: null) due to the consumer unsubscribed from all topics
2020-08-14 13:41:41.043 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-3, groupId=topic.group1] Member consumer-topic.group1-3-51d9eab6-ad2c-4bee-9cfc-ac715283caa7 sending LeaveGroup request to coordinator ops-basic02.lingda.com:6667 (id: 2147483646 rack: null) due to the consumer unsubscribed from all topics
2020-08-14 13:41:41.043 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group1-2, groupId=topic.group1] Unsubscribed all topics or patterns and assigned partitions
2020-08-14 13:41:41.043 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group1-3, groupId=topic.group1] Unsubscribed all topics or patterns and assigned partitions
2020-08-14 13:41:41.042 [org.springframework.kafka.KafkaListenerEndpointContainer#1-1-C-1] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Shutting down ExecutorService
2020-08-14 13:41:41.043 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Shutting down ExecutorService
2020-08-14 13:41:41.043 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Shutting down ExecutorService
2020-08-14 13:41:41.044 [org.springframework.kafka.KafkaListenerEndpointContainer#1-3-C-1] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group2-9, groupId=topic.group2] Unsubscribed all topics or patterns and assigned partitions
2020-08-14 13:41:41.044 [org.springframework.kafka.KafkaListenerEndpointContainer#1-3-C-1] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Shutting down ExecutorService
2020-08-14 13:41:41.046 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group2-10, groupId=topic.group2] Unsubscribed all topics or patterns and assigned partitions
2020-08-14 13:41:41.046 [org.springframework.kafka.KafkaListenerEndpointContainer#1-2-C-1] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group2-8, groupId=topic.group2] Unsubscribed all topics or patterns and assigned partitions
2020-08-14 13:41:41.046 [org.springframework.kafka.KafkaListenerEndpointContainer#1-2-C-1] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Shutting down ExecutorService
2020-08-14 13:41:41.046 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Shutting down ExecutorService
2020-08-14 13:41:41.060 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - topic.group1: Consumer stopped
2020-08-14 13:41:41.060 [org.springframework.kafka.KafkaListenerEndpointContainer#1-3-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - topic.group2: Consumer stopped
2020-08-14 13:41:41.061 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - topic.group1: Consumer stopped
2020-08-14 13:41:41.061 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - topic.group1: Consumer stopped
2020-08-14 13:41:41.061 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - topic.group1: Consumer stopped
2020-08-14 13:41:41.061 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - topic.group1: Consumer stopped
2020-08-14 13:41:58.641 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-6, groupId=topic.group2] Group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2020-08-14 13:41:58.641 [org.springframework.kafka.KafkaListenerEndpointContainer#1-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-7, groupId=topic.group2] Group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2020-08-14 13:41:58.649 [org.springframework.kafka.KafkaListenerEndpointContainer#1-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-8, groupId=topic.group2] Group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2020-08-14 13:41:58.652 [org.springframework.kafka.KafkaListenerEndpointContainer#1-1-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - topic.group2: Consumer stopped
2020-08-14 13:41:58.653 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - topic.group2: Consumer stopped
2020-08-14 13:41:58.653 [org.springframework.kafka.KafkaListenerEndpointContainer#1-2-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - topic.group2: Consumer stopped
2020-08-14 13:41:58.690 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-10, groupId=topic.group2] Group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2020-08-14 13:41:58.691 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - topic.group2: Consumer stopped
2020-08-14 13:41:58.692 [SpringContextShutdownHook] INFO  o.s.scheduling.concurrent.ThreadPoolTaskExecutor - Shutting down ExecutorService 'applicationTaskExecutor'
2020-08-14 13:45:51.852 [main] INFO  com.kafka.demo.test.KafkaProducerSerTest - Starting KafkaProducerSerTest on LAPTOP-NFQDMTR9 with PID 20732 (started by sq in E:\otherProjects\kafkaDemo)
2020-08-14 13:45:51.853 [main] INFO  com.kafka.demo.test.KafkaProducerSerTest - No active profile set, falling back to default profiles: default
2020-08-14 13:45:52.877 [main] INFO  com.kafka.demo.clients.KafkaProducerSevice - 初始化:producer
2020-08-14 13:45:52.908 [main] INFO  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [192.168.100.213:6667, 192.168.100.214:6667, 192.168.100.215:6667]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 500
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2020-08-14 13:45:53.376 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.5.0
2020-08-14 13:45:53.378 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 66563e712b0b9f84
2020-08-14 13:45:53.378 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1597383953374
2020-08-14 13:45:53.815 [kafka-producer-network-thread | producer-1] INFO  org.apache.kafka.clients.Metadata - [Producer clientId=producer-1] Cluster ID: JcD5Rmr-Rmu4LUPRR7vWMw
2020-08-14 13:45:53.885 [main] INFO  o.s.scheduling.concurrent.ThreadPoolTaskExecutor - Initializing ExecutorService 'applicationTaskExecutor'
2020-08-14 13:45:54.324 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [192.168.100.213:6667, 192.168.100.214:6667, 192.168.100.215:6667]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = topic.group1
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 100
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-08-14 13:45:54.364 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.5.0
2020-08-14 13:45:54.364 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 66563e712b0b9f84
2020-08-14 13:45:54.364 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1597383954364
2020-08-14 13:45:54.365 [main] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group1-1, groupId=topic.group1] Subscribed to topic(s): topic.test
2020-08-14 13:45:54.367 [main] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Initializing ExecutorService
2020-08-14 13:45:54.372 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [192.168.100.213:6667, 192.168.100.214:6667, 192.168.100.215:6667]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = topic.group1
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 100
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-08-14 13:45:54.382 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.5.0
2020-08-14 13:45:54.382 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 66563e712b0b9f84
2020-08-14 13:45:54.382 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1597383954382
2020-08-14 13:45:54.382 [main] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group1-2, groupId=topic.group1] Subscribed to topic(s): topic.test
2020-08-14 13:45:54.383 [main] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Initializing ExecutorService
2020-08-14 13:45:54.384 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [192.168.100.213:6667, 192.168.100.214:6667, 192.168.100.215:6667]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = topic.group1
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 100
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-08-14 13:45:54.390 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-topic.group1-1, groupId=topic.group1] Cluster ID: JcD5Rmr-Rmu4LUPRR7vWMw
2020-08-14 13:45:54.391 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.5.0
2020-08-14 13:45:54.391 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-1, groupId=topic.group1] Discovered group coordinator ops-basic02.lingda.com:6667 (id: 2147483646 rack: null)
2020-08-14 13:45:54.391 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 66563e712b0b9f84
2020-08-14 13:45:54.391 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1597383954391
2020-08-14 13:45:54.392 [main] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group1-3, groupId=topic.group1] Subscribed to topic(s): topic.test
2020-08-14 13:45:54.392 [main] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Initializing ExecutorService
2020-08-14 13:45:54.393 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [192.168.100.213:6667, 192.168.100.214:6667, 192.168.100.215:6667]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = topic.group1
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 100
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-08-14 13:45:54.394 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-1, groupId=topic.group1] (Re-)joining group
2020-08-14 13:45:54.406 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.5.0
2020-08-14 13:45:54.406 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 66563e712b0b9f84
2020-08-14 13:45:54.406 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1597383954406
2020-08-14 13:45:54.407 [main] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group1-4, groupId=topic.group1] Subscribed to topic(s): topic.test
2020-08-14 13:45:54.407 [main] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Initializing ExecutorService
2020-08-14 13:45:54.408 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [192.168.100.213:6667, 192.168.100.214:6667, 192.168.100.215:6667]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = topic.group1
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 100
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-08-14 13:45:54.413 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.5.0
2020-08-14 13:45:54.414 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 66563e712b0b9f84
2020-08-14 13:45:54.414 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1597383954413
2020-08-14 13:45:54.414 [main] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group1-5, groupId=topic.group1] Subscribed to topic(s): topic.test
2020-08-14 13:45:54.414 [main] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Initializing ExecutorService
2020-08-14 13:45:54.416 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [192.168.100.213:6667, 192.168.100.214:6667, 192.168.100.215:6667]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = topic.group2
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 100
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-08-14 13:45:54.418 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group1-1, groupId=topic.group1] Finished assignment for group at generation 18: {consumer-topic.group1-1-ed37905e-0ec6-4016-a804-17fc40289536=Assignment(partitions=[topic.test-0, topic.test-1, topic.test-2])}
2020-08-14 13:45:54.421 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.5.0
2020-08-14 13:45:54.421 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 66563e712b0b9f84
2020-08-14 13:45:54.422 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1597383954421
2020-08-14 13:45:54.422 [main] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group2-6, groupId=topic.group2] Subscribed to topic(s): topic.test
2020-08-14 13:45:54.422 [main] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Initializing ExecutorService
2020-08-14 13:45:54.423 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [192.168.100.213:6667, 192.168.100.214:6667, 192.168.100.215:6667]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = topic.group2
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 100
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-08-14 13:45:54.428 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.5.0
2020-08-14 13:45:54.428 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 66563e712b0b9f84
2020-08-14 13:45:54.428 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1597383954428
2020-08-14 13:45:54.428 [main] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group2-7, groupId=topic.group2] Subscribed to topic(s): topic.test
2020-08-14 13:45:54.428 [main] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Initializing ExecutorService
2020-08-14 13:45:54.429 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [192.168.100.213:6667, 192.168.100.214:6667, 192.168.100.215:6667]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = topic.group2
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 100
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-08-14 13:45:54.432 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-1, groupId=topic.group1] Successfully joined group with generation 18
2020-08-14 13:45:54.436 [org.springframework.kafka.KafkaListenerEndpointContainer#1-1-C-1] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-topic.group2-7, groupId=topic.group2] Cluster ID: JcD5Rmr-Rmu4LUPRR7vWMw
2020-08-14 13:45:54.436 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.5.0
2020-08-14 13:45:54.436 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 66563e712b0b9f84
2020-08-14 13:45:54.436 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1597383954436
2020-08-14 13:45:54.436 [org.springframework.kafka.KafkaListenerEndpointContainer#1-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-7, groupId=topic.group2] Discovered group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null)
2020-08-14 13:45:54.437 [main] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group2-8, groupId=topic.group2] Subscribed to topic(s): topic.test
2020-08-14 13:45:54.437 [main] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Initializing ExecutorService
2020-08-14 13:45:54.437 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group1-1, groupId=topic.group1] Adding newly assigned partitions: topic.test-0, topic.test-1, topic.test-2
2020-08-14 13:45:54.438 [org.springframework.kafka.KafkaListenerEndpointContainer#1-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-7, groupId=topic.group2] (Re-)joining group
2020-08-14 13:45:54.439 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [192.168.100.213:6667, 192.168.100.214:6667, 192.168.100.215:6667]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = topic.group2
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 100
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-08-14 13:45:54.443 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.5.0
2020-08-14 13:45:54.444 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 66563e712b0b9f84
2020-08-14 13:45:54.444 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1597383954443
2020-08-14 13:45:54.444 [main] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group2-9, groupId=topic.group2] Subscribed to topic(s): topic.test
2020-08-14 13:45:54.444 [main] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Initializing ExecutorService
2020-08-14 13:45:54.445 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [192.168.100.213:6667, 192.168.100.214:6667, 192.168.100.215:6667]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = topic.group2
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 100
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-08-14 13:45:54.446 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group1-1, groupId=topic.group1] Found no committed offset for partition topic.test-0
2020-08-14 13:45:54.447 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group1-1, groupId=topic.group1] Found no committed offset for partition topic.test-1
2020-08-14 13:45:54.447 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group1-1, groupId=topic.group1] Found no committed offset for partition topic.test-2
2020-08-14 13:45:54.450 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.5.0
2020-08-14 13:45:54.451 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 66563e712b0b9f84
2020-08-14 13:45:54.451 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1597383954450
2020-08-14 13:45:54.452 [main] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group2-10, groupId=topic.group2] Subscribed to topic(s): topic.test
2020-08-14 13:45:54.452 [main] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Initializing ExecutorService
2020-08-14 13:45:54.458 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-topic.group2-10, groupId=topic.group2] Cluster ID: JcD5Rmr-Rmu4LUPRR7vWMw
2020-08-14 13:45:54.459 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-10, groupId=topic.group2] Discovered group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null)
2020-08-14 13:45:54.460 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-10, groupId=topic.group2] (Re-)joining group
2020-08-14 13:45:54.461 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.clients.consumer.internals.SubscriptionState - [Consumer clientId=consumer-topic.group1-1, groupId=topic.group1] Resetting offset for partition topic.test-2 to offset 1.
2020-08-14 13:45:54.463 [main] INFO  com.kafka.demo.test.KafkaProducerSerTest - Started KafkaProducerSerTest in 3.185 seconds (JVM running for 4.162)
2020-08-14 13:45:54.463 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.clients.consumer.internals.SubscriptionState - [Consumer clientId=consumer-topic.group1-1, groupId=topic.group1] Resetting offset for partition topic.test-1 to offset 0.
2020-08-14 13:45:54.468 [pool-2-thread-1] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [192.168.100.213:6667, 192.168.100.214:6667, 192.168.100.215:6667]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = new
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 100
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-08-14 13:45:54.475 [pool-2-thread-1] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.5.0
2020-08-14 13:45:54.475 [pool-2-thread-1] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 66563e712b0b9f84
2020-08-14 13:45:54.475 [pool-2-thread-1] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1597383954475
2020-08-14 13:45:54.476 [pool-2-thread-1] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-new-11, groupId=new] Subscribed to topic(s): topic.quick.initial
2020-08-14 13:45:54.482 [pool-2-thread-1] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-new-11, groupId=new] Cluster ID: JcD5Rmr-Rmu4LUPRR7vWMw
2020-08-14 13:45:54.482 [pool-2-thread-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-new-11, groupId=new] Discovered group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null)
2020-08-14 13:45:54.483 [pool-2-thread-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-new-11, groupId=new] (Re-)joining group
2020-08-14 13:45:57.823 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group1-5, groupId=topic.group1] Unsubscribed all topics or patterns and assigned partitions
2020-08-14 13:45:57.823 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group1-1, groupId=topic.group1] Revoke previously assigned partitions topic.test-0, topic.test-1, topic.test-2
2020-08-14 13:45:57.823 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group1-2, groupId=topic.group1] Unsubscribed all topics or patterns and assigned partitions
2020-08-14 13:45:57.824 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Shutting down ExecutorService
2020-08-14 13:45:57.824 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Shutting down ExecutorService
2020-08-14 13:45:57.823 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group1-4, groupId=topic.group1] Unsubscribed all topics or patterns and assigned partitions
2020-08-14 13:45:57.824 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Shutting down ExecutorService
2020-08-14 13:45:57.824 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - topic.group1: partitions revoked: [topic.test-0, topic.test-1, topic.test-2]
2020-08-14 13:45:57.824 [org.springframework.kafka.KafkaListenerEndpointContainer#1-3-C-1] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group2-9, groupId=topic.group2] Unsubscribed all topics or patterns and assigned partitions
2020-08-14 13:45:57.823 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group1-3, groupId=topic.group1] Unsubscribed all topics or patterns and assigned partitions
2020-08-14 13:45:57.824 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group2-6, groupId=topic.group2] Unsubscribed all topics or patterns and assigned partitions
2020-08-14 13:45:57.824 [org.springframework.kafka.KafkaListenerEndpointContainer#1-2-C-1] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group2-8, groupId=topic.group2] Unsubscribed all topics or patterns and assigned partitions
2020-08-14 13:45:57.824 [org.springframework.kafka.KafkaListenerEndpointContainer#1-3-C-1] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Shutting down ExecutorService
2020-08-14 13:45:57.824 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-1, groupId=topic.group1] Member consumer-topic.group1-1-ed37905e-0ec6-4016-a804-17fc40289536 sending LeaveGroup request to coordinator ops-basic02.lingda.com:6667 (id: 2147483646 rack: null) due to the consumer unsubscribed from all topics
2020-08-14 13:45:57.825 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Shutting down ExecutorService
2020-08-14 13:45:57.825 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Shutting down ExecutorService
2020-08-14 13:45:57.825 [org.springframework.kafka.KafkaListenerEndpointContainer#1-2-C-1] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Shutting down ExecutorService
2020-08-14 13:45:57.826 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group1-1, groupId=topic.group1] Unsubscribed all topics or patterns and assigned partitions
2020-08-14 13:45:57.827 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Shutting down ExecutorService
2020-08-14 13:45:57.825 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group2-10, groupId=topic.group2] Unsubscribed all topics or patterns and assigned partitions
2020-08-14 13:45:57.825 [org.springframework.kafka.KafkaListenerEndpointContainer#1-1-C-1] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group2-7, groupId=topic.group2] Unsubscribed all topics or patterns and assigned partitions
2020-08-14 13:45:57.828 [org.springframework.kafka.KafkaListenerEndpointContainer#1-1-C-1] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Shutting down ExecutorService
2020-08-14 13:45:57.828 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Shutting down ExecutorService
2020-08-14 13:45:57.832 [org.springframework.kafka.KafkaListenerEndpointContainer#1-3-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - topic.group2: Consumer stopped
2020-08-14 13:45:57.832 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - topic.group1: Consumer stopped
2020-08-14 13:45:57.833 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - topic.group2: Consumer stopped
2020-08-14 13:45:57.835 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - topic.group1: Consumer stopped
2020-08-14 13:45:57.835 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - topic.group1: Consumer stopped
2020-08-14 13:45:57.836 [org.springframework.kafka.KafkaListenerEndpointContainer#1-2-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - topic.group2: Consumer stopped
2020-08-14 13:45:57.836 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - topic.group1: Consumer stopped
2020-08-14 13:45:57.837 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - topic.group1: Consumer stopped
2020-08-14 13:46:15.481 [org.springframework.kafka.KafkaListenerEndpointContainer#1-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-7, groupId=topic.group2] Group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2020-08-14 13:46:15.485 [org.springframework.kafka.KafkaListenerEndpointContainer#1-1-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - topic.group2: Consumer stopped
2020-08-14 13:46:15.490 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-10, groupId=topic.group2] Group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2020-08-14 13:46:15.492 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - topic.group2: Consumer stopped
2020-08-14 13:46:15.493 [SpringContextShutdownHook] INFO  o.s.scheduling.concurrent.ThreadPoolTaskExecutor - Shutting down ExecutorService 'applicationTaskExecutor'
2020-08-14 13:46:27.002 [main] INFO  com.kafka.demo.test.KafkaProducerSerTest - Starting KafkaProducerSerTest on LAPTOP-NFQDMTR9 with PID 18604 (started by sq in E:\otherProjects\kafkaDemo)
2020-08-14 13:46:27.004 [main] INFO  com.kafka.demo.test.KafkaProducerSerTest - No active profile set, falling back to default profiles: default
2020-08-14 13:46:28.064 [main] INFO  com.kafka.demo.clients.KafkaProducerSevice - 初始化:producer
2020-08-14 13:46:28.096 [main] INFO  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [192.168.100.213:6667, 192.168.100.214:6667, 192.168.100.215:6667]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 500
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2020-08-14 13:46:28.596 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.5.0
2020-08-14 13:46:28.598 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 66563e712b0b9f84
2020-08-14 13:46:28.598 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1597383988594
2020-08-14 13:46:29.157 [kafka-producer-network-thread | producer-1] INFO  org.apache.kafka.clients.Metadata - [Producer clientId=producer-1] Cluster ID: JcD5Rmr-Rmu4LUPRR7vWMw
2020-08-14 13:46:29.275 [main] INFO  o.s.scheduling.concurrent.ThreadPoolTaskExecutor - Initializing ExecutorService 'applicationTaskExecutor'
2020-08-14 13:46:29.864 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [192.168.100.213:6667, 192.168.100.214:6667, 192.168.100.215:6667]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = topic.group1
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 100
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-08-14 13:46:29.918 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.5.0
2020-08-14 13:46:29.919 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 66563e712b0b9f84
2020-08-14 13:46:29.919 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1597383989918
2020-08-14 13:46:29.921 [main] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group1-1, groupId=topic.group1] Subscribed to topic(s): topic.test
2020-08-14 13:46:29.925 [main] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Initializing ExecutorService
2020-08-14 13:46:29.933 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [192.168.100.213:6667, 192.168.100.214:6667, 192.168.100.215:6667]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = topic.group1
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 100
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-08-14 13:46:29.945 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.5.0
2020-08-14 13:46:29.945 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 66563e712b0b9f84
2020-08-14 13:46:29.946 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1597383989945
2020-08-14 13:46:29.947 [main] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group1-2, groupId=topic.group1] Subscribed to topic(s): topic.test
2020-08-14 13:46:29.948 [main] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Initializing ExecutorService
2020-08-14 13:46:29.950 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [192.168.100.213:6667, 192.168.100.214:6667, 192.168.100.215:6667]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = topic.group1
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 100
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-08-14 13:46:29.961 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-topic.group1-2, groupId=topic.group1] Cluster ID: JcD5Rmr-Rmu4LUPRR7vWMw
2020-08-14 13:46:29.961 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-topic.group1-1, groupId=topic.group1] Cluster ID: JcD5Rmr-Rmu4LUPRR7vWMw
2020-08-14 13:46:29.962 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.5.0
2020-08-14 13:46:29.962 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 66563e712b0b9f84
2020-08-14 13:46:29.962 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1597383989962
2020-08-14 13:46:29.963 [main] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group1-3, groupId=topic.group1] Subscribed to topic(s): topic.test
2020-08-14 13:46:29.963 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-1, groupId=topic.group1] Discovered group coordinator ops-basic02.lingda.com:6667 (id: 2147483646 rack: null)
2020-08-14 13:46:29.963 [main] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Initializing ExecutorService
2020-08-14 13:46:29.963 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-2, groupId=topic.group1] Discovered group coordinator ops-basic02.lingda.com:6667 (id: 2147483646 rack: null)
2020-08-14 13:46:29.966 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [192.168.100.213:6667, 192.168.100.214:6667, 192.168.100.215:6667]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = topic.group1
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 100
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-08-14 13:46:29.967 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-1, groupId=topic.group1] (Re-)joining group
2020-08-14 13:46:29.967 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-2, groupId=topic.group1] (Re-)joining group
2020-08-14 13:46:29.982 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-topic.group1-3, groupId=topic.group1] Cluster ID: JcD5Rmr-Rmu4LUPRR7vWMw
2020-08-14 13:46:29.983 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-3, groupId=topic.group1] Discovered group coordinator ops-basic02.lingda.com:6667 (id: 2147483646 rack: null)
2020-08-14 13:46:29.984 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-3, groupId=topic.group1] (Re-)joining group
2020-08-14 13:46:29.986 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.5.0
2020-08-14 13:46:29.986 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 66563e712b0b9f84
2020-08-14 13:46:29.987 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1597383989986
2020-08-14 13:46:29.987 [main] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group1-4, groupId=topic.group1] Subscribed to topic(s): topic.test
2020-08-14 13:46:29.988 [main] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Initializing ExecutorService
2020-08-14 13:46:29.990 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group1-2, groupId=topic.group1] Finished assignment for group at generation 20: {consumer-topic.group1-2-84120cc6-de43-49f4-94ac-1dd77ce1499f=Assignment(partitions=[topic.test-0, topic.test-1, topic.test-2])}
2020-08-14 13:46:29.993 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [192.168.100.213:6667, 192.168.100.214:6667, 192.168.100.215:6667]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = topic.group1
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 100
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-08-14 13:46:29.996 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-2, groupId=topic.group1] Join group failed with org.apache.kafka.common.errors.RebalanceInProgressException: The group is rebalancing, so a rejoin is needed.
2020-08-14 13:46:29.996 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-2, groupId=topic.group1] (Re-)joining group
2020-08-14 13:46:29.998 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group1-2, groupId=topic.group1] Finished assignment for group at generation 21: {consumer-topic.group1-2-84120cc6-de43-49f4-94ac-1dd77ce1499f=Assignment(partitions=[topic.test-1]), consumer-topic.group1-3-21f61ab4-ad4d-4456-9bf4-b042cd12e9e8=Assignment(partitions=[topic.test-2]), consumer-topic.group1-1-cd562688-5d35-49ea-a7c7-b22fbb3fca3c=Assignment(partitions=[topic.test-0])}
2020-08-14 13:46:30.004 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.5.0
2020-08-14 13:46:30.005 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 66563e712b0b9f84
2020-08-14 13:46:30.005 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1597383990004
2020-08-14 13:46:30.005 [main] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group1-5, groupId=topic.group1] Subscribed to topic(s): topic.test
2020-08-14 13:46:30.006 [main] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Initializing ExecutorService
2020-08-14 13:46:30.007 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [192.168.100.213:6667, 192.168.100.214:6667, 192.168.100.215:6667]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = topic.group2
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 100
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-08-14 13:46:30.014 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.5.0
2020-08-14 13:46:30.015 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 66563e712b0b9f84
2020-08-14 13:46:30.015 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1597383990014
2020-08-14 13:46:30.015 [main] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group2-6, groupId=topic.group2] Subscribed to topic(s): topic.test
2020-08-14 13:46:30.015 [main] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Initializing ExecutorService
2020-08-14 13:46:30.017 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [192.168.100.213:6667, 192.168.100.214:6667, 192.168.100.215:6667]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = topic.group2
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 100
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-08-14 13:46:30.023 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.5.0
2020-08-14 13:46:30.024 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 66563e712b0b9f84
2020-08-14 13:46:30.024 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1597383990023
2020-08-14 13:46:30.024 [main] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group2-7, groupId=topic.group2] Subscribed to topic(s): topic.test
2020-08-14 13:46:30.024 [main] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Initializing ExecutorService
2020-08-14 13:46:30.026 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [192.168.100.213:6667, 192.168.100.214:6667, 192.168.100.215:6667]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = topic.group2
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 100
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-08-14 13:46:30.027 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-3, groupId=topic.group1] Successfully joined group with generation 21
2020-08-14 13:46:30.027 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-topic.group1-4, groupId=topic.group1] Cluster ID: JcD5Rmr-Rmu4LUPRR7vWMw
2020-08-14 13:46:30.028 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-2, groupId=topic.group1] Successfully joined group with generation 21
2020-08-14 13:46:30.028 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-1, groupId=topic.group1] Successfully joined group with generation 21
2020-08-14 13:46:30.029 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-4, groupId=topic.group1] Discovered group coordinator ops-basic02.lingda.com:6667 (id: 2147483646 rack: null)
2020-08-14 13:46:30.031 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-4, groupId=topic.group1] (Re-)joining group
2020-08-14 13:46:30.034 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group1-3, groupId=topic.group1] Adding newly assigned partitions: topic.test-2
2020-08-14 13:46:30.038 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group1-2, groupId=topic.group1] Adding newly assigned partitions: topic.test-1
2020-08-14 13:46:30.038 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group1-1, groupId=topic.group1] Adding newly assigned partitions: topic.test-0
2020-08-14 13:46:30.044 [org.springframework.kafka.KafkaListenerEndpointContainer#1-1-C-1] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-topic.group2-7, groupId=topic.group2] Cluster ID: JcD5Rmr-Rmu4LUPRR7vWMw
2020-08-14 13:46:30.046 [org.springframework.kafka.KafkaListenerEndpointContainer#1-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-7, groupId=topic.group2] Discovered group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null)
2020-08-14 13:46:30.044 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.5.0
2020-08-14 13:46:30.047 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 66563e712b0b9f84
2020-08-14 13:46:30.049 [org.springframework.kafka.KafkaListenerEndpointContainer#1-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-7, groupId=topic.group2] (Re-)joining group
2020-08-14 13:46:30.048 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1597383990044
2020-08-14 13:46:30.051 [main] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group2-8, groupId=topic.group2] Subscribed to topic(s): topic.test
2020-08-14 13:46:30.052 [main] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Initializing ExecutorService
2020-08-14 13:46:30.055 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group1-3, groupId=topic.group1] Found no committed offset for partition topic.test-2
2020-08-14 13:46:30.055 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group1-2, groupId=topic.group1] Found no committed offset for partition topic.test-1
2020-08-14 13:46:30.056 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [192.168.100.213:6667, 192.168.100.214:6667, 192.168.100.215:6667]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = topic.group2
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 100
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-08-14 13:46:30.055 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group1-1, groupId=topic.group1] Found no committed offset for partition topic.test-0
2020-08-14 13:46:30.070 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.5.0
2020-08-14 13:46:30.070 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 66563e712b0b9f84
2020-08-14 13:46:30.070 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1597383990070
2020-08-14 13:46:30.071 [main] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group2-9, groupId=topic.group2] Subscribed to topic(s): topic.test
2020-08-14 13:46:30.071 [main] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Initializing ExecutorService
2020-08-14 13:46:30.072 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.a.k.clients.consumer.internals.SubscriptionState - [Consumer clientId=consumer-topic.group1-2, groupId=topic.group1] Resetting offset for partition topic.test-1 to offset 0.
2020-08-14 13:46:30.073 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  o.a.k.clients.consumer.internals.SubscriptionState - [Consumer clientId=consumer-topic.group1-3, groupId=topic.group1] Resetting offset for partition topic.test-2 to offset 1.
2020-08-14 13:46:30.074 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - topic.group1: partitions assigned: [topic.test-2]
2020-08-14 13:46:30.074 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - topic.group1: partitions assigned: [topic.test-1]
2020-08-14 13:46:30.077 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [192.168.100.213:6667, 192.168.100.214:6667, 192.168.100.215:6667]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = topic.group2
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 100
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-08-14 13:46:30.088 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.5.0
2020-08-14 13:46:30.088 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 66563e712b0b9f84
2020-08-14 13:46:30.088 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1597383990088
2020-08-14 13:46:30.089 [main] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group2-10, groupId=topic.group2] Subscribed to topic(s): topic.test
2020-08-14 13:46:30.089 [main] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Initializing ExecutorService
2020-08-14 13:46:30.089 [org.springframework.kafka.KafkaListenerEndpointContainer#1-3-C-1] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-topic.group2-9, groupId=topic.group2] Cluster ID: JcD5Rmr-Rmu4LUPRR7vWMw
2020-08-14 13:46:30.090 [org.springframework.kafka.KafkaListenerEndpointContainer#1-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-9, groupId=topic.group2] Discovered group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null)
2020-08-14 13:46:30.092 [org.springframework.kafka.KafkaListenerEndpointContainer#1-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-9, groupId=topic.group2] (Re-)joining group
2020-08-14 13:46:30.101 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-topic.group2-10, groupId=topic.group2] Cluster ID: JcD5Rmr-Rmu4LUPRR7vWMw
2020-08-14 13:46:30.102 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-10, groupId=topic.group2] Discovered group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null)
2020-08-14 13:46:30.103 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-10, groupId=topic.group2] (Re-)joining group
2020-08-14 13:46:30.110 [main] INFO  com.kafka.demo.test.KafkaProducerSerTest - Started KafkaProducerSerTest in 3.854 seconds (JVM running for 5.091)
2020-08-14 13:46:30.118 [pool-2-thread-1] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [192.168.100.213:6667, 192.168.100.214:6667, 192.168.100.215:6667]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = new
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 100
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-08-14 13:46:30.129 [pool-2-thread-1] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.5.0
2020-08-14 13:46:30.130 [pool-2-thread-1] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 66563e712b0b9f84
2020-08-14 13:46:30.130 [pool-2-thread-1] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1597383990129
2020-08-14 13:46:30.131 [pool-2-thread-1] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-new-11, groupId=new] Subscribed to topic(s): topic.quick.initial
2020-08-14 13:46:33.043 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-3, groupId=topic.group1] Attempt to heartbeat failed since group is rebalancing
2020-08-14 13:46:33.043 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-2, groupId=topic.group1] Attempt to heartbeat failed since group is rebalancing
2020-08-14 13:46:33.045 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group1-3, groupId=topic.group1] Revoke previously assigned partitions topic.test-2
2020-08-14 13:46:33.046 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - topic.group1: partitions revoked: [topic.test-2]
2020-08-14 13:46:33.046 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group1-2, groupId=topic.group1] Revoke previously assigned partitions topic.test-1
2020-08-14 13:46:33.046 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - topic.group1: partitions revoked: [topic.test-1]
2020-08-14 13:46:33.046 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-3, groupId=topic.group1] (Re-)joining group
2020-08-14 13:46:33.046 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-2, groupId=topic.group1] (Re-)joining group
2020-08-14 13:46:33.247 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-1, groupId=topic.group1] Attempt to heartbeat failed since group is rebalancing
2020-08-14 13:46:36.260 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-1, groupId=topic.group1] Attempt to heartbeat failed since group is rebalancing
2020-08-14 13:46:39.464 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-1, groupId=topic.group1] Attempt to heartbeat failed since group is rebalancing
2020-08-14 13:46:42.574 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-1, groupId=topic.group1] Attempt to heartbeat failed since group is rebalancing
2020-08-14 13:46:45.656 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-1, groupId=topic.group1] Attempt to heartbeat failed since group is rebalancing
2020-08-14 13:46:48.854 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-1, groupId=topic.group1] Attempt to heartbeat failed since group is rebalancing
2020-08-14 13:46:51.201 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-6, groupId=topic.group2] Discovered group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null)
2020-08-14 13:46:51.203 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-6, groupId=topic.group2] (Re-)joining group
2020-08-14 13:46:51.223 [org.springframework.kafka.KafkaListenerEndpointContainer#1-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-7, groupId=topic.group2] Group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2020-08-14 13:46:51.232 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-5, groupId=topic.group1] Discovered group coordinator ops-basic02.lingda.com:6667 (id: 2147483646 rack: null)
2020-08-14 13:46:51.233 [org.springframework.kafka.KafkaListenerEndpointContainer#1-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-8, groupId=topic.group2] Discovered group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null)
2020-08-14 13:46:51.233 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-5, groupId=topic.group1] (Re-)joining group
2020-08-14 13:46:51.234 [org.springframework.kafka.KafkaListenerEndpointContainer#1-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-8, groupId=topic.group2] (Re-)joining group
2020-08-14 13:46:51.285 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-topic.group2-6, groupId=topic.group2] Cluster ID: JcD5Rmr-Rmu4LUPRR7vWMw
2020-08-14 13:46:51.319 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-10, groupId=topic.group2] Group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2020-08-14 13:46:51.324 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-topic.group1-5, groupId=topic.group1] Cluster ID: JcD5Rmr-Rmu4LUPRR7vWMw
2020-08-14 13:46:51.326 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-10, groupId=topic.group2] Discovered group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null)
2020-08-14 13:46:51.326 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-10, groupId=topic.group2] Group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2020-08-14 13:46:51.327 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-10, groupId=topic.group2] Discovered group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null)
2020-08-14 13:46:51.328 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-10, groupId=topic.group2] Group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2020-08-14 13:46:51.329 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-10, groupId=topic.group2] Discovered group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null)
2020-08-14 13:46:51.330 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-10, groupId=topic.group2] Group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2020-08-14 13:46:51.331 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-10, groupId=topic.group2] Discovered group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null)
2020-08-14 13:46:51.332 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-10, groupId=topic.group2] Group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2020-08-14 13:46:51.333 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-10, groupId=topic.group2] Discovered group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null)
2020-08-14 13:46:51.333 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-10, groupId=topic.group2] Group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2020-08-14 13:46:51.334 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-10, groupId=topic.group2] Discovered group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null)
2020-08-14 13:46:51.335 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-10, groupId=topic.group2] Group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2020-08-14 13:46:51.338 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-10, groupId=topic.group2] Discovered group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null)
2020-08-14 13:46:51.338 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-10, groupId=topic.group2] Group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2020-08-14 13:46:51.340 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-10, groupId=topic.group2] Discovered group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null)
2020-08-14 13:46:51.340 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-10, groupId=topic.group2] Group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2020-08-14 13:46:51.341 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-10, groupId=topic.group2] Discovered group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null)
2020-08-14 13:46:51.341 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-10, groupId=topic.group2] Group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2020-08-14 13:46:51.343 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-10, groupId=topic.group2] Discovered group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null)
2020-08-14 13:46:51.343 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-10, groupId=topic.group2] Group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2020-08-14 13:46:51.344 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-10, groupId=topic.group2] Discovered group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null)
2020-08-14 13:46:51.344 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-10, groupId=topic.group2] Group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2020-08-14 13:46:51.345 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-10, groupId=topic.group2] Discovered group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null)
2020-08-14 13:46:51.346 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-10, groupId=topic.group2] Group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2020-08-14 13:46:51.346 [org.springframework.kafka.KafkaListenerEndpointContainer#1-2-C-1] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-topic.group2-8, groupId=topic.group2] Cluster ID: JcD5Rmr-Rmu4LUPRR7vWMw
2020-08-14 13:46:51.347 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-10, groupId=topic.group2] Discovered group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null)
2020-08-14 13:46:51.347 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-10, groupId=topic.group2] Group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2020-08-14 13:46:51.349 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-10, groupId=topic.group2] Discovered group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null)
2020-08-14 13:46:51.349 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-10, groupId=topic.group2] Group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2020-08-14 13:46:51.350 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-10, groupId=topic.group2] Discovered group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null)
2020-08-14 13:46:51.350 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-10, groupId=topic.group2] Group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2020-08-14 13:46:51.351 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-10, groupId=topic.group2] Discovered group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null)
2020-08-14 13:46:51.352 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-10, groupId=topic.group2] Group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2020-08-14 13:46:51.353 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-10, groupId=topic.group2] Discovered group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null)
2020-08-14 13:46:51.353 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-10, groupId=topic.group2] Group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2020-08-14 13:46:51.355 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-10, groupId=topic.group2] Discovered group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null)
2020-08-14 13:46:51.355 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-10, groupId=topic.group2] Group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2020-08-14 13:46:51.356 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-10, groupId=topic.group2] Discovered group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null)
2020-08-14 13:46:51.357 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-10, groupId=topic.group2] Group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2020-08-14 13:46:51.361 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-10, groupId=topic.group2] Discovered group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null)
2020-08-14 13:46:51.362 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-10, groupId=topic.group2] Group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2020-08-14 13:46:51.364 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-10, groupId=topic.group2] Discovered group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null)
2020-08-14 13:46:51.364 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-10, groupId=topic.group2] Group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2020-08-14 13:46:51.365 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-10, groupId=topic.group2] Discovered group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null)
2020-08-14 13:46:51.366 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-10, groupId=topic.group2] Group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2020-08-14 13:46:51.367 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-10, groupId=topic.group2] Discovered group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null)
2020-08-14 13:46:51.367 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-10, groupId=topic.group2] Group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2020-08-14 13:46:51.368 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-10, groupId=topic.group2] Discovered group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null)
2020-08-14 13:46:51.370 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-10, groupId=topic.group2] Join group failed with org.apache.kafka.common.errors.DisconnectException
2020-08-14 13:46:51.370 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-10, groupId=topic.group2] (Re-)joining group
2020-08-14 13:46:51.410 [org.springframework.kafka.KafkaListenerEndpointContainer#1-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-9, groupId=topic.group2] Group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2020-08-14 13:46:51.418 [org.springframework.kafka.KafkaListenerEndpointContainer#1-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-9, groupId=topic.group2] Join group failed with org.apache.kafka.common.errors.DisconnectException
2020-08-14 13:46:51.472 [org.springframework.kafka.KafkaListenerEndpointContainer#1-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-9, groupId=topic.group2] Discovered group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null)
2020-08-14 13:46:51.473 [org.springframework.kafka.KafkaListenerEndpointContainer#1-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-9, groupId=topic.group2] (Re-)joining group
2020-08-14 13:46:51.978 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-1, groupId=topic.group1] Attempt to heartbeat failed since group is rebalancing
2020-08-14 13:46:54.995 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-topic.group1-1, groupId=topic.group1] Revoke previously assigned partitions topic.test-0
2020-08-14 13:46:54.996 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - topic.group1: partitions revoked: [topic.test-0]
2020-08-14 13:46:54.996 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-1, groupId=topic.group1] Member consumer-topic.group1-1-cd562688-5d35-49ea-a7c7-b22fbb3fca3c sending LeaveGroup request to coordinator ops-basic02.lingda.com:6667 (id: 2147483646 rack: null) due to the consumer unsubscribed from all topics
2020-08-14 13:46:54.997 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group1-1, groupId=topic.group1] Unsubscribed all topics or patterns and assigned partitions
2020-08-14 13:46:54.998 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Shutting down ExecutorService
2020-08-14 13:46:54.999 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-3, groupId=topic.group1] Member consumer-topic.group1-3-21f61ab4-ad4d-4456-9bf4-b042cd12e9e8 sending LeaveGroup request to coordinator ops-basic02.lingda.com:6667 (id: 2147483646 rack: null) due to the consumer unsubscribed from all topics
2020-08-14 13:46:54.999 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group1-5, groupId=topic.group1] Unsubscribed all topics or patterns and assigned partitions
2020-08-14 13:46:54.999 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Shutting down ExecutorService
2020-08-14 13:46:55.000 [org.springframework.kafka.KafkaListenerEndpointContainer#1-1-C-1] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group2-7, groupId=topic.group2] Unsubscribed all topics or patterns and assigned partitions
2020-08-14 13:46:55.000 [org.springframework.kafka.KafkaListenerEndpointContainer#1-1-C-1] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Shutting down ExecutorService
2020-08-14 13:46:55.000 [org.springframework.kafka.KafkaListenerEndpointContainer#1-2-C-1] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group2-8, groupId=topic.group2] Unsubscribed all topics or patterns and assigned partitions
2020-08-14 13:46:54.999 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group1-4, groupId=topic.group1] Unsubscribed all topics or patterns and assigned partitions
2020-08-14 13:46:55.000 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group1-3, groupId=topic.group1] Unsubscribed all topics or patterns and assigned partitions
2020-08-14 13:46:55.000 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Shutting down ExecutorService
2020-08-14 13:46:55.000 [org.springframework.kafka.KafkaListenerEndpointContainer#1-2-C-1] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Shutting down ExecutorService
2020-08-14 13:46:55.001 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Shutting down ExecutorService
2020-08-14 13:46:55.003 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-1, groupId=topic.group1] Attempt to heartbeat failed since group is rebalancing
2020-08-14 13:46:55.001 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group2-6, groupId=topic.group2] Unsubscribed all topics or patterns and assigned partitions
2020-08-14 13:46:55.006 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Shutting down ExecutorService
2020-08-14 13:46:55.001 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group1-2, groupId=topic.group1] Member consumer-topic.group1-2-84120cc6-de43-49f4-94ac-1dd77ce1499f sending LeaveGroup request to coordinator ops-basic02.lingda.com:6667 (id: 2147483646 rack: null) due to the consumer unsubscribed from all topics
2020-08-14 13:46:55.001 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group2-10, groupId=topic.group2] Unsubscribed all topics or patterns and assigned partitions
2020-08-14 13:46:55.001 [org.springframework.kafka.KafkaListenerEndpointContainer#1-3-C-1] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group2-9, groupId=topic.group2] Unsubscribed all topics or patterns and assigned partitions
2020-08-14 13:46:55.008 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Shutting down ExecutorService
2020-08-14 13:46:55.011 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-topic.group1-2, groupId=topic.group1] Unsubscribed all topics or patterns and assigned partitions
2020-08-14 13:46:55.008 [org.springframework.kafka.KafkaListenerEndpointContainer#1-3-C-1] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Shutting down ExecutorService
2020-08-14 13:46:55.010 [org.springframework.kafka.KafkaListenerEndpointContainer#1-1-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - topic.group2: Consumer stopped
2020-08-14 13:46:55.012 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Shutting down ExecutorService
2020-08-14 13:46:55.014 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - topic.group1: Consumer stopped
2020-08-14 13:46:55.021 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - topic.group1: Consumer stopped
2020-08-14 13:46:55.024 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - topic.group1: Consumer stopped
2020-08-14 13:46:55.024 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - topic.group1: Consumer stopped
2020-08-14 13:46:55.029 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - topic.group1: Consumer stopped
2020-08-14 13:47:12.228 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-6, groupId=topic.group2] Group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2020-08-14 13:47:12.229 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - topic.group2: Consumer stopped
2020-08-14 13:47:12.384 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-10, groupId=topic.group2] Group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2020-08-14 13:47:12.388 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - topic.group2: Consumer stopped
2020-08-14 13:47:12.432 [org.springframework.kafka.KafkaListenerEndpointContainer#1-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-8, groupId=topic.group2] Group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2020-08-14 13:47:12.434 [org.springframework.kafka.KafkaListenerEndpointContainer#1-2-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - topic.group2: Consumer stopped
2020-08-14 13:47:12.542 [org.springframework.kafka.KafkaListenerEndpointContainer#1-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-topic.group2-9, groupId=topic.group2] Group coordinator ops-basic01.lingda.com:6667 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2020-08-14 13:47:12.544 [org.springframework.kafka.KafkaListenerEndpointContainer#1-3-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - topic.group2: Consumer stopped
2020-08-14 13:47:12.545 [SpringContextShutdownHook] INFO  o.s.scheduling.concurrent.ThreadPoolTaskExecutor - Shutting down ExecutorService 'applicationTaskExecutor'
